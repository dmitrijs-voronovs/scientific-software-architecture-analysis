id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1307:2304,deployability,version,versions,2304,"/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2333,deployability,log,logging,2333,"1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2428,deployability,version,versions,2428,"_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the sam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2457,deployability,log,logging,2457,"heckouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2552,deployability,version,versions,2552,"ilders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (thoug",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2581,deployability,log,logging,2581,", in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2674,deployability,version,versions,2674,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2703,deployability,log,logging,2703,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2889,deployability,log,logging,2889,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1835,integrability,version,versions,1835,"rg/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2304,integrability,version,versions,2304,"/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2428,integrability,version,versions,2428,"_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the sam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2552,integrability,version,versions,2552,"ilders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (thoug",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2634,integrability,filter,filter,2634,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2674,integrability,version,versions,2674,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2738,integrability,filter,filter,2738,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2757,integrability,filter,filter,2757,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2915,integrability,filter,filter,2915,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2964,integrability,messag,message,2964,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:787,interoperability,format,format,787,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2964,interoperability,messag,message,2964,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:576,modifiability,pac,packages,576,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1172,modifiability,pac,packages,1172,"suecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1361,modifiability,pac,packages,1361,"o look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1538,modifiability,pac,packages,1538,"anpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/do",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1715,modifiability,pac,packages,1715," cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1835,modifiability,version,versions,1835,"rg/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2013,modifiability,pac,packages,2013,"heet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/ch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2201,modifiability,pac,packages,2201,"ne 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2304,modifiability,version,versions,2304,"/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2428,modifiability,version,versions,2428,"_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the sam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2552,modifiability,version,versions,2552,"ilders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (thoug",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2674,modifiability,version,versions,2674,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2868,modifiability,pac,packages,2868,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:290,performance,error,errors,290,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:382,performance,error,error,382,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:726,performance,error,errors,726,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:779,performance,error,errors,779,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2982,performance,error,errors,2982,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3209,performance,error,error,3209,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3434,performance,error,error,3434,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3563,performance,error,errors,3563,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:412,reliability,fail,fail,412,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:290,safety,error,errors,290,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:382,safety,error,error,382,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:388,safety,log,logs,388,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:726,safety,error,errors,726,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:779,safety,error,errors,779,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2034,safety,log,logging,2034,"). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2097,safety,log,logger,2097,"uts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2222,safety,log,logging,2222,". app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/doc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2257,safety,log,logger,2257,"mes). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2333,safety,log,logging,2333,"1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2457,safety,log,logging,2457,"heckouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2581,safety,log,logging,2581,", in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2703,safety,log,logging,2703,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2889,safety,log,logging,2889,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2982,safety,error,errors,2982,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3209,safety,error,error,3209,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3434,safety,error,error,3434,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3563,safety,error,errors,3563,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:323,security,privil,privileges,323,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:388,security,log,logs,388,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2034,security,log,logging,2034,"). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2097,security,log,logger,2097,"uts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2222,security,log,logging,2222,". app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/doc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2257,security,log,logger,2257,"mes). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2333,security,log,logging,2333,"1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2457,security,log,logging,2457,"heckouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2581,security,log,logging,2581,", in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2703,security,log,logging,2703,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2889,security,log,logging,2889,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:388,testability,log,logs,388,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:427,testability,trace,traceback,427,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:460,testability,Trace,Traceback,460,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1041,testability,Trace,Traceback,1041,"m opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"",",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1864,testability,context,contextlib,1864,"kouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2034,testability,log,logging,2034,"). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2097,testability,log,logger,2097,"uts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2222,testability,log,logging,2222,". app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/doc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2257,testability,log,logger,2257,"mes). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2333,testability,log,logging,2333,"1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2457,testability,log,logging,2457,"heckouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2581,testability,log,logging,2581,", in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2703,testability,log,logging,2703,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2889,testability,log,logging,2889,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:290,usability,error,errors,290,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:382,usability,error,error,382,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:611,usability,User,UserWarning,611,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:726,usability,error,errors,726,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:779,usability,error,errors,779,"Doc builds broken; @fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:1027,usability,custom,custom,1027,"gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs? Anyways, the docs fail with this traceback:. <details>. <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead. app.add_stylesheet('css/custom.css'). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2982,usability,error,errors,2982,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3209,usability,error,error,3209,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3434,usability,error,error,3434,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3563,usability,error,errors,3563,"build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build. updated_docnames = set(self.read()). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter. raise SphinxWarning(location + "":"" + str(message)). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/pull/1308:4,modifiability,layer,layer,4,Add layer option to pca; https://github.com/theislab/scanpy/issues/1301,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1308
https://github.com/scverse/scanpy/issues/1312:70,usability,clear,clear,70,"The legend overlap with figures in plot function ; <!-- Please give a clear and concise description of what the bug is: -->. When multiple plots in one figure, if the legend of one figure is comprehensive, there is no space left for the legend to be shown. The scanpy just overlap the next plot on it. ![25AD7E00-E9A8-4CC6-A347-C4C76177F770](https://user-images.githubusercontent.com/16257776/86968887-e0ae3a80-c13a-11ea-805c-8620a9557087.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pl.umap(adata, color=['sample_id','IMPACT_TMB']) . ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:350,usability,user,user-images,350,"The legend overlap with figures in plot function ; <!-- Please give a clear and concise description of what the bug is: -->. When multiple plots in one figure, if the legend of one figure is comprehensive, there is no space left for the legend to be shown. The scanpy just overlap the next plot on it. ![25AD7E00-E9A8-4CC6-A347-C4C76177F770](https://user-images.githubusercontent.com/16257776/86968887-e0ae3a80-c13a-11ea-805c-8620a9557087.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pl.umap(adata, color=['sample_id','IMPACT_TMB']) . ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1312:456,usability,minim,minimal,456,"The legend overlap with figures in plot function ; <!-- Please give a clear and concise description of what the bug is: -->. When multiple plots in one figure, if the legend of one figure is comprehensive, there is no space left for the legend to be shown. The scanpy just overlap the next plot on it. ![25AD7E00-E9A8-4CC6-A347-C4C76177F770](https://user-images.githubusercontent.com/16257776/86968887-e0ae3a80-c13a-11ea-805c-8620a9557087.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pl.umap(adata, color=['sample_id','IMPACT_TMB']) . ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1313:0,availability,Error,Error,0,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:299,availability,Cluster,Cluster-marker-genes,299,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:329,availability,Cluster,Cluster,329,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:703,availability,cluster,clusters,703,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:804,availability,cluster,clusters,804,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1631,availability,cluster,clusters,1631,"ata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_posi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1675,availability,cluster,clusters,1675,"nk_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1784,availability,cluster,clusters,1784,"es=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4036,availability,cluster,cluster,4036,"m, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4466,availability,consist,consistent,4466,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:299,deployability,Cluster,Cluster-marker-genes,299,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:329,deployability,Cluster,Cluster,329,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:703,deployability,cluster,clusters,703,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:804,deployability,cluster,clusters,804,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1030,deployability,log,logfoldchanges,1030,"map: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1605,deployability,modul,module,1605,".pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1631,deployability,cluster,clusters,1631,"ata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_posi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1675,deployability,cluster,clusters,1675,"nk_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1784,deployability,cluster,clusters,1784,"es=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1805,deployability,version,versions,1805,"ers""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2042,deployability,version,versions,2042," sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2456,deployability,version,versions,2456,"-------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2574,deployability,log,log,2574,"n-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/ver",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2904,deployability,version,versions,2904,"map(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3225,deployability,version,versions,3225,"anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3573,deployability,version,versions,3573,", num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3987,deployability,version,versions,3987,"gories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4036,deployability,cluster,cluster,4036,"m, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4497,deployability,version,versions,4497,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4908,deployability,VERSION,VERSIONS,4908,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:5090,deployability,version,version,5090,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2244,energy efficiency,heat,heatmap,2244," found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2257,energy efficiency,heat,heatmap,2257," key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2530,energy efficiency,heat,heatmap,2530,"Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4547,energy efficiency,core,core,4547,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1805,integrability,version,versions,1805,"ers""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2042,integrability,version,versions,2042," sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2456,integrability,version,versions,2456,"-------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2904,integrability,version,versions,2904,"map(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3225,integrability,version,versions,3225,"anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3573,integrability,version,versions,3573,", num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3987,integrability,version,versions,3987,"gories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4497,integrability,version,versions,4497,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4908,integrability,VERSION,VERSIONS,4908,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:5090,integrability,version,version,5090,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4725,interoperability,format,format,4725,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1328,modifiability,paramet,parameters,1328,"ter marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1605,modifiability,modul,module,1605,".pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1805,modifiability,version,versions,1805,"ers""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1839,modifiability,pac,packages,1839,"lows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2042,modifiability,version,versions,2042," sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2076,modifiability,pac,packages,2076,"by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_grou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2456,modifiability,version,versions,2456,"-------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2490,modifiability,pac,packages,2490,"---------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2680,modifiability,layer,layer,2680,""", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, us",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2904,modifiability,version,versions,2904,"map(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2938,modifiability,pac,packages,2938,"y, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3225,modifiability,version,versions,3225,"anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3259,modifiability,pac,packages,3259,"p(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3573,modifiability,version,versions,3573,", num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3607,modifiability,pac,packages,3607,"_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3987,modifiability,version,versions,3987,"gories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4021,modifiability,pac,packages,4021,"upby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4497,modifiability,version,versions,4497,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4531,modifiability,pac,packages,4531,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4908,modifiability,VERSION,VERSIONS,4908,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:5090,modifiability,version,version,5090,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:0,performance,Error,Error,0,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:0,safety,Error,Error,0,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:724,safety,test,test,724,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1030,safety,log,logfoldchanges,1030,"map: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1578,safety,input,input-,1578,"s.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1605,safety,modul,module,1605,".pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1696,safety,test,test,1696,"ta, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2574,safety,log,log,2574,"n-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/ver",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1030,security,log,logfoldchanges,1030,"map: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2574,security,log,log,2574,"n-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/ver",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:724,testability,test,test,724,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1030,testability,log,logfoldchanges,1030,"map: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1534,testability,Trace,Traceback,1534,"unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1696,testability,test,test,1696,"ta, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2574,testability,log,log,2574,"n-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/ver",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:0,usability,Error,Error,0,"Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.; The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc. import pandas as pd. import matplotlib.pyplot as plt. import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). adata.var_names_make_unique(). adata.var[""mt""] = adata.var_names.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1578,usability,input,input-,1578,"s.str.startswith(""MT-""). sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ```. The results are as follows:. ```ranking genes. finished: added to `.uns['rank_genes_groups']`. 'names', sorted np.recarray to be indexed by group ids. 'scores', sorted np.recarray to be indexed by group ids. 'logfoldchanges', sorted np.recarray to be indexed by group ids. 'pvals', sorted np.recarray to be indexed by group ids. 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02). WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-a44c51f396af> in <module>. 2 # genes across clusters. 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""). ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds). 454 show=show,. 455 save=save,. --> 456 **kwds,. 457 ). 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). 392 from .._anndata import heatmap. 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,. --> 394 var_group_positions=group_positions, show=show, save=save, **kwds). 395 . 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:3623,usability,tool,tools,3623,"roup_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1454 var_names=var_names,. 1455 var_group_labels=var_group_labels,. -> 1456 var_group_positions=var_group_positions,. 1457 ). 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions). 3109 """""". 3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4466,usability,consist,consistent,4466,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:5010,usability,learn,learn,5010,"3110 . -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby). 3112 . 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 3196 ). -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key). 3198 . 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering. 131 ). --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True). 133 . 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self). 2229 raise ValueError(""The truth value of a {0} is ambiguous. "". 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."". -> 2231 .format(self.__class__.__name__)). 2232 . 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1. Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/pull/1314:0,deployability,updat,update,0,update doc images;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1314
https://github.com/scverse/scanpy/pull/1314:0,safety,updat,update,0,update doc images;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1314
https://github.com/scverse/scanpy/pull/1314:0,security,updat,update,0,update doc images;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1314
https://github.com/scverse/scanpy/issues/1315:37,availability,error,error,37,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:211,availability,error,error,211,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:572,availability,Error,Error,572,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:811,deployability,modul,module,811,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1347,deployability,Version,Versions,1347,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1380,deployability,log,logging,1380,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1347,integrability,Version,Versions,1347,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:811,modifiability,modul,module,811,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:924,modifiability,pac,packages,924,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:981,modifiability,layer,layer,981,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1347,modifiability,Version,Versions,1347,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:37,performance,error,error,37,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:211,performance,error,error,211,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:572,performance,Error,Error,572,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:37,safety,error,error,37,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:211,safety,error,error,211,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:572,safety,Error,Error,572,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:784,safety,input,input-,784,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:811,safety,modul,module,811,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1380,safety,log,logging,1380,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1380,security,log,logging,1380,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:740,testability,Trace,Traceback,740,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1380,testability,log,logging,1380,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:37,usability,error,error,37,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:88,usability,clear,clear,88,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:211,usability,error,error,211,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:343,usability,minim,minimal,343,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:572,usability,Error,Error,572,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:784,usability,input,input-,784,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1499,usability,learn,learn,1499,"get.obs_df and get.var_df produce an error when there is only 1 key; <!-- Please give a clear and concise description of what the bug is: -->. When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. pbmc = sc.datasets.pbmc68k_reduced(). sc.get.obs_df(pbmc, keys=('HES4')). sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-60-663347265b80> in <module>. ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer). 223 not_found.append(key). 224 if len(not_found) > 0:. --> 225 raise KeyError(. 226 f""Could not find keys '{not_found}' in columns of `adata.var` or"". 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`."". ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/pull/1316:29,deployability,updat,updates,29,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:40,deployability,updat,updated,40,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:95,modifiability,paramet,parameters,95,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:157,modifiability,paramet,parameter,157,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:29,safety,updat,updates,29,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:40,safety,updat,updated,40,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:29,security,updat,updates,29,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:40,security,updat,updated,40,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:223,testability,unit,units,223,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:0,usability,document,documentation,0,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:48,usability,document,documentation,48,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1316:248,usability,document,documentation,248,documentation and small plot updates; * updated documentation images. * fix overwrite of style parameters after multiple calls to `style()`. * added padding parameter to dotplot and stacked_violin to address #1270. * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/pull/1317:0,deployability,Updat,Update,0,Update installation.rst; correct leidenalg package name,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1317
https://github.com/scverse/scanpy/pull/1317:7,deployability,instal,installation,7,Update installation.rst; correct leidenalg package name,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1317
https://github.com/scverse/scanpy/pull/1317:43,modifiability,pac,package,43,Update installation.rst; correct leidenalg package name,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1317
https://github.com/scverse/scanpy/pull/1317:0,safety,Updat,Update,0,Update installation.rst; correct leidenalg package name,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1317
https://github.com/scverse/scanpy/pull/1317:0,security,Updat,Update,0,Update installation.rst; correct leidenalg package name,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1317
https://github.com/scverse/scanpy/issues/1318:1543,availability,Error,Error,1543,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1888,deployability,Version,Versions,1888,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1921,deployability,log,logging,1921,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1888,integrability,Version,Versions,1888,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:931,modifiability,layer,layers,931,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1888,modifiability,Version,Versions,1888,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1543,performance,Error,Error,1543,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:873,safety,detect,detectable,873,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1543,safety,Error,Error,1543,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1921,safety,log,logging,1921,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:873,security,detect,detectable,873,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1921,security,log,logging,1921,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1921,testability,log,logging,1921,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:14,usability,custom,custom,14,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:104,usability,clear,clear,104,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:176,usability,custom,custom,176,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:427,usability,tool,tools,427,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:536,usability,tool,tools,536,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:640,usability,minim,minimal,640,"sc.tl.umap on custom connectivities from representation ""X"" forces PCA calc instead; <!-- Please give a clear and concise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1543,usability,Error,Error,1543,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:2040,usability,learn,learn,2040,"ise description of what the bug is: -->. I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. . sc.tl.umap falls back to pca in:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities? ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from scvelo.pp import neighbors. adata. #AnnData object with n_obs  n_vars = 4329  192. #obs: 'BARCODE', 'sample', 'detectable.features'. #var: 'gene_ids', 'feature_types'. #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']. #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. #WARNING: .obsp[""connectivities""] have not been computed using umap. #WARNING: Youre trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`. # Falling back to preprocessing with `sc.pp.pca` and default params. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/pull/1319:0,deployability,updat,updated,0,updated documentation to point to latest plotting tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1319
https://github.com/scverse/scanpy/pull/1319:0,safety,updat,updated,0,updated documentation to point to latest plotting tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1319
https://github.com/scverse/scanpy/pull/1319:0,security,updat,updated,0,updated documentation to point to latest plotting tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1319
https://github.com/scverse/scanpy/pull/1319:8,usability,document,documentation,8,updated documentation to point to latest plotting tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1319
https://github.com/scverse/scanpy/pull/1320:10,deployability,depend,dependencies,10,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:48,deployability,build,builds,48,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:63,deployability,build,builds,63,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:113,deployability,version,versions,113,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:163,deployability,version,version,163,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:176,deployability,instal,installed,176,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:74,energy efficiency,current,currently,74,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:10,integrability,depend,dependencies,10,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:113,integrability,version,versions,113,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:163,integrability,version,version,163,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:100,interoperability,incompatib,incompatible,100,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:152,interoperability,compatib,compatible,152,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:10,modifiability,depend,dependencies,10,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:113,modifiability,version,versions,113,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:163,modifiability,version,version,163,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:10,safety,depend,dependencies,10,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/pull/1320:10,testability,depend,dependencies,10,"Make sure dependencies are up to date in travis builds; Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/issues/1321:611,availability,Error,Error,611,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:690,availability,down,download,690,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:2,deployability,scale,scale,2,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:129,deployability,scale,scale,129,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:194,deployability,version,version,194,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:551,deployability,log,log,551,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:566,deployability,log,logging,566,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:808,deployability,Version,Versions,808,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:841,deployability,log,logging,841,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:2,energy efficiency,scale,scale,2,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:129,energy efficiency,scale,scale,129,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:194,integrability,version,version,194,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:808,integrability,Version,Versions,808,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:2,modifiability,scal,scale,2,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:129,modifiability,scal,scale,129,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:194,modifiability,version,version,194,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:808,modifiability,Version,Versions,808,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:2,performance,scale,scale,2,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:129,performance,scale,scale,129,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:611,performance,Error,Error,611,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:551,safety,log,log,551,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:566,safety,log,logging,566,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:611,safety,Error,Error,611,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:841,safety,log,logging,841,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:551,security,log,log,551,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:566,security,log,logging,566,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:841,security,log,logging,841,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:551,testability,log,log,551,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:566,testability,log,logging,566,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:841,testability,log,logging,841,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:68,usability,clear,clear,68,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:227,usability,minim,minimal,227,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:611,usability,Error,Error,611,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:708,usability,user,user-images,708,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:978,usability,learn,learn,978,"y-scale missing in stacked_violin for 1.5.2.dev; <!-- Please give a clear and concise description of what the bug is: -->. The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False). sc.logging.print_versions(). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1322:547,availability,Error,Error,547,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:16,deployability,modul,module,16,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:192,deployability,modul,module,192,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:721,deployability,modul,module,721,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:839,deployability,modul,module,839,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:893,deployability,Version,Versions,893,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:926,deployability,log,logging,926,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:257,energy efficiency,load,load,257,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:893,integrability,Version,Versions,893,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:16,modifiability,modul,module,16,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:192,modifiability,modul,module,192,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:721,modifiability,modul,module,721,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:839,modifiability,modul,module,839,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:893,modifiability,Version,Versions,893,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:257,performance,load,load,257,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:547,performance,Error,Error,547,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:16,safety,modul,module,16,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:192,safety,modul,module,192,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:547,safety,Error,Error,547,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:684,safety,input,input-,684,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:721,safety,modul,module,721,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:839,safety,modul,module,839,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:926,safety,log,logging,926,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:926,security,log,logging,926,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:633,testability,Trace,Traceback,633,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:926,testability,log,logging,926,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:79,usability,clear,clear,79,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:312,usability,minim,minimal,312,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:547,usability,Error,Error,547,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:684,usability,input,input-,684,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:1050,usability,learn,learn,1050,"AttributeError: module 'scanpy' has no attribute 'anndata'; <!-- Please give a clear and concise description of what the bug is: -->. The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>. sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/pull/1323:7,availability,error,error,7,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:59,deployability,depend,depends,59,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:97,deployability,API,API,97,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:0,energy efficiency,Reduc,Reduce,0,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:59,integrability,depend,depends,59,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:97,integrability,API,API,97,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:97,interoperability,API,API,97,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:59,modifiability,depend,depends,59,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:7,performance,error,error,7,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:28,performance,network,networkx,28,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:7,safety,error,error,7,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:59,safety,depend,depends,59,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:28,security,network,networkx,28,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:59,testability,depend,depends,59,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/pull/1323:7,usability,error,error,7,Reduce error potential from networkx (e.g. #1227); nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/issues/1324:343,integrability,filter,filter,343,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:451,integrability,filter,filter,451,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:966,integrability,filter,filtering,966,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:250,modifiability,paramet,parameter,250,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:782,modifiability,paramet,parameter,782,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:823,safety,test,test,823,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:847,safety,detect,detected,847,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:847,security,detect,detected,847,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:823,testability,test,test,823,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:861,usability,minim,minimum,861,"DE analysis and filter_rank_genes_groups; Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`. I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells). There are mainly two possibilities, namely:. - a gene is expressed in at least X% of cells of **both** groups;. - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks! Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1325:231,availability,down,downregulated,231,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:330,availability,down,downregulated,330,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:828,availability,slo,slot,828,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:929,availability,down,downregulated,929,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:27,reliability,doe,does,27,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:828,reliability,slo,slot,828,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:36,usability,support,support,36,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:75,usability,clear,clear,75,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:623,usability,behavi,behavior,623,"filter_rank_genes_groups() does not support rankby_abs; <!-- Please give a clear and concise description of what the bug is: -->. Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions. 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold. 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1326:303,deployability,log,log,303,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:534,deployability,modul,module,534,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:602,deployability,log,log,602,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:737,deployability,log,log,737,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:990,deployability,modul,module,990,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:1057,deployability,Version,Versions,1057,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:1057,integrability,Version,Versions,1057,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:534,modifiability,modul,module,534,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:668,modifiability,pac,packages,668,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:990,modifiability,modul,module,990,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:1057,modifiability,Version,Versions,1057,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:86,safety,compl,complete,86,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:303,safety,log,log,303,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:508,safety,input,input-,508,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:534,safety,modul,module,534,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:602,safety,log,log,602,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:737,safety,log,log,737,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:990,safety,modul,module,990,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:86,security,compl,complete,86,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:303,security,log,log,303,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:602,security,log,log,602,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:737,security,log,log,737,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:867,security,modif,modifies,867,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:303,testability,log,log,303,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:464,testability,Trace,Traceback,464,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:602,testability,log,log,602,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:737,testability,log,log,737,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:51,usability,help,help,51,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:508,usability,input,input-,508,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:1158,usability,learn,learn,1158,"Summer student from Pinello Lab at Harvard seeking help from Theis Lab; I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```. adata.raw = adata. sc.pp.recipe_weinreb17(adata, log=False). sc.tl.pca(adata). ```. I keep getting this output:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-4-bfa4168a87e6> in <module>. 1 adata.raw = adata. ----> 2 sc.pp.recipe_weinreb17(adata, log=False). 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy). 48 ). 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself. ---> 50 X_pca = pp.pca(. 51 pp.zscore_deprecated(adata.X),. 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'. ```. Versions:. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/pull/1327:138,safety,test,test,138,"Weinreb recipe fix; Fixes https://github.com/theislab/scanpy/issues/1326. `pca` was being imported from an old location, and there was no test. Cleaned up a bit of related code while I was at it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1327
https://github.com/scverse/scanpy/pull/1327:138,testability,test,test,138,"Weinreb recipe fix; Fixes https://github.com/theislab/scanpy/issues/1326. `pca` was being imported from an old location, and there was no test. Cleaned up a bit of related code while I was at it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1327
https://github.com/scverse/scanpy/pull/1330:187,safety,test,test,187,"Add tie correction to wilcoxon method in rank_genes_groups; Addresses https://github.com/theislab/scanpy/issues/698. Adds some bug fixes and optional tie correction for wilcoxon rank sum test. ```. # tie_correct=False by default. sc.tl.rank_genes_groups(adata, ..., method='wilcoxon', tie_correct=True). ```. Also the test here compares `rank_genes_groups` method `'wilcoxon'` to `scipy.stats.mannwhitneyu`. @idavydov , thanks for the `matrix_tiecorrect` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1330
https://github.com/scverse/scanpy/pull/1330:318,safety,test,test,318,"Add tie correction to wilcoxon method in rank_genes_groups; Addresses https://github.com/theislab/scanpy/issues/698. Adds some bug fixes and optional tie correction for wilcoxon rank sum test. ```. # tie_correct=False by default. sc.tl.rank_genes_groups(adata, ..., method='wilcoxon', tie_correct=True). ```. Also the test here compares `rank_genes_groups` method `'wilcoxon'` to `scipy.stats.mannwhitneyu`. @idavydov , thanks for the `matrix_tiecorrect` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1330
https://github.com/scverse/scanpy/pull/1330:187,testability,test,test,187,"Add tie correction to wilcoxon method in rank_genes_groups; Addresses https://github.com/theislab/scanpy/issues/698. Adds some bug fixes and optional tie correction for wilcoxon rank sum test. ```. # tie_correct=False by default. sc.tl.rank_genes_groups(adata, ..., method='wilcoxon', tie_correct=True). ```. Also the test here compares `rank_genes_groups` method `'wilcoxon'` to `scipy.stats.mannwhitneyu`. @idavydov , thanks for the `matrix_tiecorrect` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1330
https://github.com/scverse/scanpy/pull/1330:318,testability,test,test,318,"Add tie correction to wilcoxon method in rank_genes_groups; Addresses https://github.com/theislab/scanpy/issues/698. Adds some bug fixes and optional tie correction for wilcoxon rank sum test. ```. # tie_correct=False by default. sc.tl.rank_genes_groups(adata, ..., method='wilcoxon', tie_correct=True). ```. Also the test here compares `rank_genes_groups` method `'wilcoxon'` to `scipy.stats.mannwhitneyu`. @idavydov , thanks for the `matrix_tiecorrect` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1330
https://github.com/scverse/scanpy/pull/1332:14,deployability,integr,integration,14,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:38,deployability,API,API,38,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:152,deployability,integr,integration,152,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:320,deployability,scale,scale,320,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:326,deployability,integr,integration,326,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:444,deployability,API,API,444,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:320,energy efficiency,scale,scale,320,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:14,integrability,integr,integration,14,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:38,integrability,API,API,38,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:152,integrability,integr,integration,152,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:326,integrability,integration test,integration testing,326,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:385,integrability,batch,batch,385,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:444,integrability,API,API,444,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:14,interoperability,integr,integration,14,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:38,interoperability,API,API,38,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:152,interoperability,integr,integration,152,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:326,interoperability,integr,integration,326,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:444,interoperability,API,API,444,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:14,modifiability,integr,integration,14,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:152,modifiability,integr,integration,152,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:320,modifiability,scal,scale,320,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:326,modifiability,integr,integration,326,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:320,performance,scale,scale,320,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:385,performance,batch,batch,385,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:14,reliability,integr,integration,14,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:152,reliability,integr,integration,152,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:326,reliability,integr,integration,326,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:338,safety,test,testing,338,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:14,security,integr,integration,14,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:152,security,integr,integration,152,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:326,security,integr,integration,326,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:14,testability,integr,integration,14,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:152,testability,integr,integration,152,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:326,testability,integr,integration,326,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:338,testability,test,testing,338,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:373,testability,verif,verify,373,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:285,usability,close,closely,285,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:478,usability,help,help,478,Add Scanorama integration to external API; Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/issues/1333:692,availability,Error,Error,692,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:23,deployability,log,logged,23,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:72,deployability,log,logged,72,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:275,deployability,log,logged,275,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:299,deployability,log,logging,299,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:360,deployability,log,logging,360,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:411,deployability,log,logged,411,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:815,deployability,log,log-transformed,815,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:842,deployability,Version,Versions,842,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:875,deployability,log,logging,875,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:819,integrability,transform,transformed,819,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:842,integrability,Version,Versions,842,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:819,interoperability,transform,transformed,819,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:61,modifiability,layer,layers,61,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:216,modifiability,layer,layer,216,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:309,modifiability,layer,layer,309,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:377,modifiability,layer,layer,377,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:591,modifiability,layer,layers,591,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:637,modifiability,layer,layer,637,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:842,modifiability,Version,Versions,842,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:692,performance,Error,Error,692,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:23,safety,log,logged,23,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:72,safety,log,logged,72,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:275,safety,log,logged,275,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:299,safety,log,logging,299,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:360,safety,log,logging,360,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:411,safety,log,logged,411,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:692,safety,Error,Error,692,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:815,safety,log,log-transformed,815,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:875,safety,log,logging,875,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:23,security,log,logged,23,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:72,security,log,logged,72,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:275,security,log,logged,275,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:299,security,log,logging,299,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:360,security,log,logging,360,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:411,security,log,logged,411,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:815,security,log,log-transformed,815,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:875,security,log,logging,875,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:23,testability,log,logged,23,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:72,testability,log,logged,72,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:275,testability,log,logged,275,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:299,testability,log,logging,299,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:360,testability,log,logging,360,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:411,testability,log,logged,411,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:815,testability,log,log-transformed,815,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:875,testability,log,logging,875,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:100,usability,clear,clear,100,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:430,usability,minim,minimal,430,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:692,usability,Error,Error,692,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:1012,usability,learn,learn,1012,"log1p warns adata.X is logged when it may not be (when other layers are logged); <!-- Please give a clear and concise description of what the bug is: -->. When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata.layers['other'] = adata.X. sc.pp.log1p(adata, layer='other'). sc.pp.log1p(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. WARNING: adata.X seems to be already log-transformed. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/pull/1334:84,availability,Error,Error,84,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:106,availability,error,error,106,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:195,availability,error,error,195,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:259,availability,down,downloading,259,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:84,performance,Error,Error,84,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:106,performance,error,error,106,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:195,performance,error,error,195,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:84,safety,Error,Error,84,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:106,safety,error,error,106,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:195,safety,error,error,195,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:7,usability,User,User-Agent,7,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:84,usability,Error,Error,84,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:106,usability,error,error,106,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:195,usability,error,error,195,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:325,usability,User,User-Agent,325,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:450,usability,User,User-agent,450,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:483,usability,user,user,483,"adding User-Agent changer into _download.py; Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running. `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/issues/1335:679,deployability,Version,Versions,679,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:712,deployability,log,logging,712,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:679,integrability,Version,Versions,679,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:654,interoperability,share,sharey,654,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:679,modifiability,Version,Versions,679,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:615,safety,test,test,615,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:712,safety,log,logging,712,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:712,security,log,logging,712,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:615,testability,test,test,615,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:712,testability,log,logging,712,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:108,usability,clear,clear,108,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:247,usability,user,user-images,247,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:352,usability,minim,minimal,352,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:847,usability,learn,learn,847,"Recent changes in sc.tl.rank_genes_groups broke y-axis range in sc.pl.rank_genes_groups; <!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. sc.set_figure_params(dpi=72). adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'). sc.pl.rank_genes_groups(adata, sharey=False). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/pull/1337:153,testability,simpl,simplification,153,"Fix y-axis for rank_genes_groups; * Previously min and max were set by full range of scores, not just the ones being plotted. * Also did some minor code simplification. Fixes #1335. Still need to change reference plots",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/pull/1337:153,usability,simpl,simplification,153,"Fix y-axis for rank_genes_groups; * Previously min and max were set by full range of scores, not just the ones being plotted. * Also did some minor code simplification. Fixes #1335. Still need to change reference plots",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/issues/1338:104,availability,cluster,clustering,104,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2343,availability,Error,Error,2343,"6 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:104,deployability,cluster,clustering,104,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3195,deployability,modul,module,3195,"B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4736,deployability,modul,module,4736,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5517,deployability,Version,Versions,5517,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2570,energy efficiency,core,core,2570," C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3286,energy efficiency,core,core,3286,"53 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3448,energy efficiency,core,core,3448,". Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4111,energy efficiency,core,core,4111,"eption occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4827,energy efficiency,core,core,4827,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4989,energy efficiency,core,core,4989,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5517,integrability,Version,Versions,5517,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2554,modifiability,pac,packages,2554,"119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3195,modifiability,modul,module,3195,"B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3270,modifiability,pac,packages,3270,"551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3432,modifiability,pac,packages,3432,"ta.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.ha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4095,modifiability,pac,packages,4095,"n, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4736,modifiability,modul,module,4736,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4811,modifiability,pac,packages,4811,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4973,modifiability,pac,packages,4973,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5517,modifiability,Version,Versions,5517,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2343,performance,Error,Error,2343,"6 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:776,safety,test,tests,776,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:782,safety,test,test,782,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2343,safety,Error,Error,2343,"6 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3091,safety,except,exception,3091,"7 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3110,safety,except,exception,3110,"SG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3195,safety,modul,module,3195,"B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4632,safety,except,exception,4632," File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4651,safety,except,exception,4651,"/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4736,safety,modul,module,4736,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2893,security,hash,hashtable,2893,"7672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3006,security,hash,hashtable,3006,"19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3797,security,hash,hashtable,3797,"Engine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3910,security,hash,hashtable,3910,"Table.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/U",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4434,security,hash,hashtable,4434,"s/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4547,security,hash,hashtable,4547,". File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 annda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5338,security,hash,hashtable,5338,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5451,security,hash,hashtable,5451,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:277,testability,simpl,simply,277,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:776,testability,test,tests,776,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:782,testability,test,test,782,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2452,testability,Trace,Traceback,2452,"e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3131,testability,Trace,Traceback,3131,"e 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3993,testability,Trace,Traceback,3993,"s._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4672,testability,Trace,Traceback,4672,", in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:277,usability,simpl,simply,277,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:443,usability,tool,tools,443,"3k PBMC tutorial misses important marker genes; I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of? ```. >>> import anndata. >>> adata = anndata.read('./src/tests/test.h5ad'). >>> adata. AnnData object with n_obs  n_vars = 2638  1838. obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'. var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'. >>> adata.var. gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names. TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2343,usability,Error,Error,2343,"6 -3.672069e-10 0.424481 TNFRSF4. CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L. ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2495,usability,User,Users,2495,"915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C. C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86. RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1. ... ... ... ... ... ... ... ... ... ... ... ... ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG. SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3. SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1. S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B. PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3211,usability,User,Users,3211,"00160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3373,usability,User,Users,3373,"if applicable, else delete the block): -->. ```pytb. >>> adata.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4036,usability,User,Users,4036,"tem. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4752,usability,User,Users,4752,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4914,usability,User,Users,4914,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5622,usability,learn,learn,5622,"dex.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. >>> adata.raw.var['CD14']. Traceback (most recent call last):. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc. return self._engine.get_loc(key). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__. indexer = self.columns.get_loc(key). File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc. return self._engine.get_loc(self._maybe_cast_indexer(key)). File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item. File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item. KeyError: 'CD14'. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/pull/1339:9,deployability,releas,release,9,Clean up release notes for v1.6.0;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1339
https://github.com/scverse/scanpy/issues/1340:133,modifiability,paramet,parameters,133,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:410,modifiability,pac,package,410,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:553,modifiability,variab,variables,553,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:215,testability,simpl,simple,215,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:207,usability,tool,tool,207,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:215,usability,simpl,simple,215,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:231,usability,tool,tool,231,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:279,usability,tool,tools,279,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:379,usability,tool,tools,379,"Uns categorical colour maping as a dictionary ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1341:411,availability,error,error,411,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:549,availability,error,errors,549,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2044,availability,state,state,2044,"Data\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2208,availability,state,state,2208,"x, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquir",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2565,availability,state,state,2565,"Data\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2585,availability,state,state,2585,"\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2708,availability,state,state,2708,"locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2906,availability,state,state,2906,"um\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2997,availability,state,state,2997,"lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3831,availability,state,state,3831,"aconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3918,availability,state,state,3918,"isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3940,availability,state,state,3940,"CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4052,availability,state,state,4052,"\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4744,availability,error,error,4744,"\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4882,availability,error,error,4882,"-> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4907,availability,error,error,4907,"un_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_me",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6777,availability,error,errors,6777,"d(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7359,availability,error,errors,7359,"tch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7883,availability,error,errors,7883,"ata\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8206,availability,error,error,8206,"dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8761,availability,state,state,8761,"mpile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patche",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8789,availability,state,state,8789,"urn_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9057,availability,state,state,9057,"). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9261,availability,state,state,9261,"not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9375,availability,avail,available,9375,"y in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. --->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9555,availability,state,state,9555," return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9575,availability,state,state,9575," locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9709,availability,state,state,9709,"mpiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9980,availability,state,state,9980,"mba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10122,availability,state,state,10122,"3 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations sh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11251,availability,state,state,11251,"ompiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11344,availability,state,state,11344,", **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11366,availability,state,state,11366,"self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11412,availability,state,state,11412,"3 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11432,availability,state,state,11432,"mpile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11544,availability,state,state,11544,"ass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_bloc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13180,availability,error,errors,13180,"tion_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13798,availability,error,error,13798,"). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13823,availability,error,error,13823,"ock). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:500,deployability,Continu,Continuum,500,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:674,deployability,Continu,Continuum,674,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:882,deployability,Continu,Continuum,882,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1058,deployability,Continu,Continuum,1058,"e=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 ret",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1322,deployability,Continu,Continuum,1322," I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1579,deployability,Continu,Continuum,1579,", *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1793,deployability,pipelin,pipeline,1793,"errcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exceptio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1902,deployability,Continu,Continuum,1902,"ite-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2109,deployability,Continu,Continuum,2109,"or_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2294,deployability,Continu,Continuum,2294,"ally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2450,deployability,Continu,Continuum,2450,"pingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2624,deployability,Continu,Continuum,2624,"ompiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2822,deployability,Continu,Continuum,2822,"r, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3032,deployability,Continu,Continuum,3032,"s(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3243,deployability,Continu,Continuum,3243,"n self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Mate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3513,deployability,Continu,Continuum,3513,"pile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_as",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3748,deployability,Continu,Continuum,3748,"rror(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3874,deployability,pipelin,pipeline,3874,"r_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR pars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3969,deployability,Continu,Continuum,3969,"unPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4161,deployability,Continu,Continuum,4161,"turn func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4261,deployability,Modul,Module,4261,"ib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4309,deployability,modul,module,4309,"y in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4340,deployability,Continu,Continuum,4340,"nternal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_q",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4583,deployability,Continu,Continuum,4583,"heck(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4638,deployability,modul,module,4638,"ler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4802,deployability,Fail,Failed,4802,"sses.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4826,deployability,pipelin,pipeline,4826," state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5167,deployability,modul,module,5167,"\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5265,deployability,Continu,Continuum,5265,"-> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5558,deployability,Continu,Continuum,5558,"me. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\C",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5979,deployability,Continu,Continuum,5979,"q i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6249,deployability,Continu,Continuum,6249,"Data\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6562,deployability,Continu,Continuum,6562,"\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6896,deployability,Continu,Continuum,6896,"16 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7160,deployability,Continu,Continuum,7160,"mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7433,deployability,Continu,Continuum,7433,"RACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, retur",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7695,deployability,Continu,Continuum,7695,"yval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7957,deployability,Continu,Continuum,7957,"in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8321,deployability,Continu,Continuum,8321,"e(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8491,deployability,pipelin,pipeline,8491," in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8603,deployability,pipelin,pipeline,8603,"lf._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8661,deployability,Continu,Continuum,8661,"turn retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8943,deployability,Continu,Continuum,8943,"ta\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9167,deployability,Continu,Continuum,9167,"peline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9385,deployability,pipelin,pipelines,9385,"le_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9424,deployability,Continu,Continuum,9424,"gs, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acqu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9625,deployability,Continu,Continuum,9625,"). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9896,deployability,Continu,Continuum,9896,"d=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10204,deployability,Continu,Continuum,10204,"a\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10468,deployability,Continu,Continuum,10468,"compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10857,deployability,Continu,Continuum,10857,"_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.gen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11168,deployability,Continu,Continuum,11168,"pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11300,deployability,pipelin,pipeline,11300,"kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11461,deployability,Continu,Continuum,11461,"l\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11770,deployability,Continu,Continuum,11770,"e_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12033,deployability,Continu,Continuum,12033,"ate). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12311,deployability,Continu,Continuum,12311,"2 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12441,deployability,build,builder,12441,"~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12571,deployability,Continu,Continuum,12571,"er(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12854,deployability,Continu,Continuum,12854,"generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13131,deployability,Continu,Continuum,13131,"1 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13450,deployability,Continu,Continuum,13450,"on_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13654,deployability,Fail,Failed,13654,"k). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13678,deployability,pipelin,pipeline,13678,"ntext('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13718,deployability,Fail,Failed,13718,"t=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13742,deployability,pipelin,pipeline,13742,", errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Conti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13955,deployability,Continu,Continuum,13955,"ry:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14378,deployability,Continu,Continuum,14378,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14499,deployability,Continu,Continuum,14499,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14620,deployability,Continu,Continuum,14620,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14741,deployability,Continu,Continuum,14741,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14862,deployability,Continu,Continuum,14862,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15002,deployability,Continu,Continuum,15002,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15094,deployability,version,version,15094,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:544,energy efficiency,core,core,544,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:718,energy efficiency,core,core,718,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:926,energy efficiency,core,core,926,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1623,energy efficiency,core,core,1623,"ld. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\C",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1946,energy efficiency,core,core,1946,"wer_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, Compi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2153,energy efficiency,core,core,2153,"lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2338,energy efficiency,core,core,2338,"3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2494,energy efficiency,core,core,2494,"iases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2668,energy efficiency,core,core,2668,"tctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2866,energy efficiency,core,core,2866,"fted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out int",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3076,energy efficiency,core,core,3076,"le_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3287,energy efficiency,core,core,3287,"ocal\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3557,energy efficiency,core,core,3557,"(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_modul",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3792,energy efficiency,core,core,3792,"tion. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. Runtim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4013,energy efficiency,core,core,4013," ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. Du",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4205,energy efficiency,core,core,4205,"quire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4384,energy efficiency,core,core,4384," pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6293,energy efficiency,core,core,6293,"ackages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6606,energy efficiency,core,core,6606,"ocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6940,energy efficiency,core,core,6940,"n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7204,energy efficiency,core,core,7204,"np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7477,energy efficiency,core,core,7477,"-> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7739,energy efficiency,core,core,7739,"ompile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8001,energy efficiency,core,core,8001,". 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8365,energy efficiency,core,core,8365,"orceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerErr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8705,energy efficiency,core,core,8705,"aconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8987,energy efficiency,core,core,8987,"kages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9211,energy efficiency,core,core,9211,"f object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9468,energy efficiency,core,core,9468,"pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9669,energy efficiency,core,core,9669,"anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9940,energy efficiency,core,core,9940,"\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10248,energy efficiency,core,core,10248,". 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10512,energy efficiency,core,core,10512,"es = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\type",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10901,energy efficiency,core,core,10901,"um\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11212,energy efficiency,core,core,11212,"anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11505,energy efficiency,core,core,11505,"umba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11814,energy efficiency,core,core,11814,"alizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12077,energy efficiency,core,core,12077,":. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *un",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12355,energy efficiency,core,core,12355,"owered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12615,energy efficiency,core,core,12615,"69 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13175,energy efficiency,core,core,13175,"t_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13340,energy efficiency,core,core,13340,"ckages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13494,energy efficiency,core,core,13494,"lock). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Loc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:417,integrability,messag,message,417,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1793,integrability,pipelin,pipeline,1793,"errcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exceptio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2044,integrability,state,state,2044,"Data\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2208,integrability,state,state,2208,"x, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquir",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2565,integrability,state,state,2565,"Data\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2585,integrability,state,state,2585,"\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2708,integrability,state,state,2708,"locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2906,integrability,state,state,2906,"um\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2997,integrability,state,state,2997,"lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3831,integrability,state,state,3831,"aconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3874,integrability,pipelin,pipeline,3874,"r_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR pars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3918,integrability,state,state,3918,"isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3940,integrability,state,state,3940,"CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4052,integrability,state,state,4052,"\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4826,integrability,pipelin,pipeline,4826," state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8491,integrability,pipelin,pipeline,8491," in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8603,integrability,pipelin,pipeline,8603,"lf._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8761,integrability,state,state,8761,"mpile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patche",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8789,integrability,state,state,8789,"urn_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9057,integrability,state,state,9057,"). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9261,integrability,state,state,9261,"not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9385,integrability,pipelin,pipelines,9385,"le_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9555,integrability,state,state,9555," return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9575,integrability,state,state,9575," locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9709,integrability,state,state,9709,"mpiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9980,integrability,state,state,9980,"mba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10122,integrability,state,state,10122,"3 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations sh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11251,integrability,state,state,11251,"ompiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11300,integrability,pipelin,pipeline,11300,"kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11344,integrability,state,state,11344,", **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11366,integrability,state,state,11366,"self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11412,integrability,state,state,11412,"3 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11432,integrability,state,state,11432,"mpile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11544,integrability,state,state,11544,"ass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_bloc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13678,integrability,pipelin,pipeline,13678,"ntext('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13742,integrability,pipelin,pipeline,13742,", errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Conti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15094,integrability,version,version,15094,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:417,interoperability,messag,message,417,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4630,interoperability,bind,binding,4630,", compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4756,interoperability,format,format,4756,"naconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:529,modifiability,pac,packages,529,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:703,modifiability,pac,packages,703,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:911,modifiability,pac,packages,911,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1087,modifiability,pac,packages,1087,"clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1351,modifiability,pac,packages,1351,"etrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1608,modifiability,pac,packages,1608,". --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\Ap",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1931,modifiability,pac,packages,1931,"ring.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2138,modifiability,pac,packages,2138,"for_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2323,modifiability,pac,packages,2323,"nuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2479,modifiability,pac,packages,2479,"ocals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2653,modifiability,pac,packages,2653,"ingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2851,modifiability,pac,packages,2851,"ifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3061,modifiability,pac,packages,3061,"n self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3272,modifiability,pac,packages,3272,". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3542,modifiability,pac,packages,3542,"-> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3777,modifiability,pac,packages,3777,"patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 retur",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3998,modifiability,pac,packages,3998,"). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4190,modifiability,pac,packages,4190,"33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4261,modifiability,Modul,Module,4261,"ib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4309,modifiability,modul,module,4309,"y in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4369,modifiability,pac,packages,4369,"pleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4612,modifiability,pac,packages,4612,"263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4630,modifiability,bind,binding,4630,", compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4638,modifiability,modul,module,4638,"ler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5167,modifiability,modul,module,5167,"\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5294,modifiability,pac,packages,5294,"odule(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5405,modifiability,layer,layer,5405,"r_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5587,modifiability,pac,packages,5587,"m\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5690,modifiability,layer,layer,5690,"ose(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6008,modifiability,pac,packages,6008," During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6278,modifiability,pac,packages,6278,"a3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 80",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6591,modifiability,pac,packages,6591,"\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6925,modifiability,pac,packages,6925,"ype}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7189,modifiability,pac,packages,7189,"ay(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7462,modifiability,pac,packages,7462," reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, libra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7724,modifiability,pac,packages,7724,"return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7986,modifiability,pac,packages,7986,"gs, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\cor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8350,modifiability,pac,packages,8350,"cept errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 rais",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8690,modifiability,pac,packages,8690,"\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8972,modifiability,pac,packages,8972,"\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9196,modifiability,pac,packages,9196,"yping error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9453,modifiability,pac,packages,9453,"ls, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\App",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9654,modifiability,pac,packages,9654,"al\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9925,modifiability,pac,packages,9925,"AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10233,modifiability,pac,packages,10233,"le_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10497,modifiability,pac,packages,10497,"(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10886,modifiability,pac,packages,10886,"Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11197,modifiability,pac,packages,11197,"al\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11490,modifiability,pac,packages,11490,"te-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11799,modifiability,pac,packages,11799,"k(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12062,modifiability,pac,packages,12062,"(True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress Stop",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12340,modifiability,pac,packages,12340,"state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12600,modifiability,pac,packages,12600,"c, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13160,modifiability,pac,packages,13160,"2 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13479,modifiability,pac,packages,13479,"lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13984,modifiability,pac,packages,13984,"type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14407,modifiability,pac,packages,14407,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14528,modifiability,pac,packages,14528,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14649,modifiability,pac,packages,14649,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14770,modifiability,pac,packages,14770,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14891,modifiability,pac,packages,14891,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15031,modifiability,pac,packages,15031,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15086,modifiability,pac,package,15086,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15094,modifiability,version,version,15094,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:411,performance,error,error,411,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:549,performance,error,errors,549,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4744,performance,error,error,4744,"\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4882,performance,error,error,4882,"-> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4907,performance,error,error,4907,"un_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_me",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5437,performance,parallel,parallel,5437," = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRAC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5725,performance,parallel,parallel,5725,"LVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6777,performance,error,errors,6777,"d(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7359,performance,error,errors,7359,"tch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7883,performance,error,errors,7883,"ata\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8206,performance,error,error,8206,"dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13180,performance,error,errors,13180,"tion_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13798,performance,error,error,13798,"). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13823,performance,error,error,13823,"ock). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4802,reliability,Fail,Failed,4802,"sses.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9375,reliability,availab,available,9375,"y in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. --->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13654,reliability,Fail,Failed,13654,"k). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13718,reliability,Fail,Failed,13718,"t=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14194,reliability,pra,prange,14194,"error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:411,safety,error,error,411,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:549,safety,error,errors,549,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:633,safety,except,except,633,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4261,safety,Modul,Module,4261,"ib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4309,safety,modul,module,4309,"y in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4638,safety,modul,module,4638,"ler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4744,safety,error,error,4744,"\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4882,safety,error,error,4882,"-> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4907,safety,error,error,4907,"un_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_me",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5042,safety,except,exception,5042,"elf, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5061,safety,except,exception,5061,"tadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_propor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5140,safety,input,input-,5140,". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5167,safety,modul,module,5167,"\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6770,safety,except,except,6770,"= sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6777,safety,error,errors,6777,"d(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7352,safety,except,except,7352,"32 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7359,safety,error,errors,7359,"tch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7876,safety,except,except,7876," ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7883,safety,error,errors,7883,"ata\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8206,safety,error,error,8206,"dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9375,safety,avail,available,9375,"y in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. --->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13017,safety,except,except,13017,"ppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13099,safety,except,exception,13099,"ormal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source eli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13180,safety,error,errors,13180,"tion_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13798,safety,error,error,13798,"). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13823,safety,error,error,13823,"ock). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6528,security,sign,signature,6528,"be_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9375,security,availab,available,9375,"y in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. --->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11383,security,sign,signature,11383,"rn func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_functio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11402,security,sign,signature,11402,"args). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:449,testability,Trace,Traceback,449,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2196,testability,assert,assert,2196,"ap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 348 FixupArgs().run_pass(self.state). --> 349 return self._compile_ir(). 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self). 407 assert self.state.func_ir is not None. --> 408 return self._compile_core(). 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3370,testability,Simpl,SimpleTimer,3370,"). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3464,testability,Simpl,SimpleTimer,3464,"lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4674,testability,context,context,4674,"ompiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5096,testability,Trace,Traceback,5096,"er(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9045,testability,assert,assert,9045," return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if is",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10657,testability,Simpl,SimpleTimer,10657,"numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10751,testability,Simpl,SimpleTimer,10751," patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12878,testability,context,contextlib,12878," 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12923,testability,trace,traceback,12923,"_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13001,testability,trace,traceback,13001,"wer(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\prepro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:91,usability,clear,clear,91,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:411,usability,error,error,411,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:549,usability,error,errors,549,"scanpy sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True); <!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py. adata = sc.read_visium(. './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',. genome=None, library_id=None, load_images=True,. ). ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb. RuntimeError Traceback (most recent call last). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 744 try:. --> 745 yield. 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst). 485 if isinstance(inst, _class):. --> 486 func(self, inst). 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor). 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 240 bool(alias_map), index_var_typ, parfor.races). 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1326 flags,. -> 1327 locals). 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 667 lifted_from=lifted_from). 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3370,usability,Simpl,SimpleTimer,3370,"). 380 if is_final_pipeline:. --> 381 raise e. 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3464,usability,Simpl,SimpleTimer,3464,"lib\site-packages\numba\core\compiler.py in _compile_core(self). 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4691,usability,close,close,4691,"265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4744,usability,error,error,4744,"\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4882,usability,error,error,4882,"-> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4907,usability,error,error,4907,"un_pass(state). 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_me",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:5140,usability,input,input-,5140,". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 216 # Materialize LLVM Module. --> 217 self.library.add_ir_module(self.module). 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module). 205 ir = cgutils.normalize_ir_text(str(ir_module)). --> 206 ll_module = ll.parse_assembly(ir). 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 24 mod.close(). ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-10-a83dc5279093> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 294 inplace=inplace,. 295 X=X,. --> 296 log1p=log1p,. 297 ). 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 112 if percent_top:. 113 percent_top = sorted(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6777,usability,error,errors,6777,"d(percent_top). --> 114 proportions = top_segment_proportions(X, percent_top). 115 for i, n in enumerate(percent_top):. 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 377 mtx = csr_matrix(mtx). 378 return top_segment_proportions_sparse_csr(. --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 380 ). 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7359,usability,error,errors,7359,"tch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7588,usability,statu,status,7588,"packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7652,usability,statu,status,7652,"gs, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7883,usability,error,errors,7883,"ata\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8206,usability,error,error,8206,"dispatcher.py in compile(self, sig). 806 self._cache_misses[sig] += 1. 807 try:. --> 808 cres = self._compiler.compile(args, return_type). 809 except errors.ForceLiteralArg as e:. 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type). 76 . 77 def compile(self, args, return_type):. ---> 78 status, retval = self._compile_cached(args, return_type). 79 if status:. 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type). 90 . 91 try:. ---> 92 retval = self._compile_core(args, return_type). 93 except errors.TypingError as e:. 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type). 108 args=args, return_type=return_type,. 109 flags=flags, locals=self.locals,. --> 110 pipeline_class=self.pipeline_class). 111 # Check typing error if object mode is used. 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9267,usability,statu,status,9267,"ne and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 601 pipeline = pipeline_class(typingctx, targetctx, library,. 602 args, return_type, flags, locals). --> 603 return pipeline.compile_extra(func). 604 . 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func). 337 self.state.lifted = (). 338 self.state.lifted_from = None. --> 339 return self._compile_bytecode(). 340 . 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self). 399 """""". 400 assert self.state.func_ir is None. --> 401 return self._compile_core(). 402 . 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 379 self.state.status.fail_reason = e. 380 if is_final_pipeline:. --> 381 raise e. 382 else:. 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self). 370 res = None. 371 try:. --> 372 pm.run(self.state). 373 if self.state.cr is not None:. 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10657,usability,Simpl,SimpleTimer,10657,"numba\core\compiler_machinery.py in run(self, state). 339 (self.pipeline_name, pass_desc). 340 patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10751,usability,Simpl,SimpleTimer,10751," patched_exception = self._patch_error(msg, e). --> 341 raise patched_exception. 342 . 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state). 330 pass_inst = _pass_registry.get(pss).pass_inst. 331 if isinstance(pass_inst, CompilerPass):. --> 332 self._runPass(idx, pass_inst, state). 333 else:. 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state). 289 mutated |= check(pss.run_initialization, internal_state). 290 with SimpleTimer() as pass_time:. --> 291 mutated |= check(pss.run_pass, internal_state). 292 with SimpleTimer() as finalize_time:. 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state). 262 . 263 def check(func, compiler_state):. --> 264 mangled = func(compiler_state). 265 if mangled not in (True, False):. 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 440 . 441 # TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:12268,usability,Close,Close,12268,"TODO: Pull this out into the pipeline. --> 442 NativeLowering().run_pass(state). 443 lowered = state['cr']. 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state). 368 lower = lowering.Lower(targetctx, library, fndesc, interp,. 369 metadata=metadata). --> 370 lower.lower(). 371 if not flags.no_cpython_wrapper:. 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self). 177 if self.generator_info is None:. 178 self.genlower = None. --> 179 self.lower_normal_function(self.fndesc). 180 else:. 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13024,usability,Stop,StopIteration,13024,"l\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13062,usability,Stop,StopIteration,13062,"s\numba\core\lowering.py in lower_normal_function(self, fndesc). 231 # Init argument values. 232 self.extract_function_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13180,usability,error,errors,13180,"tion_arguments(). --> 233 entry_block_tail = self.lower_function_body(). 234 . 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self). 257 bb = self.blkmap[offset]. 258 self.builder.position_at_end(bb). --> 259 self.lower_block(block). 260 self.post_lower(). 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block). 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 272 loc=self.loc, errcls_=defaulterrcls):. --> 273 self.lower_inst(inst). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13798,usability,error,error,13798,"). 274 self.post_block(block). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13823,usability,error,error,13823,"ock). 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs). 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14352,usability,User,Users,14352,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14473,usability,User,Users,14473,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14594,usability,User,Users,14594,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14715,usability,User,Users,14715,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14836,usability,User,Users,14836,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:14976,usability,User,Users,14976,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15209,usability,learn,learn,15209,"s, kwargs)). 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 752 reraise(type(newerr), newerr, tb). 753 . 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb). 79 if value.__traceback__ is not tb:. 80 raise value.with_traceback(tb). ---> 81 raise value. 82 . 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'. %"".2748"" = icmp eq i32 %"".2746"", %"".2747"". ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412). ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/pull/1342:211,deployability,log,log,211,"fix missing yticklabels; PR to solve #1321 . ```PYTHON. marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True,log=False).style(yticklabels=True,row_palette='muted').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/88898994-cbb25c00-d24d-11ea-8de2-5768752c9939.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:211,safety,log,log,211,"fix missing yticklabels; PR to solve #1321 . ```PYTHON. marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True,log=False).style(yticklabels=True,row_palette='muted').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/88898994-cbb25c00-d24d-11ea-8de2-5768752c9939.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:211,security,log,log,211,"fix missing yticklabels; PR to solve #1321 . ```PYTHON. marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True,log=False).style(yticklabels=True,row_palette='muted').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/88898994-cbb25c00-d24d-11ea-8de2-5768752c9939.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:211,testability,log,log,211,"fix missing yticklabels; PR to solve #1321 . ```PYTHON. marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True,log=False).style(yticklabels=True,row_palette='muted').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/88898994-cbb25c00-d24d-11ea-8de2-5768752c9939.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1342:296,usability,user,user-images,296,"fix missing yticklabels; PR to solve #1321 . ```PYTHON. marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True,log=False).style(yticklabels=True,row_palette='muted').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/88898994-cbb25c00-d24d-11ea-8de2-5768752c9939.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1343:31,deployability,updat,updated,31,"`print_versions` outputs more, updated GH issue template; See #978 and #1341",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:31,safety,updat,updated,31,"`print_versions` outputs more, updated GH issue template; See #978 and #1341",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1343:31,security,updat,updated,31,"`print_versions` outputs more, updated GH issue template; See #978 and #1341",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1343
https://github.com/scverse/scanpy/pull/1344:0,availability,Down,Download,0,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:43,availability,down,downloads,43,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:86,availability,down,downloads,86,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:173,availability,state,state,173,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:466,availability,down,download,466,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:565,availability,down,downloaded,565,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:610,deployability,updat,updated,610,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:173,integrability,state,state,173,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:427,integrability,coupl,couple,427,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:427,modifiability,coupl,couple,427,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:531,safety,test,test,531,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:601,safety,test,test,601,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:610,safety,updat,updated,610,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:157,security,modif,modifies,157,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:371,security,modif,modification,371,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:610,security,updat,updated,610,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:427,testability,coupl,couple,427,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:531,testability,test,test,531,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:601,testability,test,test,601,"Download header; As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented. The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore. * One of the downloaded datasets changed, so the test got updated. * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/issues/1346:161,integrability,sub,subsequent,161,"Reproducibility of regress_out() results; Hi. I encountered a problem with **regress_out** function. The returned X matrix for the same input anndata varies for subsequent iterations. The function doesn't have any parameter such as ""random_state"" or ""seed"". Have you noticed this problem before? Is there a way to make this function more stable and return reproducibile results? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1346:214,modifiability,paramet,parameter,214,"Reproducibility of regress_out() results; Hi. I encountered a problem with **regress_out** function. The returned X matrix for the same input anndata varies for subsequent iterations. The function doesn't have any parameter such as ""random_state"" or ""seed"". Have you noticed this problem before? Is there a way to make this function more stable and return reproducibile results? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1346:197,reliability,doe,doesn,197,"Reproducibility of regress_out() results; Hi. I encountered a problem with **regress_out** function. The returned X matrix for the same input anndata varies for subsequent iterations. The function doesn't have any parameter such as ""random_state"" or ""seed"". Have you noticed this problem before? Is there a way to make this function more stable and return reproducibile results? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1346:136,safety,input,input,136,"Reproducibility of regress_out() results; Hi. I encountered a problem with **regress_out** function. The returned X matrix for the same input anndata varies for subsequent iterations. The function doesn't have any parameter such as ""random_state"" or ""seed"". Have you noticed this problem before? Is there a way to make this function more stable and return reproducibile results? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1346:136,usability,input,input,136,"Reproducibility of regress_out() results; Hi. I encountered a problem with **regress_out** function. The returned X matrix for the same input anndata varies for subsequent iterations. The function doesn't have any parameter such as ""random_state"" or ""seed"". Have you noticed this problem before? Is there a way to make this function more stable and return reproducibile results? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1346
https://github.com/scverse/scanpy/issues/1347:68,deployability,log,logo,68,"explain title please; Hi,. I was always a bit perplexed by Scanpy's logo (some sort of shrimp? ant?), since the name doesn't make me think of an animal. Would you mind explaining, @falexwolf? Is it, maybe, a pun on ""scampi""? Because that would explain it. thanks,. Niko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:117,reliability,doe,doesn,117,"explain title please; Hi,. I was always a bit perplexed by Scanpy's logo (some sort of shrimp? ant?), since the name doesn't make me think of an animal. Would you mind explaining, @falexwolf? Is it, maybe, a pun on ""scampi""? Because that would explain it. thanks,. Niko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:68,safety,log,logo,68,"explain title please; Hi,. I was always a bit perplexed by Scanpy's logo (some sort of shrimp? ant?), since the name doesn't make me think of an animal. Would you mind explaining, @falexwolf? Is it, maybe, a pun on ""scampi""? Because that would explain it. thanks,. Niko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:68,security,log,logo,68,"explain title please; Hi,. I was always a bit perplexed by Scanpy's logo (some sort of shrimp? ant?), since the name doesn't make me think of an animal. Would you mind explaining, @falexwolf? Is it, maybe, a pun on ""scampi""? Because that would explain it. thanks,. Niko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1347:68,testability,log,logo,68,"explain title please; Hi,. I was always a bit perplexed by Scanpy's logo (some sort of shrimp? ant?), since the name doesn't make me think of an animal. Would you mind explaining, @falexwolf? Is it, maybe, a pun on ""scampi""? Because that would explain it. thanks,. Niko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1351:151,availability,error,error,151,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:258,availability,error,error,258,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:531,availability,Error,Error,531,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2046,availability,error,error,2046,"group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2076,availability,error,error,2076,"niconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/mini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3275,availability,error,error,3275,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3391,availability,error,error,3391,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1917,deployability,fail,failed,1917,"data/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 position",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2372,deployability,modul,module,2372,"r(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3484,deployability,Version,Versions,3484,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:72,energy efficiency,load,load,72,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1369,integrability,wrap,wrapper,1369,"e dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1425,integrability,wrap,wrapper,1425,"AM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1682,integrability,wrap,wrapper,1682,"rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1738,integrability,wrap,wrapper,1738,"in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2052,integrability,messag,message,2052,"to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledisp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2141,integrability,sub,sub-read,2141,"rse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2883,integrability,wrap,wrapper,2883,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3484,integrability,Version,Versions,3484,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:359,interoperability,specif,specific,359,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1369,interoperability,wrapper,wrapper,1369,"e dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1425,interoperability,wrapper,wrapper,1425,"AM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1682,interoperability,wrapper,wrapper,1682,"rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1738,interoperability,wrapper,wrapper,1738,"in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2052,interoperability,messag,message,2052,"to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledisp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2883,interoperability,wrapper,wrapper,2883,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:712,modifiability,pac,packages,712,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:908,modifiability,pac,packages,908,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1119,modifiability,pac,packages,1119,"Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1480,modifiability,pac,packages,1480," using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2372,modifiability,modul,module,2372,"r(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2583,modifiability,pac,packages,2583,"pace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 sciki",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3117,modifiability,pac,packages,3117,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3484,modifiability,Version,Versions,3484,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:72,performance,load,load,72,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:151,performance,error,error,151,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:190,performance,time,times,190,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:212,performance,time,times,212,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:258,performance,error,error,258,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:392,performance,time,times,392,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:531,performance,Error,Error,531,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1925,performance,time,time,1925,"o/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2046,performance,error,error,2046,"group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2076,performance,error,error,2076,"niconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/mini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3275,performance,error,error,3275,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3391,performance,error,error,3391,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1917,reliability,fail,failed,1917,"data/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 position",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:151,safety,error,error,151,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:258,safety,error,error,258,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:531,safety,Error,Error,531,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:840,safety,except,except,840,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:847,safety,Except,Exception,847,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2046,safety,error,error,2046,"group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2063,safety,Input,Input,2063,"). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2076,safety,error,error,2076,"niconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/mini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2244,safety,except,exception,2244,"a = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2263,safety,except,exception,2263,"a""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2345,safety,input,input-,2345,"y._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2372,safety,modul,module,2372,"r(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3275,safety,error,error,3275,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3391,safety,error,error,3391,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:633,testability,Trace,Traceback,633,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2301,testability,Trace,Traceback,2301,"[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:151,usability,error,error,151,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:258,usability,error,error,258,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:531,usability,Error,Error,531,"sc.read_h5ad randomly produces AnnDataReadError/OSError; I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:. ```pytb. ---------------------------------------------------------------------------. OSError Traceback (most recent call last). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 try:. --> 156 return func(elem, *args, **kwargs). 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 505 if ""h5sparse_format"" in group.attrs: # Backwards compat. --> 506 return SparseDataset(group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_mat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2046,usability,error,error,2046,"group).to_memory(). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2063,usability,Input,Input,2063,"). 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2076,usability,error,error,2076,"niconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self). 370 mtx = format_class(self.shape, dtype=self.dtype). --> 371 mtx.data = self.group[""data""][...]. 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/mini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2345,usability,input,input-,2345,"y._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 572 fspace = selection.id. --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl). 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3275,usability,error,error,3275,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3391,usability,error,error,3391,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3589,usability,learn,learn,3589,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020. , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-14-faac769583f8> in <module>. 17 #while True:. 18 #try:. ---> 19 adatas.append(sc.read_h5ad(file)). 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])). 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 411 d[k] = read_dataframe(f[k]). 412 else: # Base case. --> 413 d[k] = read_attribute(f[k]). 414 . 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 else:. 161 parent = _get_parent(elem). --> 162 raise AnnDataReadError(. 163 f""Above error raised while reading key {elem.name!r} of "". 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions:. ```. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1352:1105,availability,down,down,1105,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1220,availability,consist,consistent,1220,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1409,deployability,integr,integrated,1409,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1090,energy efficiency,estimat,estimate,1090,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1409,integrability,integr,integrated,1409,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1409,interoperability,integr,integrated,1409,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:149,modifiability,paramet,parameters,149,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:426,modifiability,pac,package,426,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1330,modifiability,paramet,parameters,1330,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1409,modifiability,integr,integrated,1409,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1409,reliability,integr,integrated,1409,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:777,security,control,control-treat,777,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1409,security,integr,integrated,1409,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:231,testability,simpl,simple,231,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:777,testability,control,control-treat,777,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1409,testability,integr,integrated,1409,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:223,usability,tool,tool,223,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:231,usability,simpl,simple,231,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:247,usability,tool,tool,247,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:295,usability,tool,tools,295,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:395,usability,tool,tools,395,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:537,usability,visual,visualize,537,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:617,usability,user,user-images,617,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:865,usability,user,user-images,865,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:975,usability,user,user-images,975,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1220,usability,consist,consistent,1220,"Are there paramters fixing range of colorbar in scanpy.pl.umap?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy? Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1353:29,usability,visual,visualization,29,"How to change font in UMAP's visualization result?; Hi,. I'd like to directly change the font in UMAP's visualization result, e.g., by setting the font to Arial or Helvetica. I have no ideas about how to do this, could you please help me with this? Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1353
https://github.com/scverse/scanpy/issues/1353:104,usability,visual,visualization,104,"How to change font in UMAP's visualization result?; Hi,. I'd like to directly change the font in UMAP's visualization result, e.g., by setting the font to Arial or Helvetica. I have no ideas about how to do this, could you please help me with this? Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1353
https://github.com/scverse/scanpy/issues/1353:230,usability,help,help,230,"How to change font in UMAP's visualization result?; Hi,. I'd like to directly change the font in UMAP's visualization result, e.g., by setting the font to Arial or Helvetica. I have no ideas about how to do this, could you please help me with this? Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1353
https://github.com/scverse/scanpy/issues/1354:35,availability,error,error,35,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:163,deployability,version,version,163,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:701,deployability,modul,module,701,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:1586,deployability,Version,Versions,1586,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:5,integrability,filter,filtering,5,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:163,integrability,version,version,163,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:1586,integrability,Version,Versions,1586,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:520,interoperability,format,format,520,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:163,modifiability,version,version,163,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:701,modifiability,modul,module,701,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:804,modifiability,pac,packages,804,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:1142,modifiability,pac,packages,1142,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:1586,modifiability,Version,Versions,1586,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:35,performance,error,error,35,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:35,safety,error,error,35,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:674,safety,input,input-,674,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:701,safety,modul,module,701,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:630,testability,Trace,Traceback,630,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:35,usability,error,error,35,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:123,usability,confirm,confirmed,123,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:206,usability,confirm,confirmed,206,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:273,usability,Minim,Minimal,273,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:674,usability,input,input-,674,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:1518,usability,support,supported,1518,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1354:1696,usability,learn,learn,1696,"Gene filtering using sparse matrix error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.filter_genes(adata, min_cells=10). # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'. # with 11965294 stored elements in Compressed Sparse Row format>. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-37-431c88656c87> in <module>. ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 216 filter_genes(adata.X, min_cells=min_cells,. 217 min_counts=min_counts, max_cells=max_cells,. --> 218 max_counts=max_counts)). 219 if not inplace:. 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy). 230 max_number = max_counts if max_cells is None else max_cells. 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None. --> 232 else X > 0, axis=0). 233 if issparse(X):. 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/issues/1355:1074,availability,sli,slika,1074,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:193,deployability,version,version,193,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:301,deployability,version,version,301,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:193,integrability,version,version,193,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:301,integrability,version,version,301,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:193,modifiability,version,version,193,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:301,modifiability,version,version,301,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:1074,reliability,sli,slika,1074,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:153,usability,confirm,confirmed,153,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:236,usability,confirm,confirmed,236,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/issues/1355:1089,usability,user,user-images,1089,"UMAP plotting can not properly colour np.nan values in categorical obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Scanpy version: 1.5.1. If np.nan values are present in obs column used for colouring `sc.pl.umap` they are coloured with the colour of the last non-nan category (see example below). This is very problematic as cells that are not annotated get the color of one of the categories. This is another reason why https://github.com/theislab/scanpy/issues/1340 is needed - there should be a default for nan (such as gray). I plotted an UMAP and coloured it by cell type (left). Then I replaced half of alpha cells' cell types (column pre_cell_type) with np.nan and plotted it again (right). Half of the alpha cells (previously coloured blue) are now coloured pink (colour of the last category, here named 'NA'). These cells should not be coloured pink - nan should have its own colour. ![slika](https://user-images.githubusercontent.com/47607471/89209123-fbe75b00-d5bd-11ea-9a46-6d3dd628cb31.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355
https://github.com/scverse/scanpy/pull/1356:1047,availability,down,down,1047,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:820,deployability,Updat,Update,820,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1140,deployability,continu,continuous,1140,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1158,deployability,updat,update,1158,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:883,integrability,wrap,wrap,883,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:91,safety,test,tests,91,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:820,safety,Updat,Update,820,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:952,safety,test,tests,952,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:999,safety,Test,Tests,999,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1158,safety,updat,update,1158,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:820,security,Updat,Update,820,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1158,security,updat,update,1158,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:91,testability,test,tests,91,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:941,testability,Regress,Regression,941,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:952,testability,test,tests,952,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:999,testability,Test,Tests,999,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:465,usability,user,user-images,465,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:723,usability,user,user-images,723,"Make missing values lightgray in scatterplots; Potentially fixes #1355. * Would still need tests/ further consideration. * Need to fix missing values not being plotted below present ones. Using this branch:. ```python. import scanpy as sc. import numpy as np. import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(). pbmc.obs[""louvain""].iloc[::2] = np.nan. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain""). ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python. with mpl.rc_context({""figure.dpi"": 150}):. sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])). ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well). - [x] Decide on adding arguments, and default values. - [x] Decide on whether continuous legend update happens in this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/issues/1357:0,deployability,Automat,Automate,0,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:133,deployability,releas,release,133,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:289,deployability,automat,automatic,289,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:299,deployability,build,build,299,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:604,deployability,automat,automatically,604,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:0,testability,Automat,Automate,0,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:289,testability,automat,automatic,289,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:580,testability,simpl,simple,580,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:604,testability,automat,automatically,604,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:74,usability,document,documentation,74,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:580,usability,simpl,simple,580,"Automate figure generation for docs; Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1358:67,deployability,build,builds,67,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:486,deployability,build,build,486,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:541,deployability,build,build,541,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:618,deployability,integr,integration,618,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:671,deployability,depend,depending,671,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:761,energy efficiency,core,cores,761,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:48,integrability,queue,queue,48,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:618,integrability,integr,integration,618,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:671,integrability,depend,depending,671,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:618,interoperability,integr,integration,618,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:618,modifiability,integr,integration,618,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:671,modifiability,depend,depending,671,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:48,performance,queue,queue,48,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:54,performance,time,times,54,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:215,performance,concurren,concurrent,215,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:262,performance,time,time,262,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:383,performance,concurren,concurrent,383,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:434,performance,concurren,concurrent,434,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:816,performance,time,time,816,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:618,reliability,integr,integration,618,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:510,safety,test,testing,510,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:654,safety,test,test,654,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:671,safety,depend,depending,671,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:771,safety,test,testing,771,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:618,security,integr,integration,618,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:510,testability,test,testing,510,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:618,testability,integr,integration,618,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:654,testability,test,test,654,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:671,testability,depend,depending,671,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:771,testability,test,testing,771,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:599,usability,navigat,navigate,599,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:824,usability,learn,learn,824,"Use Azure for CI?; We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs. * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks). * Output looks easy to navigate, has good integration with github. * We could test on windows (depending on how hard this is to set up). * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn. * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/pull/1359:161,integrability,transform,transform,161,Promote ns from machine int to int64.; As title. This should act as a workaround for Numba issue. https://github.com/numba/numba/issues/5955 where the parallel. transform compiler pass cannot handle different sized integers. in the lowering of an array shape.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359
https://github.com/scverse/scanpy/pull/1359:161,interoperability,transform,transform,161,Promote ns from machine int to int64.; As title. This should act as a workaround for Numba issue. https://github.com/numba/numba/issues/5955 where the parallel. transform compiler pass cannot handle different sized integers. in the lowering of an array shape.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359
https://github.com/scverse/scanpy/pull/1359:151,performance,parallel,parallel,151,Promote ns from machine int to int64.; As title. This should act as a workaround for Numba issue. https://github.com/numba/numba/issues/5955 where the parallel. transform compiler pass cannot handle different sized integers. in the lowering of an array shape.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1359
https://github.com/scverse/scanpy/issues/1361:44,deployability,scale,scale,44,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:348,deployability,scale,scaled,348,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:389,deployability,scale,scale,389,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:683,deployability,scale,scaled,683,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:44,energy efficiency,scale,scale,44,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:348,energy efficiency,scale,scaled,348,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:389,energy efficiency,scale,scale,389,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:683,energy efficiency,scale,scaled,683,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:44,modifiability,scal,scale,44,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:348,modifiability,scal,scaled,348,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:389,modifiability,scal,scale,389,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:683,modifiability,scal,scaled,683,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:726,modifiability,variab,variable,726,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:44,performance,scale,scale,44,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:348,performance,scale,scaled,348,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:389,performance,scale,scale,389,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/issues/1361:683,performance,scale,scaled,683,"Likely wrong % of cells in dotplot after pp.scale(); The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/pull/1362:448,availability,error,error,448,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:283,deployability,modul,module,283,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:432,deployability,build,build,432,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:283,modifiability,modul,module,283,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:448,performance,error,error,448,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:283,safety,modul,module,283,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:448,safety,error,error,448,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:373,usability,tool,tool,373,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/pull/1362:448,usability,error,error,448,"Starfish; `scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/issues/1363:143,modifiability,paramet,parameters,143,"umap axes rotated; Hello,. I am not sure if it is a bug or not. Is it possible that the umap plots can be rotated running scanpy with the same parameters? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363
https://github.com/scverse/scanpy/issues/1363:10,security,rotat,rotated,10,"umap axes rotated; Hello,. I am not sure if it is a bug or not. Is it possible that the umap plots can be rotated running scanpy with the same parameters? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363
https://github.com/scverse/scanpy/issues/1363:106,security,rotat,rotated,106,"umap axes rotated; Hello,. I am not sure if it is a bug or not. Is it possible that the umap plots can be rotated running scanpy with the same parameters? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1363
https://github.com/scverse/scanpy/issues/1364:621,availability,Incid,Incidentally,621,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:32,deployability,log,log,32,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:173,deployability,version,version,173,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:496,deployability,log,log,496,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:930,deployability,log,log,930,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1006,deployability,depend,depend,1006,"ding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1169,deployability,log,log-counts,1169,"ersion of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1213,deployability,log,log-mean,1213,"onfirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1285,deployability,log,log-transformation,1285,"ug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2156,deployability,Version,Versions,2156,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2300,deployability,log,logging,2300,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:856,energy efficiency,profil,profiles,856,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:36,integrability,transform,transformation,36,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:173,integrability,version,version,173,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:500,integrability,transform,transformation,500,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:935,integrability,transform,transformation,935,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1006,integrability,depend,depend,1006,"ding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1289,integrability,transform,transformation,1289," in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2156,integrability,Version,Versions,2156,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:36,interoperability,transform,transformation,36,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:500,interoperability,transform,transformation,500,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:935,interoperability,transform,transformation,935,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1289,interoperability,transform,transformation,1289," in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:173,modifiability,version,version,173,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:456,modifiability,variab,variable,456,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1006,modifiability,depend,depend,1006,"ding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2156,modifiability,Version,Versions,2156,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:856,performance,profil,profiles,856,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1077,performance,content,content,1077,"s issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:621,reliability,Incid,Incidentally,621,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:32,safety,log,log,32,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:496,safety,log,log,496,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:930,safety,log,log,930,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1006,safety,depend,depend,1006,"ding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1020,safety,detect,detection,1020,"on and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1169,safety,log,log-counts,1169,"ersion of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1213,safety,log,log-mean,1213,"onfirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1285,safety,log,log-transformation,1285,"ug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2300,safety,log,logging,2300,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:32,security,log,log,32,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:496,security,log,log,496,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:930,security,log,log,930,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1020,security,detect,detection,1020,"on and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1169,security,log,log-counts,1169,"ersion of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1213,security,log,log-mean,1213,"onfirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1285,security,log,log-transformation,1285,"ug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2300,security,log,logging,2300,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:0,testability,Understand,Understanding,0,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:32,testability,log,log,32,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:496,testability,log,log,496,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:930,testability,log,log,930,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1006,testability,depend,depend,1006,"ding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1169,testability,log,log-counts,1169,"ersion of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1213,testability,log,log-mean,1213,"onfirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1266,testability,context,contexts,1266,"py. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the mas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1285,testability,log,log-transformation,1285,"ug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2300,testability,log,logging,2300,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:133,usability,confirm,confirmed,133,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:216,usability,confirm,confirmed,216,"Understanding normalization and log transformation; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1355,usability,Minim,Minimal,1355,"tal()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2429,usability,learn,learn,2429,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic? Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python. >>> from anndata import AnnData. >>> import scanpy as sc. >>> import numpy as np. >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])). >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']. >>> X_norm_log = np.log1p(X_norm). >>> X_norm_again = np.expm1(X_norm_log). >>> adata.X.sum(axis=1). array([21., 7., 28.], dtype=float32) # Different counts for each cell. >>> X_norm.sum(axis=1). array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell. >>> X_norm_log.sum(axis=1). array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell. >>> X_norm_again.sum(axis=1). array([1., 1., 1.], dtype=float32) # Counts the same again. ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(). scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1365:0,deployability,Releas,Release,0,"Release date for next version?; Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:22,deployability,version,version,22,"Release date for next version?; Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:168,deployability,releas,release,168,"Release date for next version?; Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:185,energy efficiency,schedul,scheduled,185,"Release date for next version?; Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:22,integrability,version,version,22,"Release date for next version?; Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:22,modifiability,version,version,22,"Release date for next version?; Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:185,performance,schedul,scheduled,185,"Release date for next version?; Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1366:77,availability,cluster,clusters,77,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1366:153,availability,cluster,clusters,153,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1366:185,availability,cluster,clusters,185,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1366:77,deployability,cluster,clusters,77,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1366:153,deployability,cluster,clusters,153,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1366:185,deployability,cluster,clusters,185,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1366:47,safety,avoid,avoiding,47,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1366:136,usability,visual,visualize,136,Use graph coloring algorithm for a world map avoiding to color neighboring clusters in the same color; I was trying to plot a tsne to visualize all my clusters. But since I have 100+ clusters the pl.umap function gave me all grey. Is there a way to assign colors to them?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1366
https://github.com/scverse/scanpy/issues/1367:525,availability,error,error,525,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:648,availability,error,error,648,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:134,deployability,version,version,134,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:597,deployability,updat,updating,597,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1216,deployability,modul,module,1216,"anch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatena",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:2954,deployability,Version,Versions,2954,"5f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 180 print(' Computing correction vectors...'). 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,. --> 182 new_batch_in, sigma). 183 if not same_set:. 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.19.1 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. numba==0.50.1. llvmlite==0.33.0+1.g022ab0f. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:134,integrability,version,version,134,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:962,integrability,batch,batch,962,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:996,integrability,batch,batch,996,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:2954,integrability,Version,Versions,2954,"5f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 180 print(' Computing correction vectors...'). 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,. --> 182 new_batch_in, sigma). 183 if not same_set:. 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.19.1 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. numba==0.50.1. llvmlite==0.33.0+1.g022ab0f. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:134,modifiability,version,version,134,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:620,modifiability,pac,packages,620,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1216,modifiability,modul,module,1216,"anch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatena",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1396,modifiability,pac,packages,1396,"s to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1812,modifiability,pac,packages,1812,"ernal.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 180 print(' Computing correction vectors...'). 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,. --> 182 new_batch_in, sigma). 183 if not same_set:. 184 correction_out = compute_corre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:2260,modifiability,Pac,Packing,2260,"5f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 180 print(' Computing correction vectors...'). 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,. --> 182 new_batch_in, sigma). 183 if not same_set:. 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.19.1 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. numba==0.50.1. llvmlite==0.33.0+1.g022ab0f. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:2350,modifiability,pac,packages,2350,"5f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 180 print(' Computing correction vectors...'). 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,. --> 182 new_batch_in, sigma). 183 if not same_set:. 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.19.1 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. numba==0.50.1. llvmlite==0.33.0+1.g022ab0f. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:2954,modifiability,Version,Versions,2954,"5f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 180 print(' Computing correction vectors...'). 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,. --> 182 new_batch_in, sigma). 183 if not same_set:. 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.19.1 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. numba==0.50.1. llvmlite==0.33.0+1.g022ab0f. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:525,performance,error,error,525,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:648,performance,error,error,648,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:885,performance,Perform,Performing,885,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:962,performance,batch,batch,962,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:996,performance,batch,batch,996,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:525,safety,error,error,525,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:597,safety,updat,updating,597,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:648,safety,error,error,648,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1189,safety,input,input-,1189,"bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1216,safety,modul,module,1216,"anch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatena",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:597,security,updat,updating,597,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1145,testability,Trace,Traceback,1145,"y. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:94,usability,confirm,confirmed,94,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:177,usability,confirm,confirmed,177,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:268,usability,guid,guide,268,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:323,usability,minim,minimal-bug-reports,323,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:429,usability,Minim,Minimal,429,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:525,usability,error,error,525,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:648,usability,error,error,648,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:885,usability,Perform,Performing,885,"mnn_correct; - [ ] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1189,usability,input,input-,1189,"bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:1335,usability,User,Users,1335,"orts) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hi Scanpy,. I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python. adata_mnn = adata.copy(). adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]. adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). ```. ```pytb. Performing cosine normalization... Starting MNN correct iteration. Reference batch: 0. Step 1 of 4: processing batch 1. Looking for MNNs... Computing correction vectors... ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-49-f894e9f745f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:3064,usability,learn,learn,3064,"5f6> in <module>. ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 152 save_raw=save_raw,. 153 n_jobs=n_jobs,. --> 154 **kwargs,. 155 ). 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. 125 compute_angle=compute_angle, mnn_order=mnn_order,. --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). 127 print('Packing AnnData object...'). 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 180 print(' Computing correction vectors...'). 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,. --> 182 new_batch_in, sigma). 183 if not same_set:. 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.19.1 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. numba==0.50.1. llvmlite==0.33.0+1.g022ab0f. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1368:508,availability,down,downsample,508,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:917,availability,error,error,917,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1013,availability,error,error,1013,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:164,deployability,version,version,164,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1487,deployability,Version,Versions,1487,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1564,deployability,log,logging,1564,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:164,integrability,version,version,164,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1487,integrability,Version,Versions,1487,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:164,modifiability,version,version,164,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1142,modifiability,pac,packages,1142,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1487,modifiability,Version,Versions,1487,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:917,performance,error,error,917,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1013,performance,error,error,1013,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:917,safety,error,error,917,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1013,safety,error,error,1013,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1564,safety,log,logging,1564,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1564,security,log,logging,1564,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:576,testability,Spy,Spyder,576,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1072,testability,Spy,Spyder,1072,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1462,testability,Spy,Spyder,1462,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1564,testability,log,logging,1564,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:124,usability,confirm,confirmed,124,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:207,usability,confirm,confirmed,207,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:298,usability,guid,guide,298,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:353,usability,minim,minimal-bug-reports,353,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:604,usability,Minim,Minimal,604,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:917,usability,error,error,917,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1013,usability,error,error,1013,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1248,usability,prefer,prefer,1248,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1284,usability,statu,status,1284,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1726,usability,learn,learn,1726,"A bug about scanpy.pp.downsample_counts(); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. import numpy as np. import scanpy as sc. import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']). adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb. [Paste the error output produced by the above code here]. ```. after I run the above code, there isn;t any error. But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`. status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want. After that, my console cant output anything, unless I exit Spyder and re-enter. ### Versions. Python 3.7.0. Scanpy 1.4.3. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1369:70,availability,error,error,70,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:0,deployability,Modul,ModuleNotFoundError,0,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:24,deployability,modul,module,24,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:92,deployability,version,version,92,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:121,deployability,Modul,ModuleNotFoundError,121,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:212,deployability,modul,module,212,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:814,deployability,Modul,ModuleNotFoundError,814,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:838,deployability,modul,module,838,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:416,energy efficiency,cpu,cpumode,416,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:92,integrability,version,version,92,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:0,modifiability,Modul,ModuleNotFoundError,0,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:24,modifiability,modul,module,24,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:92,modifiability,version,version,92,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:121,modifiability,Modul,ModuleNotFoundError,121,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:212,modifiability,modul,module,212,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:443,modifiability,pac,packages,443,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:814,modifiability,Modul,ModuleNotFoundError,814,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:838,modifiability,modul,module,838,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:70,performance,error,error,70,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:416,performance,cpu,cpumode,416,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:0,safety,Modul,ModuleNotFoundError,0,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:24,safety,modul,module,24,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:70,safety,error,error,70,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:121,safety,Modul,ModuleNotFoundError,121,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:185,safety,input,input-,185,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:212,safety,modul,module,212,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:814,safety,Modul,ModuleNotFoundError,814,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:838,safety,modul,module,838,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:141,testability,Trace,Traceback,141,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:70,usability,error,error,70,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:185,usability,input,input-,185,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1369:459,usability,tool,tools,459,"ModuleNotFoundError: No module named 'louvain'; Getting the following error with the latest version of scanpy:. ```pytb. ModuleNotFoundError Traceback (most recent call last). <ipython-input-24-7f6e74b434f4> in <module>. ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10). 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy). 135 weights = None. 136 if flavor == 'vtraag':. --> 137 import louvain. 138 if partition_type is None:. 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1370:36,deployability,integr,integrated,36,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:143,deployability,integr,integrated,143,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:203,deployability,integr,integrated,203,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:392,deployability,integr,integrated,392,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:541,deployability,integr,integrated,541,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:923,deployability,integr,integrated,923,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1161,deployability,integr,integrated,1161,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:36,integrability,integr,integrated,36,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:143,integrability,integr,integrated,143,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:203,integrability,integr,integrated,203,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:392,integrability,integr,integrated,392,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:541,integrability,integr,integrated,541,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:726,integrability,batch,batch,726,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:923,integrability,integr,integrated,923,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1161,integrability,integr,integrated,1161,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:36,interoperability,integr,integrated,36,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:143,interoperability,integr,integrated,143,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:203,interoperability,integr,integrated,203,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:392,interoperability,integr,integrated,392,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:541,interoperability,integr,integrated,541,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:923,interoperability,integr,integrated,923,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1161,interoperability,integr,integrated,1161,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:36,modifiability,integr,integrated,36,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:143,modifiability,integr,integrated,143,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:203,modifiability,integr,integrated,203,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:392,modifiability,integr,integrated,392,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:541,modifiability,integr,integrated,541,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:923,modifiability,integr,integrated,923,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1161,modifiability,integr,integrated,1161,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:726,performance,batch,batch,726,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:36,reliability,integr,integrated,36,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:143,reliability,integr,integrated,143,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:203,reliability,integr,integrated,203,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:392,reliability,integr,integrated,392,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:541,reliability,integr,integrated,541,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:923,reliability,integr,integrated,923,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1161,reliability,integr,integrated,1161,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:36,security,integr,integrated,36,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:143,security,integr,integrated,143,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:203,security,integr,integrated,203,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:392,security,integr,integrated,392,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:448,security,ident,ident,448,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:514,security,ident,ident,514,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:541,security,integr,integrated,541,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:869,security,ident,ident,869,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:923,security,integr,integrated,923,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1099,security,sign,significantly,1099,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1161,security,integr,integrated,1161,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:36,testability,integr,integrated,36,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:143,testability,integr,integrated,143,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:203,testability,integr,integrated,203,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:392,testability,integr,integrated,392,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:541,testability,integr,integrated,541,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:923,testability,integr,integrated,923,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1161,testability,integr,integrated,1161,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:96,usability,tool,tools,96,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:173,usability,workflow,workflow,173,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:586,usability,user,user-images,586,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:903,usability,indicat,indicating,903,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:978,usability,user,user-images,978,"why umap showing bbknn perfectively integrated but tsne ; Hi @all,. Thanks to develop the great tools,. I encounter a pecular problem on bbknn integrated data. i follow the workflow code to run the data integrated,the code showing below,. #. sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]. sc.tl.pca(adata, svd_solver='arpack'). sc.tl.tsne(adata). ///data integrated. sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata). adata. sc.pl.umap(adata, color=['orig.ident']). showing the well integrated, picture below,. ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png). But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture. ,i runing ,. sc.tl.tsne(adata). sc.pl.tsne(adata, color=['orig.ident']). the picture show below, indicating that the integrated can not be worked on tsne. ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png). So, why this tsne showing significantly different with the object just running over the integrated process. any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1371:148,modifiability,paramet,parameters,148,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/issues/1371:425,modifiability,pac,package,425,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/issues/1371:230,testability,simpl,simple,230,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/issues/1371:222,usability,tool,tool,222,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/issues/1371:230,usability,simpl,simple,230,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/issues/1371:246,usability,tool,tool,246,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/issues/1371:294,usability,tool,tools,294,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/issues/1371:394,usability,tool,tools,394,"Option for dot_ax.grid(True, linewidth = x) in sc.pl.dotplot(); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ x] Other? s. <!-- Please describe your wishes below: -->. ... In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument? Thank you! Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/pull/1372:0,deployability,version,version,0,version 1.6.0;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1372
https://github.com/scverse/scanpy/pull/1372:0,integrability,version,version,0,version 1.6.0;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1372
https://github.com/scverse/scanpy/pull/1372:0,modifiability,version,version,0,version 1.6.0;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1372
https://github.com/scverse/scanpy/pull/1373:6,deployability,version,version,6,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:50,deployability,log,log,50,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:62,deployability,version,version,62,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:278,deployability,log,logical,278,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:324,deployability,updat,updated,324,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:286,energy efficiency,CPU,CPU,286,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:290,energy efficiency,core,cores,290,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:6,integrability,version,version,6,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:62,integrability,version,version,62,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:6,modifiability,version,version,6,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:62,modifiability,version,version,62,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:286,performance,CPU,CPU,286,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:50,safety,log,log,50,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:278,safety,log,logical,278,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:324,safety,updat,updated,324,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:50,security,log,log,50,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:278,security,log,logical,278,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:304,security,Session,Session,304,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:324,security,updat,updated,324,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:50,testability,log,log,50,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:278,testability,log,logical,278,"short version of print_versions and print_header; log a short version of the sinfo header:. ```. -----. anndata 0.7.4. scanpy 1.5.2.dev106+gd355654f. sinfo 0.3.1. -----. Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]. Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5. 16 logical CPU cores. -----. Session information updated at 2020-08-16 21:09. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1374:27,deployability,manag,managed,27,"Switch to flit; Ha, I even managed to eliminate docs/requirements.txt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1374
https://github.com/scverse/scanpy/pull/1374:27,energy efficiency,manag,managed,27,"Switch to flit; Ha, I even managed to eliminate docs/requirements.txt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1374
https://github.com/scverse/scanpy/pull/1374:27,safety,manag,managed,27,"Switch to flit; Ha, I even managed to eliminate docs/requirements.txt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1374
https://github.com/scverse/scanpy/pull/1375:19,integrability,configur,configured,19,pytest can also be configured in TOML!; Also get rid of useless .gitattributes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1375
https://github.com/scverse/scanpy/pull/1375:19,modifiability,configur,configured,19,pytest can also be configured in TOML!; Also get rid of useless .gitattributes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1375
https://github.com/scverse/scanpy/pull/1375:19,security,configur,configured,19,pytest can also be configured in TOML!; Also get rid of useless .gitattributes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1375
https://github.com/scverse/scanpy/pull/1376:4,deployability,instal,install,4,Fix install;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1376
https://github.com/scverse/scanpy/pull/1377:31,deployability,instal,install,31,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:135,deployability,instal,install,135,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:162,deployability,Instal,Installation,162,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:204,deployability,instal,install,204,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:232,deployability,instal,install,232,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:271,deployability,instal,install,271,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:566,deployability,updat,update,566,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:357,modifiability,pac,packages,357,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:566,safety,updat,update,566,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:566,security,updat,update,566,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:319,testability,simpl,simply,319,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:63,usability,workflow,workflow,63,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:91,usability,User,Users,91,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:319,usability,simpl,simply,319,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:396,usability,user,user-images,396,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:546,usability,user,users,546,Add instructions for conda dev install; I hope that solves all workflow woes! @ivirshup? - Users still only need `pip` and can do `pip install scanpy[extras]`. - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`. - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore cant create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1378:30,deployability,instal,installs,30,Allow JUST symlinking anndata installs; @Koncopd said in https://github.com/theislab/scanpy/pull/1377#issuecomment-675422847 that he has problems with the package metadata being found. Which is extremely weird as `flit install --symlink` creates both a symlink and package metadata:. ```console. $ ls -l ~/.conda/envs/anndata/lib/python3.8/site-packages/ | grep anndata. lrwxrwxrwx 49 phil 2020-08-18 14:30 anndata -> ~/Dev/Python/Single Cell/anndata/anndata. drwxr-sr-x - phil 2020-08-18 14:30 anndata-0.7.5.dev9_gd32f11b.dist-info. ```. @Koncopd does that help? please post your stack trace before and after this PR so I see whats going on. And also please post if the `.dist-info` directory has been created. Maybe we need to recommend `--pth-file` for windows users.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378
https://github.com/scverse/scanpy/pull/1378:219,deployability,instal,install,219,Allow JUST symlinking anndata installs; @Koncopd said in https://github.com/theislab/scanpy/pull/1377#issuecomment-675422847 that he has problems with the package metadata being found. Which is extremely weird as `flit install --symlink` creates both a symlink and package metadata:. ```console. $ ls -l ~/.conda/envs/anndata/lib/python3.8/site-packages/ | grep anndata. lrwxrwxrwx 49 phil 2020-08-18 14:30 anndata -> ~/Dev/Python/Single Cell/anndata/anndata. drwxr-sr-x - phil 2020-08-18 14:30 anndata-0.7.5.dev9_gd32f11b.dist-info. ```. @Koncopd does that help? please post your stack trace before and after this PR so I see whats going on. And also please post if the `.dist-info` directory has been created. Maybe we need to recommend `--pth-file` for windows users.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378
https://github.com/scverse/scanpy/pull/1378:581,deployability,stack,stack,581,Allow JUST symlinking anndata installs; @Koncopd said in https://github.com/theislab/scanpy/pull/1377#issuecomment-675422847 that he has problems with the package metadata being found. Which is extremely weird as `flit install --symlink` creates both a symlink and package metadata:. ```console. $ ls -l ~/.conda/envs/anndata/lib/python3.8/site-packages/ | grep anndata. lrwxrwxrwx 49 phil 2020-08-18 14:30 anndata -> ~/Dev/Python/Single Cell/anndata/anndata. drwxr-sr-x - phil 2020-08-18 14:30 anndata-0.7.5.dev9_gd32f11b.dist-info. ```. @Koncopd does that help? please post your stack trace before and after this PR so I see whats going on. And also please post if the `.dist-info` directory has been created. Maybe we need to recommend `--pth-file` for windows users.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378
