id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/177:1146,usability,command,command,1146,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1491,usability,command,command,1491,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1681,usability,error,error,1681,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1940,usability,error,error,1940,"Hello,. I tried installing deepvariant using `conda install deepvariant` . With this, conda successfully;. -Collects package metadata. -Solves environment. -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```. Preparing transaction: done. Verifying transaction: done. Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. failed. ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1. running your command again with `-v` will provide additional information. location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. I had a similar error installing with . `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:74,availability,down,downloads,74,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:238,availability,Failur,Failures,238,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:568,availability,failur,failures,568,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:16,deployability,instal,install,16,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:66,deployability,fail,failing,66,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:238,deployability,Fail,Failures,238,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:311,deployability,configurat,configuration,311,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:568,deployability,fail,failures,568,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:662,deployability,instal,installed,662,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:96,energy efficiency,model,models,96,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:311,integrability,configur,configuration,311,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:613,interoperability,specif,specific,613,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:311,modifiability,configur,configuration,311,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:238,performance,Failur,Failures,238,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:568,performance,failur,failures,568,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:66,reliability,fail,failing,66,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:238,reliability,Fail,Failures,238,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:568,reliability,fail,failures,568,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:96,security,model,models,96,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:311,security,configur,configuration,311,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:521,usability,tip,tips,521,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:603,usability,help,help,603,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1514,availability,Avail,Available,1514,"s. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2263,availability,Avail,Available,2263," (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3720,availability,avail,available,3720," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:15,deployability,Instal,Installation,15,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:51,deployability,version,version,51,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:124,deployability,instal,installed,124,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:154,deployability,version,version,154,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:257,deployability,instal,install,257,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:381,deployability,fail,failed,381,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:576,deployability,fail,failed,576,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:653,deployability,instal,install,653,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:788,deployability,fail,failed,788,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:983,deployability,fail,failed,983,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1042,deployability,version,version,1042,"onda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Sol",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1099,deployability,instal,install,1099,"pvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1120,deployability,version,version,1120,"installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1369,deployability,fail,failed,1369,"ronment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1524,deployability,version,versions,1524,"an take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1599,deployability,version,version,1599,": . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1663,deployability,version,version,1663,"conda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1886,deployability,version,version,1886,"ts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2118,deployability,fail,failed,2118,"ersion**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. R",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2273,deployability,version,versions,2273,"a.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifica",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2341,deployability,version,version,2341," incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python instal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2460,deployability,version,version,2460,"ch other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2510,deployability,version,version,2510,"Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2576,deployability,version,version,2576,"pvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2808,deployability,instal,install,2808,".com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2857,deployability,instal,installing,2857,"strain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2962,deployability,instal,install,2962,"<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3086,deployability,fail,failed,3086," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3225,deployability,fail,failed,3225," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3339,deployability,instal,installation,3339," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3415,deployability,version,version,3415," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3602,deployability,version,version,3602," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3745,deployability,version,version,3745," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3822,deployability,version,version,3822," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3851,deployability,version,version,3851," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1876,energy efficiency,cloud,cloud-sdk,1876,"d conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1957,energy efficiency,cloud,cloud-sdk,1957,"ess CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2298,energy efficiency,cloud,cloud-sdk,2298,"ironment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2331,energy efficiency,cloud,cloud-sdk,2331,"oking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2384,energy efficiency,cloud,cloud-sdk,2384,"leError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2500,energy efficiency,cloud,cloud-sdk,2500,"ckage -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:51,integrability,version,version,51,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:154,integrability,version,version,154,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1042,integrability,version,version,1042,"onda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Sol",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1120,integrability,version,version,1120,"installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1524,integrability,version,versions,1524,"an take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1599,integrability,version,version,1599,": . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1663,integrability,version,version,1663,"conda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1886,integrability,version,version,1886,"ts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2273,integrability,version,versions,2273,"a.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifica",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2341,integrability,version,version,2341," incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python instal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2460,integrability,version,version,2460,"ch other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2510,integrability,version,version,2510,"Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2576,integrability,version,version,2576,"pvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3415,integrability,version,version,3415," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3602,integrability,version,version,3602," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3745,integrability,version,version,3745," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3822,integrability,version,version,3822," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3851,integrability,version,version,3851," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:476,interoperability,conflict,conflicts,476,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:499,interoperability,incompatib,incompatible,499,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:883,interoperability,conflict,conflicts,883,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:906,interoperability,incompatib,incompatible,906,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1323,interoperability,conflict,conflicts,1323,"metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. goog",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1346,interoperability,incompatib,incompatible,1346,": done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1412,interoperability,specif,specifications,1412,"ying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1444,interoperability,incompatib,incompatible,1444,"ng environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1485,interoperability,format,format,1485,"ooking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1549,interoperability,conflict,conflicts,1549,"ress CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2072,interoperability,conflict,conflicts,2072,"ironment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving envi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2095,interoperability,incompatib,incompatible,2095,"stall it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with ini",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2161,interoperability,specif,specifications,2161,"l`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environmen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2193,interoperability,incompatib,incompatible,2193,"t python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2234,interoperability,format,format,2234,"``. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . Uns",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2308,interoperability,conflict,conflicts,2308,"- . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2410,interoperability,conflict,conflicts,2410,"cifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2697,interoperability,conflict,conflicts,2697,"a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the lef",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3179,interoperability,conflict,conflicts,3179," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3202,interoperability,incompatib,incompatible,3202," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3268,interoperability,specif,specifications,3268," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3301,interoperability,incompatib,incompatible,3301," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3374,interoperability,Specif,Specifications,3374," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3881,interoperability,specif,specify,3881," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:51,modifiability,version,version,51,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:154,modifiability,version,version,154,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:320,modifiability,pac,package,320,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:512,modifiability,pac,packages,512,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:727,modifiability,pac,package,727,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:919,modifiability,pac,packages,919,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1042,modifiability,version,version,1042,"onda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Sol",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1120,modifiability,version,version,1120,"installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1252,modifiability,pac,package,1252," install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested pack",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1359,modifiability,pac,packages,1359,"ving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1503,modifiability,pac,package,1503,"ible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1524,modifiability,version,versions,1524,"an take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1534,modifiability,Pac,Package,1534,"veral minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> pytho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1599,modifiability,version,version,1599,": . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1663,modifiability,version,version,1663,"conda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1886,modifiability,version,version,1886,"ts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2003,modifiability,pac,package,2003,"ror:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2108,modifiability,pac,packages,2108,"th this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2252,modifiability,pac,package,2252,"age metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2273,modifiability,version,versions,2273,"a.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifica",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2283,modifiability,Pac,Package,2283,"one. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2341,modifiability,version,version,2341," incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python instal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2395,modifiability,Pac,Package,2395,"he following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2460,modifiability,version,version,2460,"ch other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2510,modifiability,version,version,2510,"Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2576,modifiability,version,version,2576,"pvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2678,modifiability,Pac,Package,2678,"*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3025,modifiability,pac,package,3025," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3215,modifiability,pac,packages,3215," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3415,modifiability,version,version,3415," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3602,modifiability,version,version,3602," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3745,modifiability,version,version,3745," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3822,modifiability,version,version,3822," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3851,modifiability,version,version,3851," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:381,reliability,fail,failed,381,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:576,reliability,fail,failed,576,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:788,reliability,fail,failed,788,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:983,reliability,fail,failed,983,"**_DeepVariant Installation problem using Anaconda version 4.8.2_** . https://anaconda.org/bioconda/deepvariant. **Tried to installed with default python version which is Python 3.7.6**. ```conda create --name deepvariant. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1369,reliability,fail,failed,1369,"ronment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: - . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1514,reliability,Availab,Available,1514,"s. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2118,reliability,fail,failed,2118,"ersion**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. R",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2263,reliability,Availab,Available,2263," (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3086,reliability,fail,failed,3086," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3225,reliability,fail,failed,3225," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3720,reliability,availab,available,3720," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1514,safety,Avail,Available,1514,"s. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2263,safety,Avail,Available,2263," (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3720,safety,avail,available,3720," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:1514,security,Availab,Available,1514,"s. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: . ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError:. ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`. `conda create -n deepvariant python=2.7 deepvariant` . Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:2263,security,Availab,Available,2263," (repodata.json): done. Solving environment: - . Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3720,security,availab,available,3720," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:3667,usability,indicat,indicates,3667," Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:. google-cloud-sdk[version='<243.0.0']. deepvariant -> google-cloud-sdk. Package python conflicts for:. python=2.7. deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']. google-cloud-sdk[version='<243.0.0'] -> python=2.7. deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Package setuptools conflicts for:. deepvariant -> protobuf -> setuptools. python=2.7 -> pip -> setuptools. ```. **I also tried to install clean environment with Python 2.7 before installing deepvariant**. ```. conda create -n deepvariant python=2.7. conda activate deepvariant. conda install -c bioconda deepvariant. ```. Output:. ```. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found. to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']. Your python: python=2.7. If python is on the left-most side of the chain, that's the version you've asked for. When python appears to the right, that indicates that the thing on the left is somehow. not available for the python version you are constrained to. Note that conda will not. change your python version to a different minor version unless you explicitly specify. that. ```. Do you have any idea what is causing the problem and how to proceed, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:375,availability,avail,available,375,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:87,deployability,instal,install,87,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:232,deployability,depend,dependent,232,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:306,deployability,instal,installing,306,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:358,deployability,depend,dependencies,358,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:232,integrability,depend,dependent,232,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:358,integrability,depend,dependencies,358,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:232,modifiability,depend,dependent,232,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:257,modifiability,pac,packages,257,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:358,modifiability,depend,dependencies,358,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:375,reliability,availab,available,375,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:232,safety,depend,dependent,232,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:358,safety,depend,dependencies,358,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:375,safety,avail,available,375,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:375,security,availab,available,375,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:232,testability,depend,dependent,232,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:358,testability,depend,dependencies,358,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/177:396,usability,help,helps,396,Anna;. Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:. ```. conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant. ```. bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/177
https://github.com/google/deepvariant/issues/178:1637,availability,error,error,1637,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:439,deployability,instal,installed,439,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:538,deployability,INSTAL,INSTALL,538,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1345,deployability,Version,Version,1345,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1561,deployability,releas,release,1561,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1583,deployability,releas,release,1583,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1670,deployability,modul,module,1670,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1737,deployability,instal,installation,1737,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:269,energy efficiency,cloud,cloud-platform,269,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:305,energy efficiency,draw,drawfork-,305,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1355,energy efficiency,core,core-,1355,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1370,energy efficiency,core,core-,1370,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1601,energy efficiency,Core,Core,1601,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1345,integrability,Version,Version,1345,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1643,integrability,messag,message,1643,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:275,interoperability,platform,platform,275,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:376,interoperability,standard,standard-,376,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1643,interoperability,messag,message,1643,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:2113,interoperability,share,share,2113,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1345,modifiability,Version,Version,1345,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1670,modifiability,modul,module,1670,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1637,performance,error,error,1637,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1813,performance,time,time,1813,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1268,safety,compl,completed,1268,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1637,safety,error,error,1637,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1670,safety,modul,module,1670,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1268,security,compl,completed,1268,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1077,testability,unit,unittest,1077,"oduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll hel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:206,usability,USER,USER,206,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:887,usability,command,command,887,"Hi @drtamermansour,. In my first attempt to reproduce this, I wasn't able to reproduce the issue with the following setting:. 1. I got a CentOS 7 machine with:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:1637,usability,error,error,1637,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:2078,usability,help,help,2078,"h:. ```. gcloud beta compute instances create ""${USER}-centos-singularity"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image=centos-7-drawfork-v20181102 \. --image-project=eip-images \. --machine-type ""n1-standard-32"" \. --zone ""us-west1-b"". ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. The run completed without an issue. My CentOS machine has:. ```. $ lsb_release . LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch. ```. ```. $ cat /etc/centos-release. CentOS Linux release 7.6.1810 (Core) . ```. ---. From the original error message:. `ImportError: No module named _multiarray_umath`. It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour . Two questions for you:. (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? . (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:129,deployability,fail,failed,129,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:519,interoperability,bind,bind,519,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:519,modifiability,bind,bind,519,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:34,performance,time,time,34,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:129,reliability,fail,failed,129,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:524,safety,input,input,524,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:315,usability,help,helpful,315,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:330,usability,user,users,330,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:524,usability,input,input,524,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:617,usability,command,commands,617,"@pichuan Thank you for taking the time to address this issue. (a) The example code was running fine on the Amazon instance. Only failed to run on our CentOS machine. (b) I think this is a very good idea (specially the one made by @williamrowell which was created on a CentOS machine). I think these images might be helpful to our users as well . BTW, we used your code in #132 successfully on a similar Amazon machine to create a simg file using DeepVariant 0.7.0. However, the process was not easy. We had to add ```--bind input:${INPUT_DIR}``` only on the CentOS machine to make it run. Also non of the deepvariant commands will run with genomic regions (e.g. chr20:10000000-10010000) or even multiple chromosomes (e.g. chr20 chr21 chr22). Only ```--regions ""chr20""``` was accepted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:38,deployability,build,building,38,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:78,deployability,releas,release,78,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:215,deployability,version,version,215,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:284,deployability,build,build,284,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:415,deployability,build,building,415,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:215,integrability,version,version,215,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:533,interoperability,share,share,533,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:600,interoperability,share,share,600,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:215,modifiability,version,version,215,"Hi @drtamermansour . I have not tried building Singularity before this latest release, so I can't guarantee how easy it would be. Regarding your issue with `--regions`, I'm pretty sure it's because the intervaltree version issue. Please see this comment for a solution if you have to build from DeepVariant before 0.8.0:. https://github.com/google/deepvariant/issues/131#issuecomment-449034956. We highly recommend building from the latest one (0.8.0) if possible, though. . In terms of sharing file, we'll see if @williamrowell can share his file. I can also see if I can find a reasonable place to share mine (which is also built on a CentOS machine on GCP)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:57,performance,network,network,57,"Sorry, I've been traveling the past week without a solid network connection. I've uploaded my simg to google drive at the address below. This will likely not be a permanent link, but you can use it for testing now. https://drive.google.com/open?id=12NZKJwRTroKofGB6KrZ4JVyN36DRbPuF",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:202,safety,test,testing,202,"Sorry, I've been traveling the past week without a solid network connection. I've uploaded my simg to google drive at the address below. This will likely not be a permanent link, but you can use it for testing now. https://drive.google.com/open?id=12NZKJwRTroKofGB6KrZ4JVyN36DRbPuF",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:57,security,network,network,57,"Sorry, I've been traveling the past week without a solid network connection. I've uploaded my simg to google drive at the address below. This will likely not be a permanent link, but you can use it for testing now. https://drive.google.com/open?id=12NZKJwRTroKofGB6KrZ4JVyN36DRbPuF",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:202,testability,test,testing,202,"Sorry, I've been traveling the past week without a solid network connection. I've uploaded my simg to google drive at the address below. This will likely not be a permanent link, but you can use it for testing now. https://drive.google.com/open?id=12NZKJwRTroKofGB6KrZ4JVyN36DRbPuF",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:0,deployability,Updat,Update,0,"Update: I've emailed @drtamermansour but haven't back from him. I'll close this issue for now. If anyone had a chance to try @williamrowell 's image above, let us know how it wokr.s. If anyone else is encountering the same issue, please feel free to comment on this issue again. I will close it now since there's no information right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:0,safety,Updat,Update,0,"Update: I've emailed @drtamermansour but haven't back from him. I'll close this issue for now. If anyone had a chance to try @williamrowell 's image above, let us know how it wokr.s. If anyone else is encountering the same issue, please feel free to comment on this issue again. I will close it now since there's no information right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:0,security,Updat,Update,0,"Update: I've emailed @drtamermansour but haven't back from him. I'll close this issue for now. If anyone had a chance to try @williamrowell 's image above, let us know how it wokr.s. If anyone else is encountering the same issue, please feel free to comment on this issue again. I will close it now since there's no information right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:69,usability,close,close,69,"Update: I've emailed @drtamermansour but haven't back from him. I'll close this issue for now. If anyone had a chance to try @williamrowell 's image above, let us know how it wokr.s. If anyone else is encountering the same issue, please feel free to comment on this issue again. I will close it now since there's no information right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:286,usability,close,close,286,"Update: I've emailed @drtamermansour but haven't back from him. I'll close this issue for now. If anyone had a chance to try @williamrowell 's image above, let us know how it wokr.s. If anyone else is encountering the same issue, please feel free to comment on this issue again. I will close it now since there's no information right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:63,availability,error,error,63,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:84,availability,ERROR,ERROR,84,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:69,integrability,messag,message,69,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:69,interoperability,messag,message,69,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:106,interoperability,format,format,106,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:63,performance,error,error,63,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:84,performance,ERROR,ERROR,84,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:63,safety,error,error,63,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:84,safety,ERROR,ERROR,84,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:63,usability,error,error,63,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:84,usability,ERROR,ERROR,84,"Sorry for the late replay. Unfortunately, it did not work. The error message says:. ERROR : Unknown image format/type: deepvariant.0.8.0.simg. ABORT : Retval = 255.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:67,interoperability,share,shared,67,"Hmm interesting. . @williamrowell FYI - I tried out your image you shared, and I'm having the same issue as well. @drtamermansour Thanks for testing it out. Let me rebuild with the steps I shared in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 and see if you can try mine as well. I'll follow up soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:189,interoperability,share,shared,189,"Hmm interesting. . @williamrowell FYI - I tried out your image you shared, and I'm having the same issue as well. @drtamermansour Thanks for testing it out. Let me rebuild with the steps I shared in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 and see if you can try mine as well. I'll follow up soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:141,safety,test,testing,141,"Hmm interesting. . @williamrowell FYI - I tried out your image you shared, and I'm having the same issue as well. @drtamermansour Thanks for testing it out. Let me rebuild with the steps I shared in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 and see if you can try mine as well. I'll follow up soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:141,testability,test,testing,141,"Hmm interesting. . @williamrowell FYI - I tried out your image you shared, and I'm having the same issue as well. @drtamermansour Thanks for testing it out. Let me rebuild with the steps I shared in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 and see if you can try mine as well. I'll follow up soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:329,safety,test,tested,329,@drtamermansour . Here is a simg file I just built:. https://drive.google.com/file/d/1P768MjXLa4xPmqj12UZqnmDqUZsUpbNh/view?usp=sharing. (which should be a file with the name `deepvariant.0.8.0.issue-178.simg`). I built this with the instruction here: https://github.com/google/deepvariant/issues/132#issuecomment-482430728. and tested with the steps here: https://github.com/google/deepvariant/issues/178#issuecomment-487218238. Please let me know if this works for you or not.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/178:329,testability,test,tested,329,@drtamermansour . Here is a simg file I just built:. https://drive.google.com/file/d/1P768MjXLa4xPmqj12UZqnmDqUZsUpbNh/view?usp=sharing. (which should be a file with the name `deepvariant.0.8.0.issue-178.simg`). I built this with the instruction here: https://github.com/google/deepvariant/issues/132#issuecomment-482430728. and tested with the steps here: https://github.com/google/deepvariant/issues/178#issuecomment-487218238. Please let me know if this works for you or not.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/178
https://github.com/google/deepvariant/issues/179:65,usability,tip,tips,65,"Hi @aubcar, were you able to resolve the problem? There are some tips for `glibc` in #137.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/179
https://github.com/google/deepvariant/issues/179:58,deployability,updat,updated,58,"Turns out I was on some nodes of the HPC that hadn't been updated, issue solved itself when on current nodes. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/179
https://github.com/google/deepvariant/issues/179:95,energy efficiency,current,current,95,"Turns out I was on some nodes of the HPC that hadn't been updated, issue solved itself when on current nodes. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/179
https://github.com/google/deepvariant/issues/179:58,safety,updat,updated,58,"Turns out I was on some nodes of the HPC that hadn't been updated, issue solved itself when on current nodes. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/179
https://github.com/google/deepvariant/issues/179:58,security,updat,updated,58,"Turns out I was on some nodes of the HPC that hadn't been updated, issue solved itself when on current nodes. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/179
https://github.com/google/deepvariant/issues/180:10,reliability,doe,does,10,"Also, how does the haplotype-aware realignment of reads differ from the first three steps of haplotype caller? https://software.broadinstitute.org/gatk/documentation/article?id=11068",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:152,usability,document,documentation,152,"Also, how does the haplotype-aware realignment of reads differ from the first three steps of haplotype caller? https://software.broadinstitute.org/gatk/documentation/article?id=11068",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2168,availability,consist,consistently,2168,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2087,deployability,log,logic,2087,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2228,deployability,version,version,2228,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1932,energy efficiency,model,model,1932,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:75,integrability,event,event,75,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:137,integrability,event,events,137,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:219,integrability,event,events,219,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:317,integrability,contract,contraction,317,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:765,integrability,event,events,765,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1475,integrability,event,events,1475,"A	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1696,integrability,event,events,1696,"e that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information acros",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2228,integrability,version,version,2228,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:317,interoperability,contract,contraction,317,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:780,interoperability,specif,specific,780,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2002,interoperability,specif,specific,2002,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:938,modifiability,exten,extent,938,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1706,modifiability,Pac,PacBio,1706,"icated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the read",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2228,modifiability,version,version,2228,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:18,performance,Perform,Performance,18,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:614,performance,perform,performance,614,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:728,performance,perform,perform,728,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:893,performance,perform,perform,893,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2645,performance,network,network,2645,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1369,reliability,doe,doesn,1369,"CF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1451,reliability,pra,practice,1451,"TATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from wri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:913,safety,compl,complex,913,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1467,safety,compl,complex,1467,"TATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1580,safety,Accid,Accidentally,1580,"ed accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2087,safety,log,logic,2087,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2105,safety,compl,complex,2105,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:913,security,compl,complex,913,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1467,security,compl,complex,1467,"TATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1851,security,ident,identifying,1851,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1932,security,model,model,1932,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1944,security,ident,identifies,1944,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2087,security,log,logic,2087,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2105,security,compl,complex,2105,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2380,security,auth,authors,2380,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2414,security,auth,authors,2414,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2645,security,network,network,2645,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1925,testability,simpl,simple,1925,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2087,testability,log,logic,2087,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:18,usability,Perform,Performance,18,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:124,usability,stop,stop,124,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:614,usability,perform,performance,614,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:678,usability,tool,tools,678,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:728,usability,perform,perform,728,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:857,usability,intuit,intuition,857,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:893,usability,perform,perform,893,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:1925,usability,simpl,simple,1925,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2168,usability,consist,consistently,2168,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:2814,usability,support,support,2814,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:364,deployability,depend,depend,364,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:364,integrability,depend,depend,364,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:341,modifiability,paramet,parameters,341,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:364,modifiability,depend,depend,364,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:364,safety,depend,depend,364,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:364,testability,depend,depend,364,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:865,testability,understand,understand,865,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:68,usability,help,helpful,68,"@AndrewCarroll Thanks for the thorough response. This was extremely helpful. Also re the haplotype caller comparison: I thought DeepVariant also uses a PairHMM to score haplotypes to re-align reads to, and then feeds that to the CNN. . From the paper:. > The likelihood function used to score haplotypes is a traditional pair HMM with fixed parameters that do not depend on base quality scores. This likelihood function assumes that each read is independent. Finally, each read is then realigned to its most likely haplotype using a Smith–Waterman-like algorithm with an additional affine gap penalty score for homopolymer indels. So both methods use PairHMM to score haplotypes, and assist in re-aligning reads, ya? After that, the similarity is nil between the methods as you mentioned. . Sorry if that was implicit in your response, but wanted to double check I understand.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:307,interoperability,share,shared,307,"Sorry, there is a misunderstanding here. Only GATK uses the PairHMM to score haplotypes based on probability. DeepVariant uses does not use PairHMM at all, instead it uses a convolutional neural network. GATK's PairHMM is used in the 3rd stop from the linked document. The two steps that are (conceptually) shared are identifying regions to apply reassembly to and assembling a de Bruijn graph of the reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:195,performance,network,network,195,"Sorry, there is a misunderstanding here. Only GATK uses the PairHMM to score haplotypes based on probability. DeepVariant uses does not use PairHMM at all, instead it uses a convolutional neural network. GATK's PairHMM is used in the 3rd stop from the linked document. The two steps that are (conceptually) shared are identifying regions to apply reassembly to and assembling a de Bruijn graph of the reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:127,reliability,doe,does,127,"Sorry, there is a misunderstanding here. Only GATK uses the PairHMM to score haplotypes based on probability. DeepVariant uses does not use PairHMM at all, instead it uses a convolutional neural network. GATK's PairHMM is used in the 3rd stop from the linked document. The two steps that are (conceptually) shared are identifying regions to apply reassembly to and assembling a de Bruijn graph of the reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:195,security,network,network,195,"Sorry, there is a misunderstanding here. Only GATK uses the PairHMM to score haplotypes based on probability. DeepVariant uses does not use PairHMM at all, instead it uses a convolutional neural network. GATK's PairHMM is used in the 3rd stop from the linked document. The two steps that are (conceptually) shared are identifying regions to apply reassembly to and assembling a de Bruijn graph of the reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:318,security,ident,identifying,318,"Sorry, there is a misunderstanding here. Only GATK uses the PairHMM to score haplotypes based on probability. DeepVariant uses does not use PairHMM at all, instead it uses a convolutional neural network. GATK's PairHMM is used in the 3rd stop from the linked document. The two steps that are (conceptually) shared are identifying regions to apply reassembly to and assembling a de Bruijn graph of the reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:238,usability,stop,stop,238,"Sorry, there is a misunderstanding here. Only GATK uses the PairHMM to score haplotypes based on probability. DeepVariant uses does not use PairHMM at all, instead it uses a convolutional neural network. GATK's PairHMM is used in the 3rd stop from the linked document. The two steps that are (conceptually) shared are identifying regions to apply reassembly to and assembling a de Bruijn graph of the reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:259,usability,document,document,259,"Sorry, there is a misunderstanding here. Only GATK uses the PairHMM to score haplotypes based on probability. DeepVariant uses does not use PairHMM at all, instead it uses a convolutional neural network. GATK's PairHMM is used in the 3rd stop from the linked document. The two steps that are (conceptually) shared are identifying regions to apply reassembly to and assembling a de Bruijn graph of the reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:55,availability,state,states,55,So is the DeepVariant paper out of date then? Cause it states that a pair HMM is used or maybe I'm completely misunderstanding the point.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:55,integrability,state,states,55,So is the DeepVariant paper out of date then? Cause it states that a pair HMM is used or maybe I'm completely misunderstanding the point.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:99,safety,compl,completely,99,So is the DeepVariant paper out of date then? Cause it states that a pair HMM is used or maybe I'm completely misunderstanding the point.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:99,security,compl,completely,99,So is the DeepVariant paper out of date then? Cause it states that a pair HMM is used or maybe I'm completely misunderstanding the point.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:26,deployability,releas,released,26,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:35,deployability,version,version,35,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:170,deployability,releas,releases,170,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:349,deployability,version,version,349,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:452,deployability,releas,release,452,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:862,deployability,build,building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-,862,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:17,energy efficiency,current,current,17,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:267,energy efficiency,model,models,267,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:853,energy efficiency,power,power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-,853,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:35,integrability,version,version,35,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:110,integrability,sub,submission,110,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:349,integrability,version,version,349,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:389,integrability,sub,submission,389,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:539,integrability,pub,publication,539,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:608,integrability,pub,publications,608,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:890,interoperability,platform,platform-how-deepvariant-uses-intels-avx-optimizations-,890,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:35,modifiability,version,version,35,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:349,modifiability,version,version,349,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:651,performance,content,content,651,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:931,performance,optimiz,optimizations-,931,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:58,reliability,doe,does,58,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:297,reliability,doe,does,297,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:302,safety,valid,validly,302,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:267,security,model,models,267,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:705,security,team,team,705,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/180:713,usability,close,close,713,"The code for the current, released version of DeepVariant does not use PairHMM to score haplotypes. Since the submission of the DeepVariant manuscript, there have been 4 releases which have improved various aspects of the code, training regime, and training data for models. The DeepVariant paper does validly describe the methods used in a working version, both the original PrecisionFDA submission and the improvements made for the first open source release (v0.4). However, there are further improvements which are not captured in that publication, and which are instead represented either in other joint publications (e.g. https://www.biorxiv.org/content/10.1101/519025v2) or in blogs produced by our team or close partners (e.g. https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html), (e.g. https://medium.com/tensorflow/the-power-of-building-on-an-accelerating-platform-how-deepvariant-uses-intels-avx-optimizations-c8f0acb62344).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/180
https://github.com/google/deepvariant/issues/181:94,reliability,Doe,Does,94,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:171,safety,input,input,171,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:336,safety,input,input,336,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:385,safety,input,input,385,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:358,testability,unit,unittest,358,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:51,usability,command,command,51,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:84,usability,command,commands,84,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:171,usability,input,input,171,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:336,usability,input,input,336,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:385,usability,input,input,385,"Hi @ashraf123456789, you will need to reformat the command as it got split into two commands. Does the following work for you? ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:66,availability,error,error,66,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:553,interoperability,format,format,553,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:66,performance,error,error,66,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:66,safety,error,error,66,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:115,safety,input,input,115,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:290,safety,input,input,290,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:341,safety,input,input,341,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:312,testability,unit,unittest,312,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:35,usability,command,command,35,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:66,usability,error,error,66,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:115,usability,input,input,115,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:290,usability,input,input,290,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:341,usability,input,input,341,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:579,usability,help,help,579,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:592,usability,command,commands,592,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:649,usability,command,commands,649,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=4. docker: invalid reference format. See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix? Best,. -Ashraf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:126,availability,error,error,126,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:132,integrability,messag,message,132,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:132,interoperability,messag,message,132,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:149,modifiability,variab,variable,149,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:126,performance,error,error,126,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:126,safety,error,error,126,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:313,safety,input,input,313,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:478,safety,input,input,478,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:527,safety,input,input,527,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:500,testability,unit,unittest,500,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:35,usability,command,commands,35,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:126,usability,error,error,126,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:313,usability,input,input,313,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:478,usability,input,input,478,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:527,usability,input,input,527,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```. BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=4. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:205,availability,error,error,205,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:266,availability,error,error,266,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:314,interoperability,format,format,314,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:390,interoperability,format,format,390,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:2191,interoperability,format,format,2191,"d, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output_vcf /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result/ --model_type ONT_R104. docker: invalid reference format. See 'docker run --help'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:380,modifiability,paramet,parameter,380,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:40,performance,time,time,40,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:205,performance,error,error,205,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:266,performance,error,error,266,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:205,safety,error,error,205,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:266,safety,error,error,266,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:26,usability,command,command,26,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:162,usability,command,command,162,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:205,usability,error,error,205,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:217,usability,command,command,217,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:266,usability,error,error,266,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:340,usability,help,help,340,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:503,usability,Support,Supports,503,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:640,usability,help,help,640,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:655,usability,help,help,655,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:705,usability,command,command,705,"Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/181:2217,usability,help,help,2217,"d, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. "")**. it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output_vcf /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result/ --model_type ONT_R104. docker: invalid reference format. See 'docker run --help'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/181
https://github.com/google/deepvariant/issues/182:69,deployability,updat,updated,69,"Hi @TerjeNorderhaug, thanks for the suggestions! We will push out an updated version of the notebook by the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/182
https://github.com/google/deepvariant/issues/182:77,deployability,version,version,77,"Hi @TerjeNorderhaug, thanks for the suggestions! We will push out an updated version of the notebook by the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/182
https://github.com/google/deepvariant/issues/182:113,deployability,releas,release,113,"Hi @TerjeNorderhaug, thanks for the suggestions! We will push out an updated version of the notebook by the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/182
https://github.com/google/deepvariant/issues/182:77,integrability,version,version,77,"Hi @TerjeNorderhaug, thanks for the suggestions! We will push out an updated version of the notebook by the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/182
https://github.com/google/deepvariant/issues/182:77,modifiability,version,version,77,"Hi @TerjeNorderhaug, thanks for the suggestions! We will push out an updated version of the notebook by the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/182
https://github.com/google/deepvariant/issues/182:69,safety,updat,updated,69,"Hi @TerjeNorderhaug, thanks for the suggestions! We will push out an updated version of the notebook by the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/182
https://github.com/google/deepvariant/issues/182:69,security,updat,updated,69,"Hi @TerjeNorderhaug, thanks for the suggestions! We will push out an updated version of the notebook by the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/182
https://github.com/google/deepvariant/issues/183:462,energy efficiency,current,current,462,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:588,integrability,sub,subclonal,588,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:470,performance,perform,performance,470,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:545,safety,compl,complexity,545,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:545,security,compl,complexity,545,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:432,testability,understand,understand,432,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:559,testability,understand,understanding,559,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:420,usability,feedback,feedback,420,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:470,usability,perform,performance,470,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:660,usability,intuit,intuition,660,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:680,usability,prefer,preferences,680,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:151,performance,time,time,151,"Hi @AndrewCarroll ,. thanks for your reply and the additional info. I'd love to conduct some deeper investigations but unfortunately, I don't have the time. So if you could provide some more bacteria related test results, this would be highly appreciated. Thanks a lot and best regards!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:208,safety,test,test,208,"Hi @AndrewCarroll ,. thanks for your reply and the additional info. I'd love to conduct some deeper investigations but unfortunately, I don't have the time. So if you could provide some more bacteria related test results, this would be highly appreciated. Thanks a lot and best regards!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:208,testability,test,test,208,"Hi @AndrewCarroll ,. thanks for your reply and the additional info. I'd love to conduct some deeper investigations but unfortunately, I don't have the time. So if you could provide some more bacteria related test results, this would be highly appreciated. Thanks a lot and best regards!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:166,deployability,depend,depending,166,@oschwengers DeepVariant was included in [this bacterial variant calling benchmark](https://doi.org/10.1093%2Fgigascience%2Fgiaa007). tl;dr results were quite varied depending on the species and reference genome distance from the sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:166,integrability,depend,depending,166,@oschwengers DeepVariant was included in [this bacterial variant calling benchmark](https://doi.org/10.1093%2Fgigascience%2Fgiaa007). tl;dr results were quite varied depending on the species and reference genome distance from the sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:166,modifiability,depend,depending,166,@oschwengers DeepVariant was included in [this bacterial variant calling benchmark](https://doi.org/10.1093%2Fgigascience%2Fgiaa007). tl;dr results were quite varied depending on the species and reference genome distance from the sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:166,safety,depend,depending,166,@oschwengers DeepVariant was included in [this bacterial variant calling benchmark](https://doi.org/10.1093%2Fgigascience%2Fgiaa007). tl;dr results were quite varied depending on the species and reference genome distance from the sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:166,testability,depend,depending,166,@oschwengers DeepVariant was included in [this bacterial variant calling benchmark](https://doi.org/10.1093%2Fgigascience%2Fgiaa007). tl;dr results were quite varied depending on the species and reference genome distance from the sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:427,energy efficiency,model,model,427,"Dear @oschwengers,. I will soon have to call variants from E.coli bacteria genomes and ONT SUP reads and wonder if I can use the newly introduced haploid option to tell Deepvariant that my bacterial reference genome is haploid, like shown in [this page for X and Y](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-xy-calling-case-study.md). `--haploid_contigs ""<Ecoli_chromosome>"" `. Also, will the _ONT_R104_ model be affected by this extra argument? The paper referred to above by @mbhall88 dates from 2020 and may not be accurate anymore for the haploid aspect of variant calling in bacteria if DeepVariant has evolved in that domain. Thanks for your feedback",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:631,modifiability,evolv,evolved,631,"Dear @oschwengers,. I will soon have to call variants from E.coli bacteria genomes and ONT SUP reads and wonder if I can use the newly introduced haploid option to tell Deepvariant that my bacterial reference genome is haploid, like shown in [this page for X and Y](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-xy-calling-case-study.md). `--haploid_contigs ""<Ecoli_chromosome>"" `. Also, will the _ONT_R104_ model be affected by this extra argument? The paper referred to above by @mbhall88 dates from 2020 and may not be accurate anymore for the haploid aspect of variant calling in bacteria if DeepVariant has evolved in that domain. Thanks for your feedback",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:427,security,model,model,427,"Dear @oschwengers,. I will soon have to call variants from E.coli bacteria genomes and ONT SUP reads and wonder if I can use the newly introduced haploid option to tell Deepvariant that my bacterial reference genome is haploid, like shown in [this page for X and Y](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-xy-calling-case-study.md). `--haploid_contigs ""<Ecoli_chromosome>"" `. Also, will the _ONT_R104_ model be affected by this extra argument? The paper referred to above by @mbhall88 dates from 2020 and may not be accurate anymore for the haploid aspect of variant calling in bacteria if DeepVariant has evolved in that domain. Thanks for your feedback",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/183:671,usability,feedback,feedback,671,"Dear @oschwengers,. I will soon have to call variants from E.coli bacteria genomes and ONT SUP reads and wonder if I can use the newly introduced haploid option to tell Deepvariant that my bacterial reference genome is haploid, like shown in [this page for X and Y](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-xy-calling-case-study.md). `--haploid_contigs ""<Ecoli_chromosome>"" `. Also, will the _ONT_R104_ model be affected by this extra argument? The paper referred to above by @mbhall88 dates from 2020 and may not be accurate anymore for the haploid aspect of variant calling in bacteria if DeepVariant has evolved in that domain. Thanks for your feedback",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/183
https://github.com/google/deepvariant/issues/184:166,availability,Error,Error,166,"I think I know what's happening. The `${USER}` was `/root` when running docker. It was maybe caused by a `sudo bash`? When I changed it, everything seems OK. Similar Error #141 .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:166,performance,Error,Error,166,"I think I know what's happening. The `${USER}` was `/root` when running docker. It was maybe caused by a `sudo bash`? When I changed it, everything seems OK. Similar Error #141 .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:166,safety,Error,Error,166,"I think I know what's happening. The `${USER}` was `/root` when running docker. It was maybe caused by a `sudo bash`? When I changed it, everything seems OK. Similar Error #141 .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:40,usability,USER,USER,40,"I think I know what's happening. The `${USER}` was `/root` when running docker. It was maybe caused by a `sudo bash`? When I changed it, everything seems OK. Similar Error #141 .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:166,usability,Error,Error,166,"I think I know what's happening. The `${USER}` was `/root` when running docker. It was maybe caused by a `sudo bash`? When I changed it, everything seems OK. Similar Error #141 .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:194,usability,command,commands,194,Can you clarify your solution to this? I'm having the same issue. Deepvariant was running just fine before our recent shutdown but all of a sudden it can't find my bam files with the exact same commands....,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:198,deployability,contain,containers,198,". Hi @charlesfeigin,. The issue was that he was running as `root` and mapping `/home/${USER}`, which does not exist as `root` has a home directory of `/root` usually (not `/home/root`). Also Docker containers launch as `root`, meaning they have their own `/root`. It's best not to run as root. If you have to, just make sure your files are located other than under `/root`, and you map them from that other directory instead. Where were your files located before? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:101,reliability,doe,does,101,". Hi @charlesfeigin,. The issue was that he was running as `root` and mapping `/home/${USER}`, which does not exist as `root` has a home directory of `/root` usually (not `/home/root`). Also Docker containers launch as `root`, meaning they have their own `/root`. It's best not to run as root. If you have to, just make sure your files are located other than under `/root`, and you map them from that other directory instead. Where were your files located before? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:87,usability,USER,USER,87,". Hi @charlesfeigin,. The issue was that he was running as `root` and mapping `/home/${USER}`, which does not exist as `root` has a home directory of `/root` usually (not `/home/root`). Also Docker containers launch as `root`, meaning they have their own `/root`. It's best not to run as root. If you have to, just make sure your files are located other than under `/root`, and you map them from that other directory instead. Where were your files located before? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:599,availability,reboot,reboot,599,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:670,availability,avail,avail,670,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:285,integrability,filter,filtered,285,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:563,performance,time,time,563,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:624,reliability,doe,does,624,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:507,safety,permiss,permission,507,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:670,safety,avail,avail,670,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:342,security,ident,identical,342,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:21,testability,understand,understand,21,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:48,usability,experien,experienced,48,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:67,usability,user,user,67,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:79,usability,command,command,79,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:114,usability,user,user,114,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:145,usability,user,user,145,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:178,usability,command,commands,178,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:402,usability,command,command,402,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:502,usability,user,user,502,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:318,availability,error,errors,318,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:411,availability,state,state,411,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:411,integrability,state,state,411,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:318,performance,error,errors,318,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:170,safety,compl,complete,170,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:267,safety,input,input,267,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:299,safety,compl,complete,299,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:318,safety,error,errors,318,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:170,security,compl,complete,170,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:299,security,compl,complete,299,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:83,testability,simpl,simplify,83,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:71,usability,user,user,71,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:83,usability,simpl,simplify,83,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:186,usability,command,commands,186,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:267,usability,input,input,267,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:318,usability,error,errors,318,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant. 2. The directories where the input files are located. 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:53,availability,sli,slightly,53,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:969,availability,error,errors,969,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1209,availability,operat,operations,1209,"rectory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1255,availability,operat,operations,1255,"ch the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in per",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2278,availability,operat,operations,2278,"ow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2324,availability,operat,operations,2324,"21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2413,deployability,Fail,Failed,2413,"rmediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2662,deployability,modul,module,2662,"line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4308,deployability,fail,failed,4308,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1022,energy efficiency,core,core,1022,"ur assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1088,energy efficiency,optim,optimized,1088,"from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1168,energy efficiency,CPU,CPU,1168,"anian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized wit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2091,energy efficiency,core,core,2091,"ized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2157,energy efficiency,optim,optimized,2157,"owing CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2237,energy efficiency,CPU,CPU,2237,"e them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:230,integrability,sub,subdirectories,230,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1670,integrability,buffer,buffer,1670,"mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1027,interoperability,platform,platform,1027,"stance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2096,interoperability,platform,platform,2096,"th oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1412,modifiability,interm,intermediate,1412,"N_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Faile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1490,modifiability,Interm,Intermediate,1490,"n -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2662,modifiability,modul,module,2662,"line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:969,performance,error,errors,969,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1088,performance,optimiz,optimized,1088,"from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1122,performance,Network,Network,1122,"is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1168,performance,CPU,CPU,1168,"anian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized wit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1188,performance,perform,performance-critical,1188,". Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1627,performance,time,time,1627,"model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1642,performance,parallel,parallel,1642,"ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2157,performance,optimiz,optimized,2157,"owing CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2191,performance,Network,Network,2191,"ance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2237,performance,CPU,CPU,2237,"e them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2257,performance,perform,performance-critical,2257,"rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4289,performance,parallel,parallel,4289,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:53,reliability,sli,slightly,53,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2413,reliability,Fail,Failed,2413,"rmediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4308,reliability,fail,failed,4308,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:246,safety,input,inputs,246,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:449,safety,input,inputs,449,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:518,safety,input,input,518,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:651,safety,input,input,651,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:715,safety,input,input,715,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:950,safety,compl,complete,950,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:969,safety,error,errors,969,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1735,safety,input,input,1735,"t_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1801,safety,input,input,1801,"z --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2435,safety,input,input,2435,"utput/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2662,safety,modul,module,2662,"line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4239,safety,input,input,4239,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4374,safety,input,input,4374,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4438,safety,input,input,4438,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:950,security,compl,complete,950,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1122,security,Network,Network,1122,"is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2191,security,Network,Network,2191,"ance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2514,testability,Trace,Traceback,2514,"written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:108,usability,command,commands,108,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:246,usability,input,inputs,246,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:341,usability,command,commands,341,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:449,usability,input,inputs,449,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:518,usability,input,input,518,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:651,usability,input,input,651,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:715,usability,input,input,715,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:969,usability,error,errors,969,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1188,usability,perform,performance-critical,1188,". Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0"". docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs"". OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1612,usability,command,command,1612,"eepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1735,usability,input,input,1735,"t_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1801,usability,input,input,1801,"z --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2257,usability,perform,performance-critical,2257,"rebuild TensorFlow with the appropriate compiler flags. I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2435,usability,input,input,2435,"utput/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {}. 2023-08-30 21:45:21.348267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. [E::hts_open_format] Failed to open file ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4239,usability,input,input,4239,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4374,usability,input,input,4374,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4438,usability,input,input,4438,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:4694,usability,user,user,4694,"unfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_34o2lccw/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/NC_045426.1_A_filt_fixed_markdup_csort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads /input/NC_045426.1_A_filt_fixed_markdup_csort.bam --examples /output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/NC_045426.1_A_intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real 0m3.279s. user 0m3.908s. sys 0m6.234s.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:556,availability,echo,echo,556,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:823,availability,echo,echo,823,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:496,modifiability,variab,variable,496,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:729,modifiability,variab,variable,729,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1366,modifiability,variab,variables,1366,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:113,safety,sanit,sanity,113,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:155,safety,test,test,155,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:284,safety,input,inputs,284,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:368,safety,input,inputs,368,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:457,safety,test,test,457,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:546,safety,input,inputs,546,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:690,safety,test,test,690,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:792,safety,input,inputs,792,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:872,safety,input,input,872,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:922,safety,input,input,922,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:965,safety,input,input,965,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1015,safety,input,input,1015,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1272,safety,compl,complete,1272,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1349,safety,input,input,1349,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1581,safety,input,inputs,1581,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:113,security,sanit,sanity,113,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1272,security,compl,complete,1272,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:155,testability,test,test,155,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:457,testability,test,test,457,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:690,testability,test,test,690,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:284,usability,input,inputs,284,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:368,usability,input,inputs,368,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:546,usability,input,inputs,546,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:792,usability,input,inputs,792,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:872,usability,input,input,872,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:922,usability,input,input,922,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:965,usability,input,input,965,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1015,usability,input,input,1015,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1349,usability,input,input,1349,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1581,usability,input,inputs,1581,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```. INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:553,availability,echo,echo,553,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1074,availability,echo,echo,1074,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1677,interoperability,specif,specifying,1677,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1208,reliability,doe,does,1208,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:99,safety,input,inputs,99,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:371,safety,input,inputs,371,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:543,safety,input,inputs,543,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1043,safety,input,inputs,1043,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1156,safety,input,inputs,1156,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1227,safety,permiss,permissions,1227,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1425,safety,input,input,1425,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1475,safety,input,input,1475,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1523,safety,input,input,1523,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1573,safety,input,input,1573,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1803,safety,input,inputs,1803,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1891,safety,input,input,1891,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1941,safety,input,input,1941,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:99,usability,input,inputs,99,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:371,usability,input,inputs,371,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:543,usability,input,inputs,543,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1043,usability,input,inputs,1043,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1156,usability,input,inputs,1156,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1192,usability,user,user,1192,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1425,usability,input,input,1425,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1475,usability,input,input,1475,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1523,usability,input,input,1523,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1573,usability,input,input,1573,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1803,usability,input,inputs,1803,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1891,usability,input,input,1891,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1941,usability,input,input,1941,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}. total 6125004. -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" . BIN_VERSION=""1.5.0"". echo ${PWD}. /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam. (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1196,availability,error,error,1196,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1219,availability,Error,Error,1219,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:768,deployability,contain,container,768,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1375,deployability,contain,container,1375,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1422,deployability,contain,container,1422,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1525,deployability,contain,container,1525,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:300,interoperability,bind,bind,300,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:300,modifiability,bind,bind,300,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1196,performance,error,error,1196,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1219,performance,Error,Error,1219,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1359,performance,perform,perform,1359,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:129,safety,test,tests,129,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:200,safety,test,tests,200,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:382,safety,input,inputs,382,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:399,safety,input,input,399,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:443,safety,input,input,443,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:603,safety,input,input,603,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:647,safety,input,input,647,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:710,safety,input,input,710,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:754,safety,input,input,754,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:814,safety,input,input-path-cont,814,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:865,safety,input,input-path-cont,865,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:886,safety,input,input-path-cont,886,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:909,safety,input,input-path-cont,909,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:943,safety,input,input-path-cont,943,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:978,safety,input,input-path-cont,978,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1041,safety,input,input,1041,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1085,safety,input,input,1085,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1196,safety,error,error,1196,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1219,safety,Error,Error,1219,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:56,security,access,access,56,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:129,testability,test,tests,129,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:200,testability,test,tests,200,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:247,usability,command,command,247,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:382,usability,input,inputs,382,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:399,usability,input,input,399,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:443,usability,input,input,443,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:603,usability,input,input,603,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:647,usability,input,input,647,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:710,usability,input,input,710,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:754,usability,input,input,754,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:814,usability,input,input-path-cont,814,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:865,usability,input,input-path-cont,865,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:886,usability,input,input-path-cont,886,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:909,usability,input,input-path-cont,909,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:943,usability,input,input-path-cont,943,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:978,usability,input,input-path-cont,978,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1041,usability,input,input,1041,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1085,usability,input,input,1085,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1196,usability,error,error,1196,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1219,usability,Error,Error,1219,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1359,usability,perform,perform,1359,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. . Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```. docker run \. --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. $`2)`$ This is using volumes, which is a different approach:. ```. docker volume create --name dv-vol. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \. --mount source=dv-vol,target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol. ```. If the volume removal gives you an error like this:. ```. Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]. ```. Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```. docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2. ```. Let me know the results of both steps. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:65,availability,slo,slow,65,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:635,availability,Error,Error,635,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2220,availability,error,error,2220,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1367,deployability,contain,container,1367,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:405,interoperability,specif,specific,405,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:480,interoperability,bind,bind,480,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:694,interoperability,bind,bind,694,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:701,interoperability,bind,bind,701,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:480,modifiability,bind,bind,480,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:694,modifiability,bind,bind,694,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:701,modifiability,bind,bind,701,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:104,performance,time,time,104,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:635,performance,Error,Error,635,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2220,performance,error,error,2220,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:65,reliability,slo,slow,65,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:718,reliability,doe,does,718,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:562,safety,input,inputs,562,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:579,safety,input,input,579,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:620,safety,input,input,620,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:635,safety,Error,Error,635,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1030,safety,permiss,permission,1030,"replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagg",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1153,safety,input,input,1153," not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca04",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1194,safety,input,input,1194," biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc338450",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1254,safety,input,input,1254," that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix work",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1295,safety,input,input,1295,"lish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1413,safety,input,input-path-cont,1413,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1530,safety,input,input-path-cont,1530,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1551,safety,input,input-path-cont,1551,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1586,safety,input,input-path-cont,1586,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1714,safety,input,input-path-cont,1714,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1749,safety,input,input-path-cont,1749,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1809,safety,input,input,1809,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1850,safety,input,input,1850,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2220,safety,error,error,2220,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:228,security,access,access,228,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:876,testability,understand,understand,876,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:279,usability,undo,undone,279,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:327,usability,user,users,327,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:562,usability,input,inputs,562,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:579,usability,input,input,579,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:620,usability,input,input,620,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:635,usability,Error,Error,635,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:822,usability,help,help,822,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:920,usability,command,command,920,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1153,usability,input,input,1153," not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca04",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1194,usability,input,input,1194," biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc338450",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1254,usability,input,input,1254," that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix work",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1295,usability,input,input,1295,"lish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1413,usability,input,input-path-cont,1413,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1530,usability,input,input-path-cont,1530,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1551,usability,input,input-path-cont,1551,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1586,usability,input,input-path-cont,1586,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1714,usability,input,input-path-cont,1714,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1749,usability,input,input-path-cont,1749,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1809,usability,input,input,1809,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1850,usability,input,input,1850,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2220,usability,error,error,2220,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2230,usability,indicat,indicated,2230,"bility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me . docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol. dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file. touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. total 0. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest. Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c. Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well. docker volume rm dv-vol. Best,. Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:126,availability,State,States,126,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1618,availability,operat,operating,1618,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2225,availability,operat,operating,2225,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1639,deployability,version,version,1639,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1690,deployability,instal,install,1690,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1737,deployability,instal,install,1737,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1762,deployability,version,version,1762,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2091,deployability,instal,installation,2091,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2274,deployability,releas,release,2274,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2299,deployability,releas,release,2299,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2320,deployability,releas,release,2320,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2338,deployability,version,version,2338,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:126,integrability,State,States,126,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1639,integrability,version,version,1639,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1762,integrability,version,version,1762,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2338,integrability,version,version,2338,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:522,interoperability,specif,specifically,522,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1639,modifiability,version,version,1639,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1762,modifiability,version,version,1762,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2338,modifiability,version,version,2338,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:57,performance,time,time,57,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:755,safety,permiss,permissions,755,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1148,safety,input,inputs,1148,"ng so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1389,safety,input,inputs,1389,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1588,safety,reme,remember,1588,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2076,safety,except,except,2076,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:119,testability,Unit,United,119,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:187,usability,command,commands,187,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:855,usability,command,commands,855,"Hi Charles,. You are right, we are probably in different time zones - no worries at all. I am on the East Coast of the United States. Thank you for being so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1148,usability,input,inputs,1148,"ng so patient and going through the commands, as each provides new information telling us how to proceed forward. So the good thing is that now we know volumes would work, but you are right they can be cumbersome to use under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1389,usability,input,inputs,1389,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1713,usability,command,commands,1713,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1802,usability,command,command,1802,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1820,usability,command,commands,1820,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1924,usability,guidanc,guidance,1924,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:1969,usability,command,commands,1969,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2003,usability,command,commands,2003,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/184:2133,usability,command,commands,2133,"se under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs. ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? . * How long ago did you install Docker? * What commands did you use to install Docker? . * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```. uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version. ```. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/184
https://github.com/google/deepvariant/issues/185:70,availability,checkpoint,checkpoint,70,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1393,availability,checkpoint,checkpoint,1393,"ccurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2316,availability,checkpoint,checkpoint,2316,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2648,availability,robust,robustness,2648,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2050,deployability,observ,observe,2050,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2062,deployability,log,log,2062,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:370,energy efficiency,model,model,370,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:569,energy efficiency,load,loaded,569,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1002,energy efficiency,optim,optimizer,1002,"pyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1243,energy efficiency,model,modeling,1243,"t.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1327,energy efficiency,load,loaded,1327,", for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1473,energy efficiency,predict,prediction,1473,"ting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1561,energy efficiency,load,load,1561," gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1734,energy efficiency,model,model,1734," One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1743,energy efficiency,load,loading,1743,"e following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1846,energy efficiency,load,loads,1846,"collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emsc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2337,energy efficiency,current,currently,2337,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2500,energy efficiency,model,model,2500,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2676,energy efficiency,model,model,2676,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:539,integrability,sub,subtlety,539,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1028,integrability,batch,batch,1028," noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small cod",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1503,integrability,Batch,Batch,1503,". It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1918,integrability,Batch,BatchNorm,1918,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:318,interoperability,specif,specifically,318,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:681,interoperability,Specif,Specifically,681,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:813,modifiability,variab,variables,813,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:897,modifiability,variab,variables,897,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1286,modifiability,variab,variables,1286,"nsorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warms",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1946,modifiability,variab,variables,1946,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1988,modifiability,refact,refactoring,1988,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2188,modifiability,variab,variables,2188,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:569,performance,load,loaded,569,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1002,performance,optimiz,optimizer,1002,"pyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1028,performance,batch,batch,1028," noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small cod",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1327,performance,load,loaded,1327,", for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1503,performance,Batch,Batch,1503,". It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1561,performance,load,load,1561," gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1743,performance,load,loading,1743,"e following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1846,performance,load,loads,1846,"collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emsc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1918,performance,Batch,BatchNorm,1918,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1988,performance,refactor,refactoring,1988,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2546,performance,tune,tune,2546,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:70,reliability,checkpoint,checkpoint,70,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1393,reliability,checkpoint,checkpoint,1393,"ccurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1404,reliability,doe,does,1404," After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1802,reliability,doe,doesn,1802,"s which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2316,reliability,checkpoint,checkpoint,2316,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2648,reliability,robust,robustness,2648,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1473,safety,predict,prediction,1473,"ting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2062,safety,log,log,2062,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2648,safety,robust,robustness,2648,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:370,security,model,model,370,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1243,security,model,modeling,1243,"t.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:1734,security,model,model,1734," One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2062,security,log,log,2062,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2500,security,model,model,2500,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2676,security,model,model,2676,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2835,security,team,teammate,2835,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2050,testability,observ,observe,2050,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2062,testability,log,log,2062,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:426,usability,close,closely,426,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:458,usability,behavi,behavior,458,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:599,usability,document,documented,599,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:. https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:. https://www.tensorflow.org/api_docs/python/tf/train/warm_start. Specifically, this:. ```. vars_to_warm_start: [Optional] One of the following:. * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:2250,usability,learn,learning,2250,"variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option. ```. Because in our code, we use a regular expression like this:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start. This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:. ```. vars_to_warm_start=['|'.join(vars_to_include)]). ```. which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model. So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:274,deployability,stage,stage,274,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:70,energy efficiency,load,loading,70,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:165,energy efficiency,model,model,165,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:252,energy efficiency,load,loaded,252,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:82,modifiability,variab,variables,82,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:70,performance,load,loading,70,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:252,performance,load,loaded,252,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:165,security,model,model,165,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:368,usability,progress,progress,368,"Thanks for the reply. I think it solves my problem. I also agree that loading all variables is not the best, but I'd like to try the suggested code and check if the model would be the same first. But still I think some vars like the EMA ones should be loaded in the warm-up stage, and I'll try to figure out what vars are needed. I'll reply here if I make any further progress.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:85,deployability,updat,update,85,Great! Looking forward to hearing what you find. I'll close this issue. Feel free to update here or open another issue if you encounter other problems.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:85,safety,updat,update,85,Great! Looking forward to hearing what you find. I'll close this issue. Feel free to update here or open another issue if you encounter other problems.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:85,security,updat,update,85,Great! Looking forward to hearing what you find. I'll close this issue. Feel free to update here or open another issue if you encounter other problems.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/185:54,usability,close,close,54,Great! Looking forward to hearing what you find. I'll close this issue. Feel free to update here or open another issue if you encounter other problems.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/185
https://github.com/google/deepvariant/issues/186:107,deployability,releas,release,107,"Hi @arostamianfar, thanks for reporting this issue. We plan to push out a fix for this problem in a future release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:55,testability,plan,plan,55,"Hi @arostamianfar, thanks for reporting this issue. We plan to push out a fix for this problem in a future release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:14,deployability,patch,patched,14,Has this been patched yet?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:14,safety,patch,patched,14,Has this been patched yet?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:14,security,patch,patched,14,Has this been patched yet?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:253,availability,error,error,253,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:202,deployability,version,version,202,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:280,deployability,observ,observe,280,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:202,integrability,version,version,202,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:202,modifiability,version,version,202,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:253,performance,error,error,253,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:253,safety,error,error,253,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:280,testability,observ,observe,280,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/issues/186:253,usability,error,error,253,"Hi @JoshuaUrrutia , thanks for checking back. The issue has been fixed in this change:. https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/186
https://github.com/google/deepvariant/pull/187:53,security,sign,sign,53,This is a documentation fix only. I won't be able to sign the CLA.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/187
https://github.com/google/deepvariant/pull/187:10,usability,document,documentation,10,This is a documentation fix only. I won't be able to sign the CLA.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/187
https://github.com/google/deepvariant/pull/187:186,deployability,releas,release,186,"Thanks for the fix! Because the way our repo is set up, I have to make this fix in our internal codebase. I have made the fix internally now and it'll come out next time we make another release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/187
https://github.com/google/deepvariant/pull/187:165,performance,time,time,165,"Thanks for the fix! Because the way our repo is set up, I have to make this fix in our internal codebase. I have made the fix internally now and it'll come out next time we make another release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/187
https://github.com/google/deepvariant/issues/188:42,availability,avail,available,42,"Hi dhwani2410,. That functionality is not available. If you could tell me what exactly you're trying to achieve I may have some suggestions for you. Thank you. Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/188
https://github.com/google/deepvariant/issues/188:42,reliability,availab,available,42,"Hi dhwani2410,. That functionality is not available. If you could tell me what exactly you're trying to achieve I may have some suggestions for you. Thank you. Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/188
https://github.com/google/deepvariant/issues/188:42,safety,avail,available,42,"Hi dhwani2410,. That functionality is not available. If you could tell me what exactly you're trying to achieve I may have some suggestions for you. Thank you. Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/188
https://github.com/google/deepvariant/issues/188:42,security,availab,available,42,"Hi dhwani2410,. That functionality is not available. If you could tell me what exactly you're trying to achieve I may have some suggestions for you. Thank you. Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/188
https://github.com/google/deepvariant/issues/188:38,usability,tool,tools,38,"Hi,. What you may try is to use other tools to assemble haplotypes from VCF and reads. Here is what I found, for example https://www.biostars.org/p/298635/ (see comment #7).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/188
https://github.com/google/deepvariant/issues/190:27,availability,error,error,27,"Hello! Yes, it is a benign error. All it means is that your BAM file has a blank line in its header section. We will be removing this technically-correct but actually-pointlessly-annoying warning from future releases of DeepVariant and Nucleus.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/190
https://github.com/google/deepvariant/issues/190:208,deployability,releas,releases,208,"Hello! Yes, it is a benign error. All it means is that your BAM file has a blank line in its header section. We will be removing this technically-correct but actually-pointlessly-annoying warning from future releases of DeepVariant and Nucleus.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/190
https://github.com/google/deepvariant/issues/190:27,performance,error,error,27,"Hello! Yes, it is a benign error. All it means is that your BAM file has a blank line in its header section. We will be removing this technically-correct but actually-pointlessly-annoying warning from future releases of DeepVariant and Nucleus.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/190
https://github.com/google/deepvariant/issues/190:27,safety,error,error,27,"Hello! Yes, it is a benign error. All it means is that your BAM file has a blank line in its header section. We will be removing this technically-correct but actually-pointlessly-annoying warning from future releases of DeepVariant and Nucleus.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/190
https://github.com/google/deepvariant/issues/190:27,usability,error,error,27,"Hello! Yes, it is a benign error. All it means is that your BAM file has a blank line in its header section. We will be removing this technically-correct but actually-pointlessly-annoying warning from future releases of DeepVariant and Nucleus.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/190
https://github.com/google/deepvariant/issues/191:118,energy efficiency,core,core,118,"Hi Phil,. it doesn't seem like this is relevant to our codebase. I suspect this is something from the wrapper from nf-core. I see that you're also asking on the nf-core GitHub issues, which is likely the right place to ask. . If you think there might still be some issues related to the DeepVariant codebase, please feel free to add more information and reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:164,energy efficiency,core,core,164,"Hi Phil,. it doesn't seem like this is relevant to our codebase. I suspect this is something from the wrapper from nf-core. I see that you're also asking on the nf-core GitHub issues, which is likely the right place to ask. . If you think there might still be some issues related to the DeepVariant codebase, please feel free to add more information and reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:102,integrability,wrap,wrapper,102,"Hi Phil,. it doesn't seem like this is relevant to our codebase. I suspect this is something from the wrapper from nf-core. I see that you're also asking on the nf-core GitHub issues, which is likely the right place to ask. . If you think there might still be some issues related to the DeepVariant codebase, please feel free to add more information and reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:102,interoperability,wrapper,wrapper,102,"Hi Phil,. it doesn't seem like this is relevant to our codebase. I suspect this is something from the wrapper from nf-core. I see that you're also asking on the nf-core GitHub issues, which is likely the right place to ask. . If you think there might still be some issues related to the DeepVariant codebase, please feel free to add more information and reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:13,reliability,doe,doesn,13,"Hi Phil,. it doesn't seem like this is relevant to our codebase. I suspect this is something from the wrapper from nf-core. I see that you're also asking on the nf-core GitHub issues, which is likely the right place to ask. . If you think there might still be some issues related to the DeepVariant codebase, please feel free to add more information and reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:280,availability,error,error,280,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:88,energy efficiency,core,core,88,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:425,energy efficiency,frequenc,frequency,425,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:131,modifiability,paramet,parameters,131,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:187,modifiability,paramet,parameters,187,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:280,performance,error,error,280,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:280,safety,error,error,280,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:280,usability,error,error,280,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to? Thanks again,. Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:54,availability,error,error,54,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:488,availability,error,error,488,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:34,deployability,log,log,34,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:111,energy efficiency,core,core-deepvariant-,111,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:216,energy efficiency,current,current,216,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:224,energy efficiency,frequenc,frequency,224,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:274,energy efficiency,frequenc,frequency,274,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:441,energy efficiency,current,current,441,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:449,energy efficiency,frequenc,frequency,449,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:494,integrability,messag,message,494,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:1058,integrability,pub,publicly,1058,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:494,interoperability,messag,message,494,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:151,modifiability,pac,packages,151,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:54,performance,error,error,54,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:488,performance,error,error,488,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:502,reliability,doe,does,502,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:950,reliability,doe,doesn,950,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:34,safety,log,log,34,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:54,safety,error,error,54,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:488,safety,error,error,488,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:791,safety,input,input,791,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:830,safety,input,input,830,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:34,security,log,log,34,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:1067,security,access,accessible,1067,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:34,testability,log,log,34,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:806,testability,understand,understand,806,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:54,usability,error,error,54,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:475,usability,confirm,confirm,475,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:488,usability,error,error,488,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:575,usability,interact,interaction,575,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:661,usability,clear,clear,661,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:791,usability,input,input,791,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:830,usability,input,input,830,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:978,usability,clear,clear,978,"Hi Phil,. as you can see from the log you posted, the error actually came from:. ```. File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq. ""can't find current frequency file""). ```. If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how. And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:491,availability,robust,robust,491,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:13,deployability,updat,update,13,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:182,deployability,resourc,resources,182,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:714,deployability,releas,release,714,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:182,energy efficiency,resourc,resources,182,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:555,energy efficiency,current,current,555,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:182,performance,resourc,resources,182,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:699,performance,time,time,699,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:491,reliability,robust,robust,491,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:13,safety,updat,update,13,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:182,safety,resourc,resources,182,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:338,safety,reme,remember,338,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:491,safety,robust,robust,491,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:593,safety,except,except,593,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:13,security,updat,update,13,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/191:182,testability,resourc,resources,182,"Hi Phil,. an update:. @cmclean pointed out that it comes from this line of our code:. https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). . I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:. ```. try:. freq = psutil.cpu_freq(). return freq.current if freq is not None else 0.0. except NotImplementedError:. return 0.0. ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/191
https://github.com/google/deepvariant/issues/192:69,availability,checkpoint,checkpoint,69,The number is referring to the number of steps in training when this checkpoint is saved. You can see https://www.tensorflow.org/guide/checkpoints for more information.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:135,availability,checkpoint,checkpoints,135,The number is referring to the number of steps in training when this checkpoint is saved. You can see https://www.tensorflow.org/guide/checkpoints for more information.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:69,reliability,checkpoint,checkpoint,69,The number is referring to the number of steps in training when this checkpoint is saved. You can see https://www.tensorflow.org/guide/checkpoints for more information.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:135,reliability,checkpoint,checkpoints,135,The number is referring to the number of steps in training when this checkpoint is saved. You can see https://www.tensorflow.org/guide/checkpoints for more information.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:129,usability,guid,guide,129,The number is referring to the number of steps in training when this checkpoint is saved. You can see https://www.tensorflow.org/guide/checkpoints for more information.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:50,availability,slo,slow,50,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:423,deployability,log,logs,423,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:1085,deployability,log,log,1085,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:119,energy efficiency,model,model,119,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:550,energy efficiency,model,models,550,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:561,energy efficiency,model,model,561,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:204,integrability,batch,batch,204,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:633,interoperability,bind,bind,633,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:183,modifiability,paramet,parameters,183,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:312,modifiability,paramet,parameters,312,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:633,modifiability,bind,bind,633,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:204,performance,batch,batch,204,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:50,reliability,slo,slow,50,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:364,safety,input,input,364,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:423,safety,log,logs,423,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:639,safety,input,input,639,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:1085,safety,log,log,1085,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:119,security,model,model,119,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:423,security,log,logs,423,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:550,security,model,models,550,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:561,security,model,model,561,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:1085,security,log,log,1085,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:423,testability,log,logs,423,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:1085,testability,log,log,1085,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:364,usability,input,input,364,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:639,usability,input,input,639,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? . . The parameters I am using is here: . `INPUT_DIR=""${PWD}/input"". OUTPUT_DIR=""${PWD}/output"". LOG_DIR=""${OUTPUT_DIR}/logs"". OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output"". mkdir -p ""{OUTPUT_DIR_TRAINING}"". WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind. input:${OUTPUT_DIR}/ \. deepvariant.simg \. /opt/deepvariant/bin//model_train \. --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \. --train_dir = ""${OUTPUT_DIR_TRAINING}"" \. --keep_checkpoint_every_n_hours = 0.05 \. --model_name=""inception_v3"" \. --number_of_steps=50000 \. --save_interval_secs=300 \. --batch_size=512 \. --learning_rate=0.01 \. --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >. ""${LOG_DIR}/train.log"" 2>&1 &`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:31,energy efficiency,CPU,CPUs,31,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:68,energy efficiency,current,current,68,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:160,energy efficiency,GPU,GPUs,160,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:200,energy efficiency,power,powerful,200,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:257,energy efficiency,model,model,257,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:31,performance,CPU,CPUs,31,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:160,performance,GPU,GPUs,160,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:257,security,model,model,257,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:227,testability,unit,unit,227,"Hi @melkerdawy . are you using CPUs only? There is a reason why our current training case study uses TPU. If you can't run with TPU, at least considering using GPUs to train. Fundamentally you need a powerful enough processing unit to train an inception v3 model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:129,availability,avail,available,129,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:18,energy efficiency,GPU,GPUs,18,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:139,energy efficiency,CPU,CPUs,139,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:147,energy efficiency,GPU,GPUs,147,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:291,energy efficiency,core,core,291,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:18,performance,GPU,GPUs,18,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:139,performance,CPU,CPUs,139,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:147,performance,GPU,GPUs,147,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:224,performance,parallel,parallel,224,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:129,reliability,availab,available,129,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:129,safety,avail,available,129,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:129,security,availab,available,129,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:430,availability,slo,slow,430,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:161,deployability,automat,automatically,161,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:18,energy efficiency,current,currently,18,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:76,energy efficiency,GPU,GPUs,76,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:119,energy efficiency,CPU,CPUs,119,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:192,energy efficiency,CPU,CPUs,192,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:261,energy efficiency,CPU,CPU,261,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:334,energy efficiency,CPU,CPUs,334,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:393,energy efficiency,CPU,CPUs,393,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:447,energy efficiency,GPU,GPU,447,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:623,energy efficiency,power,powerful,623,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:632,energy efficiency,GPU,GPU,632,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:719,energy efficiency,GPU,GPU,719,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:800,interoperability,share,share,800,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:76,performance,GPU,GPUs,76,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:119,performance,CPU,CPUs,119,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:192,performance,CPU,CPUs,192,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:261,performance,CPU,CPU,261,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:334,performance,CPU,CPUs,334,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:393,performance,CPU,CPUs,393,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:447,performance,GPU,GPU,447,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:451,performance,parallel,parallel,451,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:532,performance,parallel,parallelizable,532,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:632,performance,GPU,GPU,632,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:719,performance,GPU,GPU,719,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:748,performance,time,time,748,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:37,reliability,doe,doesn,37,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:235,reliability,doe,does,235,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:430,reliability,slo,slow,430,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:572,reliability,pra,practical,572,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:161,testability,automat,automatically,161,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/192:45,usability,support,support,45,"Hi @melkerdawy ,. currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.). If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/192
https://github.com/google/deepvariant/issues/193:789,deployability,version,version,789,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:849,deployability,releas,releasing,849,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:225,energy efficiency,cloud,cloud,225,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:613,energy efficiency,cloud,cloud,613,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:789,integrability,version,version,789,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:891,interoperability,compatib,compatible,891,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:789,modifiability,version,version,789,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:35,security,modif,modify,35,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:520,testability,simpl,simple,520,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:202,usability,document,documentation,202,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:520,usability,simpl,simple,520,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:553,usability,command,command,553,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:589,usability,document,documentations,589,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details. The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/193:280,usability,close,close,280,"Thanks @samanvp for the answer! @saliksyed the GCP runner is actually in a separate repo. To ensure the developers notice your questions, you might consider posting future questions related to GCP runner in https://github.com/googlegenomics/gcp-deepvariant-runner/issues . . I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/193
https://github.com/google/deepvariant/issues/194:58,deployability,log,logs,58,"Hi, can you share the commands you ran and the associated logs so we can take a look?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:12,interoperability,share,share,12,"Hi, can you share the commands you ran and the associated logs so we can take a look?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:58,safety,log,logs,58,"Hi, can you share the commands you ran and the associated logs so we can take a look?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:58,security,log,logs,58,"Hi, can you share the commands you ran and the associated logs so we can take a look?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:58,testability,log,logs,58,"Hi, can you share the commands you ran and the associated logs so we can take a look?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:22,usability,command,commands,22,"Hi, can you share the commands you ran and the associated logs so we can take a look?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:60,interoperability,share,share,60,"If you're plotting on TensorBoard, it'll also be helpful to share a screenshot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:49,usability,help,helpful,49,"If you're plotting on TensorBoard, it'll also be helpful to share a screenshot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:146,deployability,log,log,146,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:212,energy efficiency,measur,measures,212,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:297,energy efficiency,model,models,297,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:146,safety,log,log,146,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:199,safety,valid,validation,199,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:146,security,log,log,146,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:188,security,loss,losses,188,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:199,security,validat,validation,199,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:297,security,model,models,297,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:146,testability,log,log,146,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:32,usability,user,user-images,32,"![train_loss_and_error](https://user-images.githubusercontent.com/13111474/60637174-f2844000-9e4b-11e9-9ed0-6461041cf407.png). Hi, I looked in my log file and plotted a figure of training losses and validation f-measures, and it turned out that I might have overlooked the improves in the trained models. The improvments after 10000 steps become very small (still important though) compared with that in the first steps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:214,interoperability,architectur,architecture,214,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:71,reliability,doe,does,71,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:20,security,loss,loss,20,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:157,testability,simpl,simple,157,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:157,usability,simpl,simple,157,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:251,usability,command,commands,251,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:278,usability,help,helpful,278,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:64,interoperability,architectur,architecture,64,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:58,modifiability,layer,layer,58,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:205,performance,network,network,205,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:123,security,loss,loss,123,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:205,security,network,network,205,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:44,testability,simpl,simple,44,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:194,testability,simpl,simple,194,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:44,usability,simpl,simple,44,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:194,usability,simpl,simple,194,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:221,usability,close,close,221,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/195:12,interoperability,specif,specify,12,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:28,modifiability,variab,variable,28,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:142,safety,test,testdata,142,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:222,safety,test,testdata,222,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:311,safety,input,input,311,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:476,safety,input,input,476,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:525,safety,input,input,525,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:142,testability,test,testdata,142,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:222,testability,test,testdata,222,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:498,testability,unit,unittest,498,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:311,usability,input,input,311,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:476,usability,input,input,476,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:525,usability,input,input,525,"You need to specify all the variable in the same script. For example:. ```. #!/usr/bin/zsh. BIN_VERSION=""0.8.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/196:604,availability,mask,mask,604,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:919,availability,consist,consistent,919,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:973,availability,Error,Errors,973,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:348,deployability,contain,contains,348,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:544,deployability,depend,depend,544,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:652,deployability,build,build,652,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:544,integrability,depend,depend,544,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:111,interoperability,share,share,111,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:544,modifiability,depend,depend,544,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:973,performance,Error,Errors,973,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:544,safety,depend,depend,544,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:973,safety,Error,Errors,973,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:772,security,sign,signal,772,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:909,security,sign,signal,909,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:544,testability,depend,depend,544,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:919,usability,consist,consistent,919,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:973,usability,Error,Errors,973,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using? Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:51,availability,mask,masked,51,I used the right one for hg38 with the PAR regions masked as stated here:. ```. http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use. ```. I see 401 variants on Y out of total 117.009,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:61,availability,state,stated,61,I used the right one for hg38 with the PAR regions masked as stated here:. ```. http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use. ```. I see 401 variants on Y out of total 117.009,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:61,integrability,state,stated,61,I used the right one for hg38 with the PAR regions masked as stated here:. ```. http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use. ```. I see 401 variants on Y out of total 117.009,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:41,availability,mask,mask,41,"Hi @kokyriakidis . That reference should mask the PAR regions. It's unclear what could be going on for those variants which DeepVariant calls. They may be FP variants in difficult regions, or could be positions where additional copies exist that are similar on autosomes. In general, there are always likely to be some calls made on chrY. For reference, the New York Genome Center has sequenced all 1000genomes at 30x coverage and mapped to hg38. For the NA12878 (a female sample), GATK4 makes 6,935 heterozygous variant calls and 6,422 homozygous variant calls. (This VCF file is available at: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20190425_NYGC_GATK/raw_calls/CEU/Sample_NA12878/analysis/NA12878.haplotypeCalls.er.raw.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:581,availability,avail,available,581,"Hi @kokyriakidis . That reference should mask the PAR regions. It's unclear what could be going on for those variants which DeepVariant calls. They may be FP variants in difficult regions, or could be positions where additional copies exist that are similar on autosomes. In general, there are always likely to be some calls made on chrY. For reference, the New York Genome Center has sequenced all 1000genomes at 30x coverage and mapped to hg38. For the NA12878 (a female sample), GATK4 makes 6,935 heterozygous variant calls and 6,422 homozygous variant calls. (This VCF file is available at: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20190425_NYGC_GATK/raw_calls/CEU/Sample_NA12878/analysis/NA12878.haplotypeCalls.er.raw.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:581,reliability,availab,available,581,"Hi @kokyriakidis . That reference should mask the PAR regions. It's unclear what could be going on for those variants which DeepVariant calls. They may be FP variants in difficult regions, or could be positions where additional copies exist that are similar on autosomes. In general, there are always likely to be some calls made on chrY. For reference, the New York Genome Center has sequenced all 1000genomes at 30x coverage and mapped to hg38. For the NA12878 (a female sample), GATK4 makes 6,935 heterozygous variant calls and 6,422 homozygous variant calls. (This VCF file is available at: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20190425_NYGC_GATK/raw_calls/CEU/Sample_NA12878/analysis/NA12878.haplotypeCalls.er.raw.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:581,safety,avail,available,581,"Hi @kokyriakidis . That reference should mask the PAR regions. It's unclear what could be going on for those variants which DeepVariant calls. They may be FP variants in difficult regions, or could be positions where additional copies exist that are similar on autosomes. In general, there are always likely to be some calls made on chrY. For reference, the New York Genome Center has sequenced all 1000genomes at 30x coverage and mapped to hg38. For the NA12878 (a female sample), GATK4 makes 6,935 heterozygous variant calls and 6,422 homozygous variant calls. (This VCF file is available at: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20190425_NYGC_GATK/raw_calls/CEU/Sample_NA12878/analysis/NA12878.haplotypeCalls.er.raw.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:581,security,availab,available,581,"Hi @kokyriakidis . That reference should mask the PAR regions. It's unclear what could be going on for those variants which DeepVariant calls. They may be FP variants in difficult regions, or could be positions where additional copies exist that are similar on autosomes. In general, there are always likely to be some calls made on chrY. For reference, the New York Genome Center has sequenced all 1000genomes at 30x coverage and mapped to hg38. For the NA12878 (a female sample), GATK4 makes 6,935 heterozygous variant calls and 6,422 homozygous variant calls. (This VCF file is available at: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20190425_NYGC_GATK/raw_calls/CEU/Sample_NA12878/analysis/NA12878.haplotypeCalls.er.raw.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:418,testability,coverag,coverage,418,"Hi @kokyriakidis . That reference should mask the PAR regions. It's unclear what could be going on for those variants which DeepVariant calls. They may be FP variants in difficult regions, or could be positions where additional copies exist that are similar on autosomes. In general, there are always likely to be some calls made on chrY. For reference, the New York Genome Center has sequenced all 1000genomes at 30x coverage and mapped to hg38. For the NA12878 (a female sample), GATK4 makes 6,935 heterozygous variant calls and 6,422 homozygous variant calls. (This VCF file is available at: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20190425_NYGC_GATK/raw_calls/CEU/Sample_NA12878/analysis/NA12878.haplotypeCalls.er.raw.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/197:123,reliability,Doe,Does,123,There are many moving parts in DeepVariant to understand all that is going on code-wise. So let's start at a easier level. Does the following article help: https://blog.dnanexus.com/2019-02-19-deep-dive-into-deepvariant/.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:46,testability,understand,understand,46,There are many moving parts in DeepVariant to understand all that is going on code-wise. So let's start at a easier level. Does the following article help: https://blog.dnanexus.com/2019-02-19-deep-dive-into-deepvariant/.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:150,usability,help,help,150,There are many moving parts in DeepVariant to understand all that is going on code-wise. So let's start at a easier level. Does the following article help: https://blog.dnanexus.com/2019-02-19-deep-dive-into-deepvariant/.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:409,performance,content,content,409,"Thanks very much for pointing me to the blog. It is extremely well-written and very helpful. However, it raised another question for me. In the blog, it mentions how multiple alternative alleles are treated at a site - stating that for each alternative allele combination, an image is generated. This means, more than two alleles may be considered at a site. In the DeepVariant paper (https://www.biorxiv.org/content/biorxiv/early/2018/03/20/092890.full.pdf) it is mentioned, ""Candidate haplotypes are generated by traversing the assembly graphs and the top. two most likely haplotypes are selected which best explain the read evidence."" At the time of reading this, I believed that this meant only the top two alleles at a site are considered for example generation, since top-two haplotypes will enforce having only two alleles at a site. . However, it seems to me, after reading the blog, that the candidate haplotype generation is used only to reinterpret the CIGAR strings, and during pileup read generation, the ""top-two candidates"" have no relevance and all alternative alleles are considered for example generation. Is this correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:645,performance,time,time,645,"Thanks very much for pointing me to the blog. It is extremely well-written and very helpful. However, it raised another question for me. In the blog, it mentions how multiple alternative alleles are treated at a site - stating that for each alternative allele combination, an image is generated. This means, more than two alleles may be considered at a site. In the DeepVariant paper (https://www.biorxiv.org/content/biorxiv/early/2018/03/20/092890.full.pdf) it is mentioned, ""Candidate haplotypes are generated by traversing the assembly graphs and the top. two most likely haplotypes are selected which best explain the read evidence."" At the time of reading this, I believed that this meant only the top two alleles at a site are considered for example generation, since top-two haplotypes will enforce having only two alleles at a site. . However, it seems to me, after reading the blog, that the candidate haplotype generation is used only to reinterpret the CIGAR strings, and during pileup read generation, the ""top-two candidates"" have no relevance and all alternative alleles are considered for example generation. Is this correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:84,usability,help,helpful,84,"Thanks very much for pointing me to the blog. It is extremely well-written and very helpful. However, it raised another question for me. In the blog, it mentions how multiple alternative alleles are treated at a site - stating that for each alternative allele combination, an image is generated. This means, more than two alleles may be considered at a site. In the DeepVariant paper (https://www.biorxiv.org/content/biorxiv/early/2018/03/20/092890.full.pdf) it is mentioned, ""Candidate haplotypes are generated by traversing the assembly graphs and the top. two most likely haplotypes are selected which best explain the read evidence."" At the time of reading this, I believed that this meant only the top two alleles at a site are considered for example generation, since top-two haplotypes will enforce having only two alleles at a site. . However, it seems to me, after reading the blog, that the candidate haplotype generation is used only to reinterpret the CIGAR strings, and during pileup read generation, the ""top-two candidates"" have no relevance and all alternative alleles are considered for example generation. Is this correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:106,deployability,log,logic,106,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:395,deployability,log,logic,395,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:483,deployability,log,logic,483,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:200,interoperability,Specif,Specifically,200,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:106,safety,log,logic,106,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:395,safety,log,logic,395,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:483,safety,log,logic,483,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:106,security,log,logic,106,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:395,security,log,logic,395,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:483,security,log,logic,483,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:106,testability,log,logic,106,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:395,testability,log,logic,395,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:483,testability,log,logic,483,"Hi @anands-repo ,. to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py. Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them. As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:383,availability,error,error,383,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1649,availability,error,error,1649,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:23,deployability,version,version,23,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:866,deployability,updat,update,866,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:644,energy efficiency,optim,optimized,644,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1416,energy efficiency,predict,predict,1416,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1695,energy efficiency,model,model,1695,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1750,energy efficiency,predict,predict,1750,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:23,integrability,version,version,23,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:23,modifiability,version,version,23,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:383,performance,error,error,383,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:644,performance,optimiz,optimized,644,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1099,performance,perform,performed,1099," out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1649,performance,error,error,1649,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:383,safety,error,error,383,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:866,safety,updat,update,866,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1416,safety,predict,predict,1416,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1649,safety,error,error,1649,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1750,safety,predict,predict,1750,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:866,security,updat,update,866,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1695,security,model,model,1695,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:383,usability,error,error,383,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:971,usability,close,closest-truth,971,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the gener",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1099,usability,perform,performed,1099," out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1649,usability,error,error,1649,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1678,usability,learn,learning,1678,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1816,usability,help,help,1816,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1979,usability,document,document,1979,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:2129,usability,help,help,2129,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:2167,usability,help,helps,2167,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py . https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:790,deployability,stage,stage,790,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:823,deployability,releas,release,823,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:299,energy efficiency,model,model,299,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:831,energy efficiency,model,models,831,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1282,integrability,FILTER,FILTER,1282,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:292,modifiability,Pac,PacBio,292,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:161,reliability,doe,does,161,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:299,security,model,model,299,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:831,security,model,models,831,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:204,usability,help,helpful,204,"Overall, I feel like this thread has mentioned a few different things that in my mind are pretty different. Realigner, ( @pgrosu 's pointer 2. 4. above) , which does a local realignment, which was proven helpful especially for our Indel accuracy. Note that this was turned off by default for PacBio model. This is something that @akolesnikov will be able to answer more questions on. How candidates are proposed (which seems to be the main question at the initial question) is based on set of thresholds, which can be adjusted with these flags:. https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py#L189-L202. If you change these thresholds in your make_examples during calling, you will be able to get different number of candidates proposed in the `make_examples` stage. But note that our default release models are trained with examples based on the default thresholds. @pgrosu 's pointer 6 above is the pointer of how these initial set of candidates are proposed before they're passed to the classifier (used in `call_variants` step). And in fact, if you look at the final output VCF at the end, it should include all the candidates. If the classifier decided a candidate is not actually a variant, it will get a `0/0` genotype and have ""RefCall"" in its FILTER field. @anands-repo , I'm not sure if my answer and Paul's answer cover everything you want to ask now. If not, feel free to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:131,availability,consist,consists,131,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1374,deployability,resourc,resources,1374,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1147,energy efficiency,predict,predictions,1147,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1317,energy efficiency,predict,predictions,1317,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1374,energy efficiency,resourc,resources,1374,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:48,integrability,sub,substantially,48,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:194,performance,perform,performing,194,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:347,performance,perform,perform,347,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1374,performance,resourc,resources,1374,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:231,safety,detect,detection,231,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1147,safety,predict,predictions,1147,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1317,safety,predict,predictions,1317,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1374,safety,resourc,resources,1374,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:231,security,detect,detection,231,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:34,testability,understand,understanding,34,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:765,testability,simpl,simply,765,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:934,testability,understand,understand,934,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1374,testability,resourc,resources,1374,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:131,usability,consist,consists,131,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:194,usability,perform,performing,194,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:347,usability,perform,perform,347,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:765,usability,simpl,simply,765,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:1261,usability,guidanc,guidance,1261,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/198:211,availability,checkpoint,checkpoints,211,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:262,availability,checkpoint,checkpoint,262,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:306,availability,checkpoint,checkpoint,306,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:355,availability,checkpoint,checkpoints,355,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:448,availability,restor,restored,448,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:462,availability,checkpoint,checkpoint,462,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:31,energy efficiency,Estimat,Estimator,31,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:94,energy efficiency,estimat,estimator,94,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:104,energy efficiency,Estimat,Estimator,104,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:164,energy efficiency,Estimat,Estimator,164,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:253,interoperability,specif,specific,253,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:422,modifiability,Variab,Variables,422,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:211,reliability,checkpoint,checkpoints,211,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:262,reliability,checkpoint,checkpoint,262,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:306,reliability,checkpoint,checkpoint,306,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:355,reliability,checkpoint,checkpoints,355,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:448,reliability,restor,restored,448,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:462,reliability,checkpoint,checkpoint,462,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:142,testability,simpl,simple,142,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:142,usability,simpl,simple,142,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:482,usability,help,helps,482,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps. Alexey.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/199:12,deployability,version,version,12,What Python version do you have installed?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:32,deployability,instal,installed,32,What Python version do you have installed?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:12,integrability,version,version,12,What Python version do you have installed?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:12,modifiability,version,version,12,What Python version do you have installed?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:107,deployability,instal,install,107,"Thanks @akolesnikov for responding! . I'm running Python `Python 2.7.15+`. This was on a fresh Ubuntu 14.4 install, using your default settings in DeepVariant v0.8/master and running `./build-prereq.sh` followed by `./build_and_test.sh`. What I'm confused by is that `bazel-bin/deepvariant/make_examples_test` runs and everything passes... ```. $ bazel-bin/deepvariant/make_examples_test. Running tests under Python 2.7.15: /usr/bin/python. ... . ----------------------------------------------------------------------. Ran 101 tests in 6.501s. OK. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:186,deployability,build,build-prereq,186,"Thanks @akolesnikov for responding! . I'm running Python `Python 2.7.15+`. This was on a fresh Ubuntu 14.4 install, using your default settings in DeepVariant v0.8/master and running `./build-prereq.sh` followed by `./build_and_test.sh`. What I'm confused by is that `bazel-bin/deepvariant/make_examples_test` runs and everything passes... ```. $ bazel-bin/deepvariant/make_examples_test. Running tests under Python 2.7.15: /usr/bin/python. ... . ----------------------------------------------------------------------. Ran 101 tests in 6.501s. OK. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:397,safety,test,tests,397,"Thanks @akolesnikov for responding! . I'm running Python `Python 2.7.15+`. This was on a fresh Ubuntu 14.4 install, using your default settings in DeepVariant v0.8/master and running `./build-prereq.sh` followed by `./build_and_test.sh`. What I'm confused by is that `bazel-bin/deepvariant/make_examples_test` runs and everything passes... ```. $ bazel-bin/deepvariant/make_examples_test. Running tests under Python 2.7.15: /usr/bin/python. ... . ----------------------------------------------------------------------. Ran 101 tests in 6.501s. OK. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:527,safety,test,tests,527,"Thanks @akolesnikov for responding! . I'm running Python `Python 2.7.15+`. This was on a fresh Ubuntu 14.4 install, using your default settings in DeepVariant v0.8/master and running `./build-prereq.sh` followed by `./build_and_test.sh`. What I'm confused by is that `bazel-bin/deepvariant/make_examples_test` runs and everything passes... ```. $ bazel-bin/deepvariant/make_examples_test. Running tests under Python 2.7.15: /usr/bin/python. ... . ----------------------------------------------------------------------. Ran 101 tests in 6.501s. OK. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:397,testability,test,tests,397,"Thanks @akolesnikov for responding! . I'm running Python `Python 2.7.15+`. This was on a fresh Ubuntu 14.4 install, using your default settings in DeepVariant v0.8/master and running `./build-prereq.sh` followed by `./build_and_test.sh`. What I'm confused by is that `bazel-bin/deepvariant/make_examples_test` runs and everything passes... ```. $ bazel-bin/deepvariant/make_examples_test. Running tests under Python 2.7.15: /usr/bin/python. ... . ----------------------------------------------------------------------. Ran 101 tests in 6.501s. OK. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:527,testability,test,tests,527,"Thanks @akolesnikov for responding! . I'm running Python `Python 2.7.15+`. This was on a fresh Ubuntu 14.4 install, using your default settings in DeepVariant v0.8/master and running `./build-prereq.sh` followed by `./build_and_test.sh`. What I'm confused by is that `bazel-bin/deepvariant/make_examples_test` runs and everything passes... ```. $ bazel-bin/deepvariant/make_examples_test. Running tests under Python 2.7.15: /usr/bin/python. ... . ----------------------------------------------------------------------. Ran 101 tests in 6.501s. OK. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:68,deployability,Roll,Roll,68,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:90,deployability,version,version,90,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:326,deployability,contain,container,326,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:90,integrability,version,version,90,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:90,modifiability,version,version,90,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:109,modifiability,paramet,parameters,109,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:252,safety,test,test,252,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:252,testability,test,test,252,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:51,usability,command,commands,51,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:280,usability,command,command,280,"@akolesnikov do you have any suggestions for other commands to try? Roll back to previous version? Different parameters passed to the function? Other ways to run the Python code? I am not very familair with `Bazel` to be honest. Just confusing how the test pass, and *same exact* command works when running from pulled Docker container... . Happy to provide more details. Any ideas? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:4,deployability,build,build,4,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:111,deployability,version,version,111,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:111,integrability,version,version,111,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:111,modifiability,version,version,111,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:14,safety,test,test,14,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:23,safety,test,tested,23,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:63,safety,test,test,63,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:14,testability,test,test,14,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:23,testability,test,tested,23,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:63,testability,test,test,63,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4. Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:8,deployability,releas,release,8,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:55,deployability,version,version,55,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:211,deployability,releas,release,211,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:55,integrability,version,version,55,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:55,modifiability,version,version,55,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:197,safety,review,review,197,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:271,safety,test,tests,271,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:257,security,loss,loss,257,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:197,testability,review,review,197,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:271,testability,test,tests,271,"`[bazel release 0.21.0]` -- should I try a more recent version? I believe this was prescribed by default `settings.sh`. https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:143,availability,down,downgrade,143,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks! `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:167,deployability,version,version,167,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks! `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:167,integrability,version,version,167,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks! `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:167,modifiability,version,version,167,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks! `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:83,safety,test,test,83,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks! `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:83,testability,test,test,83,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks! `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:101,availability,error,error,101,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:139,deployability,build,building,139,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:294,deployability,version,version,294,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:107,integrability,messag,message,107,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:294,integrability,version,version,294,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:107,interoperability,messag,message,107,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:294,modifiability,version,version,294,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:101,performance,error,error,101,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:101,safety,error,error,101,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:26,security,team,teammate,26,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:101,usability,error,error,101,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:641,deployability,releas,release,641,"Quick answer: Can you try `./build_release_binaries.sh` instead of `./build_and_test.sh` in your steps above? Then it should work. The issue you're encountering has nothing to do with Ubuntu 18. ----. More details:. Earlier today, @akolesnikov and I were just wondering why our internal tests didn't capture this. We have daily tests that run scripts like this:. https://github.com/google/deepvariant/blob/r0.8/scripts/run_wes_case_study_binaries.sh. After checking what that script was doing, I found out that if you run `scripts/run_wes_case_study_binaries.sh`, it'll work on both Ubuntu 16 and 18. We'll fix build_and_test.sh in the next release. Thanks for reporting! . If using `build_release_binaries.sh` still doesn't work for you, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:717,reliability,doe,doesn,717,"Quick answer: Can you try `./build_release_binaries.sh` instead of `./build_and_test.sh` in your steps above? Then it should work. The issue you're encountering has nothing to do with Ubuntu 18. ----. More details:. Earlier today, @akolesnikov and I were just wondering why our internal tests didn't capture this. We have daily tests that run scripts like this:. https://github.com/google/deepvariant/blob/r0.8/scripts/run_wes_case_study_binaries.sh. After checking what that script was doing, I found out that if you run `scripts/run_wes_case_study_binaries.sh`, it'll work on both Ubuntu 16 and 18. We'll fix build_and_test.sh in the next release. Thanks for reporting! . If using `build_release_binaries.sh` still doesn't work for you, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:287,safety,test,tests,287,"Quick answer: Can you try `./build_release_binaries.sh` instead of `./build_and_test.sh` in your steps above? Then it should work. The issue you're encountering has nothing to do with Ubuntu 18. ----. More details:. Earlier today, @akolesnikov and I were just wondering why our internal tests didn't capture this. We have daily tests that run scripts like this:. https://github.com/google/deepvariant/blob/r0.8/scripts/run_wes_case_study_binaries.sh. After checking what that script was doing, I found out that if you run `scripts/run_wes_case_study_binaries.sh`, it'll work on both Ubuntu 16 and 18. We'll fix build_and_test.sh in the next release. Thanks for reporting! . If using `build_release_binaries.sh` still doesn't work for you, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:328,safety,test,tests,328,"Quick answer: Can you try `./build_release_binaries.sh` instead of `./build_and_test.sh` in your steps above? Then it should work. The issue you're encountering has nothing to do with Ubuntu 18. ----. More details:. Earlier today, @akolesnikov and I were just wondering why our internal tests didn't capture this. We have daily tests that run scripts like this:. https://github.com/google/deepvariant/blob/r0.8/scripts/run_wes_case_study_binaries.sh. After checking what that script was doing, I found out that if you run `scripts/run_wes_case_study_binaries.sh`, it'll work on both Ubuntu 16 and 18. We'll fix build_and_test.sh in the next release. Thanks for reporting! . If using `build_release_binaries.sh` still doesn't work for you, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:287,testability,test,tests,287,"Quick answer: Can you try `./build_release_binaries.sh` instead of `./build_and_test.sh` in your steps above? Then it should work. The issue you're encountering has nothing to do with Ubuntu 18. ----. More details:. Earlier today, @akolesnikov and I were just wondering why our internal tests didn't capture this. We have daily tests that run scripts like this:. https://github.com/google/deepvariant/blob/r0.8/scripts/run_wes_case_study_binaries.sh. After checking what that script was doing, I found out that if you run `scripts/run_wes_case_study_binaries.sh`, it'll work on both Ubuntu 16 and 18. We'll fix build_and_test.sh in the next release. Thanks for reporting! . If using `build_release_binaries.sh` still doesn't work for you, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:328,testability,test,tests,328,"Quick answer: Can you try `./build_release_binaries.sh` instead of `./build_and_test.sh` in your steps above? Then it should work. The issue you're encountering has nothing to do with Ubuntu 18. ----. More details:. Earlier today, @akolesnikov and I were just wondering why our internal tests didn't capture this. We have daily tests that run scripts like this:. https://github.com/google/deepvariant/blob/r0.8/scripts/run_wes_case_study_binaries.sh. After checking what that script was doing, I found out that if you run `scripts/run_wes_case_study_binaries.sh`, it'll work on both Ubuntu 16 and 18. We'll fix build_and_test.sh in the next release. Thanks for reporting! . If using `build_release_binaries.sh` still doesn't work for you, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:125,usability,document,documentation,125,"Thanks @pichuan and @akolesnikov -- indeed you're right `./build_release_binaries.sh` solves this. Not sure what part of the documentation I missed, but indeed it's working now. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:76,availability,consist,consistent,76,@moscow25 I don't think you missed anything; we just forgot to keep scripts consistent. Thanks for your report and we'll make sure to fix it in the future!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:76,usability,consist,consistent,76,@moscow25 I don't think you missed anything; we just forgot to keep scripts consistent. Thanks for your report and we'll make sure to fix it in the future!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:52,reliability,doe,does,52,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:826,reliability,doe,does,826,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:57,safety,compl,complete,57,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:369,safety,test,testdata,369,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:682,safety,test,testdata,682,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:57,security,compl,complete,57,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:369,testability,test,testdata,369,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:394,testability,unit,unittest,394,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:682,testability,test,testdata,682,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:707,testability,unit,unittest,707,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:154,usability,command,command,154,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:729,performance,content,content,729,"Hi @animesh . I'm not sure you meant exactly. Do you mean that in two different places of our documentation, we used `quickstart-output/examples.tfrecord.vcf` and `quickstart-output/examples.vcf`? I did a quick search on our Quick Start, but couldn't find it. (BTW, I noticed that Quick Start mentioned ""docker_entrypoint.py"", which has been renamed to https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py . In case you're looking for that). If you are asking whether the two commands you posted are different. It seems to me the only difference is the output file name is different. So, first run should give you a VCF file with name `examples.tfrecord.vcf`, second should give you `examples.vcf`, but the content should be exactly the same. If that's not what you're asking, please feel free to post again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:94,usability,document,documentation,94,"Hi @animesh . I'm not sure you meant exactly. Do you mean that in two different places of our documentation, we used `quickstart-output/examples.tfrecord.vcf` and `quickstart-output/examples.vcf`? I did a quick search on our Quick Start, but couldn't find it. (BTW, I noticed that Quick Start mentioned ""docker_entrypoint.py"", which has been renamed to https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py . In case you're looking for that). If you are asking whether the two commands you posted are different. It seems to me the only difference is the output file name is different. So, first run should give you a VCF file with name `examples.tfrecord.vcf`, second should give you `examples.vcf`, but the content should be exactly the same. If that's not what you're asking, please feel free to post again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:498,usability,command,commands,498,"Hi @animesh . I'm not sure you meant exactly. Do you mean that in two different places of our documentation, we used `quickstart-output/examples.tfrecord.vcf` and `quickstart-output/examples.vcf`? I did a quick search on our Quick Start, but couldn't find it. (BTW, I noticed that Quick Start mentioned ""docker_entrypoint.py"", which has been renamed to https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py . In case you're looking for that). If you are asking whether the two commands you posted are different. It seems to me the only difference is the output file name is different. So, first run should give you a VCF file with name `examples.tfrecord.vcf`, second should give you `examples.vcf`, but the content should be exactly the same. If that's not what you're asking, please feel free to post again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:967,availability,error,error,967,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:74,deployability,build,build-prereq,74,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:172,deployability,releas,release,172,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:716,deployability,version,version,716,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:864,deployability,build,building,864,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:716,integrability,version,version,716,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:560,modifiability,layer,layer,560,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:716,modifiability,version,version,716,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:967,performance,error,error,967,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:967,safety,error,error,967,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:141,usability,user,user,141,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:967,usability,error,error,967,"Hi @kokyriakidis ,. in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:. https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:. 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested? 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/200:170,energy efficiency,cloud,cloud,170,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:377,energy efficiency,current,currently,377,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:647,energy efficiency,current,current,647,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:789,energy efficiency,model,models,789,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:1006,energy efficiency,model,models,1006,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:1060,energy efficiency,model,model,1060,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:1089,energy efficiency,model,model,1089,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:802,interoperability,specif,specific,802,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:985,interoperability,specif,specific-deepvariant-models,985,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:529,performance,perform,perform,529,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:592,performance,perform,perform,592,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:789,security,model,models,789,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:1006,security,model,models,1006,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:1060,security,model,model,1060,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:1089,security,model,model,1089,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:48,testability,plan,plant,48,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:1054,testability,plan,plant,1054,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:502,usability,clear,clear,502,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:529,usability,perform,perform,529,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:592,usability,perform,perform,592,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/201:368,availability,robust,robust,368,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:357,deployability,build,build,357,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:494,deployability,releas,released,494,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:506,deployability,version,version,506,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:225,energy efficiency,model,model,225,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:473,energy efficiency,model,model,473,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:97,integrability,pub,publication,97,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:247,integrability,Sub,Subsequent,247,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:266,integrability,pub,publication,266,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:506,integrability,version,version,506,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:234,modifiability,Pac,PacBio,234,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:279,modifiability,Pac,PacBio,279,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:301,modifiability,extens,extensive,301,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:506,modifiability,version,version,506,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:134,performance,content,content,134,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:368,reliability,robust,robust,368,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:368,safety,robust,robust,368,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:225,security,model,model,225,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:473,security,model,model,473,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:419,testability,coverag,coverage,419,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:71,availability,avail,available,71,Thanks for the clarification. Is the new PacBio training data publicly available? I apologize if this is described somewhere and I didn't find it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:62,integrability,pub,publicly,62,Thanks for the clarification. Is the new PacBio training data publicly available? I apologize if this is described somewhere and I didn't find it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:41,modifiability,Pac,PacBio,41,Thanks for the clarification. Is the new PacBio training data publicly available? I apologize if this is described somewhere and I didn't find it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:71,reliability,availab,available,71,Thanks for the clarification. Is the new PacBio training data publicly available? I apologize if this is described somewhere and I didn't find it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:71,safety,avail,available,71,Thanks for the clarification. Is the new PacBio training data publicly available? I apologize if this is described somewhere and I didn't find it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:71,security,availab,available,71,Thanks for the clarification. Is the new PacBio training data publicly available? I apologize if this is described somewhere and I didn't find it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:46,availability,avail,available,46,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:87,availability,avail,available,87,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:37,integrability,pub,publicly,37,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:9,performance,content,content,9,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:703,performance,time,time,703,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:46,reliability,availab,available,46,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:87,reliability,availab,available,87,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:46,safety,avail,available,46,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:87,safety,avail,available,87,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:46,security,availab,available,46,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:87,security,availab,available,87,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:154,testability,trace,trace,154,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:407,testability,trace,trace,407,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:532,testability,trace,trace,532,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - . . ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/202:921,availability,consist,consistently,921,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:698,deployability,log,logic,698,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:439,integrability,event,event,439,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:502,integrability,event,events,502,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:123,safety,input,input,123,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:216,safety,input,input,216,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:698,safety,log,logic,698,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:521,security,ident,identical,521,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:698,security,log,logic,698,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:450,testability,simpl,simple,450,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:485,testability,understand,understand,485,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:698,testability,log,logic,698,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:68,usability,behavi,behavior,68,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:123,usability,input,input,123,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:216,usability,input,input,216,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:268,usability,behavi,behavior,268,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:316,usability,behavi,behavior,316,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:450,usability,simpl,simple,450,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:612,usability,user,users,612,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:676,usability,close,closely,676,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:735,usability,tool,tools,735,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:819,usability,behavi,behavior,819,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:907,usability,behavi,behavior,907,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:921,usability,consist,consistently,921,"Hi @aderzelle . First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```. 90123. TGGGT. T--GTTC <-- Sample 1. TGTTC <-- Sample 2. ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/203:27,usability,learn,learning,27,I'm not sure I see how the learning rate or batch_size would affect those metrics -- could you provide more information on your setup? And the two cases you are seeing -- are those randomly occurring or have you pinpointed why it flips one way or the other?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:660,availability,checkpoint,checkpoints,660,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2949,availability,error,error,2949,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1029,deployability,observ,observe,1029,"ting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier),",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1462,deployability,releas,release,1462,"nd (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1831,deployability,depend,depends,1831,"rue Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals so",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:797,energy efficiency,model,model,797,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:938,energy efficiency,model,model,938,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:385,integrability,batch,batch,385,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1831,integrability,depend,depends,1831,"rue Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals so",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2513,integrability,wrap,wrapped,2513,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1129,interoperability,distribut,distribution,1129,"n the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1651,interoperability,distribut,distribution,1651,"he checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2071,interoperability,specif,specific,2071,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2203,interoperability,distribut,distribution,2203,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2317,interoperability,distribut,distribution,2317,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1831,modifiability,depend,depends,1831,"rue Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals so",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:385,performance,batch,batch,385,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2949,performance,error,error,2949,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:660,reliability,checkpoint,checkpoints,660,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1831,safety,depend,depends,1831,"rue Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals so",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2949,safety,error,error,2949,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:797,security,model,model,797,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:938,security,model,model,938,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2118,security,team,team,2118,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1029,testability,observ,observe,1029,"ting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier),",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1831,testability,depend,depends,1831,"rue Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals so",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:150,usability,behavi,behavior,150,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:292,usability,help,help,292,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:306,usability,progress,progress,306,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:364,usability,learn,learning,364,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:893,usability,indicat,indicate,893,"Hi @melkerdawy , thanks for reporting this issue. In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1086,usability,behavi,behavior,1086,"e developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your da",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2130,usability,help,help,2130,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2580,usability,tool,tool,2580,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:2949,usability,error,error,2949,"ven dig deeper into the training behavior, can you check this:. What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files. To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:. ```. class 0, count: 101,679,899. class 1, count: 145,911,730. class 2, count: 98,914,057. ```. There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for. DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error. Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/204:359,deployability,continu,continued,359,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:589,deployability,releas,releasing,589,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:759,deployability,releas,release,759,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:1003,deployability,releas,released,1003,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:174,energy efficiency,model,models,174,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:241,energy efficiency,model,model,241,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:532,energy efficiency,model,model,532,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:606,energy efficiency,model,model,606,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:646,energy efficiency,model,model,646,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:689,energy efficiency,current,currently,689,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:728,energy efficiency,reduc,reduce,728,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:749,energy efficiency,model,models,749,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:832,energy efficiency,model,model,832,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:900,energy efficiency,Current,Currently,900,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:916,energy efficiency,optim,optimizing,916,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:931,energy efficiency,model,model,931,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:1012,energy efficiency,model,models,1012,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:153,interoperability,specif,specific-deepvariant-models,153,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:566,interoperability,specif,specific,566,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:773,modifiability,maintain,maintaining,773,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:862,modifiability,scenario,scenarios,862,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:250,performance,perform,perform,250,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:575,performance,time,timeframe,575,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:916,performance,optimiz,optimizing,916,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:773,safety,maintain,maintaining,773,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:174,security,model,models,174,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:241,security,model,model,241,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:532,security,model,model,532,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:606,security,model,model,606,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:646,security,model,model,646,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:749,security,model,models,749,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:832,security,model,model,832,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:931,security,model,model,931,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:1012,security,model,models,1012,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:250,usability,perform,perform,250,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:457,usability,learn,learns,457,"Hi,. Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/205:605,energy efficiency,model,model,605,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:303,interoperability,specif,specifically,303,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:598,modifiability,Pac,PacBio,598,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:574,reliability,doe,does,574,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:621,reliability,doe,does,621,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:357,safety,Compl,Complete-Striped-Smith-Waterman-Library,357,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:681,safety,compl,complex,681,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:357,security,Compl,Complete-Striped-Smith-Waterman-Library,357,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:605,security,model,model,605,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:681,security,compl,complex,681,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/205:45,usability,effectiv,effectively,45,"Hi @aardes . DeepVariant uses processes that effectively normalize variants in most or all cases in the process of running. As part of candidate generation, DeepVariant constructs a candidate haplotype for the reference and alternate alleles. Reads are aligned to these candidates using Smith Waterman (specifically this library: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library). The candidate position reported in the VCF is taken from the realigned location, so this will be normalized as a function of how the SSW library works. Note that this process does not occur with the PacBio model, since it does not do reassembly. Finally, variant normalization is a complex area with many edge cases to compare between two files. When we do comparisons (like between DeepVariant and the Genome in a Bottle Truth sets) we use the hap.py + RTG in the hap.py Docker image (https://github.com/Illumina/hap.py). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/206:16,usability,close,close,16,"@bballew I will close this issue for now, but feel free to reopen if you have any other questions. [Here is a link](https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py#L308) to the `compute_quals` function.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/206
https://github.com/google/deepvariant/issues/207:334,availability,error,error,334,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:142,deployability,fail,fail,142,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:305,deployability,fail,failed,305,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:347,energy efficiency,model,model,347,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:334,performance,error,error,334,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:142,reliability,fail,fail,142,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:305,reliability,fail,failed,305,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:334,safety,error,error,334,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:347,security,model,model,347,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:360,testability,plan,plan,360,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:189,usability,command,command,189,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:266,usability,help,helpful,266,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:334,usability,error,error,334,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:. * What is the command you used to run `make_examples`? Any additional output would also be helpful. * Is task 8 the only one that failed? * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:30,deployability,pipelin,pipeline,30,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1064,deployability,log,logs,1064,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1088,deployability,fail,failed,1088,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:74,energy efficiency,MODEL,MODEL,74,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:97,energy efficiency,model,models,97,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:544,energy efficiency,gpu,gpu,544,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:664,energy efficiency,model,model,664,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:673,energy efficiency,MODEL,MODEL,673,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:30,integrability,pipelin,pipeline,30,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:544,performance,gpu,gpu,544,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1088,reliability,fail,failed,1088,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1064,safety,log,logs,1064,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:74,security,MODEL,MODEL,74,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:97,security,model,models,97,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:664,security,model,model,664,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:673,security,MODEL,MODEL,673,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1064,security,log,logs,1064,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1064,testability,log,logs,1064,"Hi @gunjanbaid,. I'm starting pipeline with a GCP runner like this:. ```. MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard. IMAGE_VERSION=0.6.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones ""${ZONES}"" \. --docker_image ""${DOCKER_IMAGE}"" \. --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \. --gpu \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --ref ""${INPUT_REF}"" \. --bam ""${INPUT_BAM}"" \. --shards 512 \. --make_examples_workers 16 \. --make_examples_cores_per_worker 10 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 16 \. --call_variants_cores_per_worker 8 \. --call_variants_ram_per_worker_gb 30 \. --call_variants_disk_per_worker_gb 50. ```. I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:50,availability,failur,failure,50,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:214,availability,failur,failures,214,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:783,availability,error,error,783,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:50,deployability,fail,failure,50,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:97,deployability,releas,release,97,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:165,deployability,releas,release,165,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:214,deployability,fail,failures,214,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:274,deployability,updat,updated,274,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:495,deployability,contain,contains,495,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:295,energy efficiency,model,models,295,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:405,energy efficiency,cloud,cloud,405,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1048,energy efficiency,model,models,1048,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1165,energy efficiency,model,model,1165,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1454,energy efficiency,model,models,1454,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1478,energy efficiency,model,model,1478,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:789,integrability,messag,messages,789,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1491,integrability,pub,public,1491,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:789,interoperability,messag,messages,789,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1433,interoperability,specif,specific-deepvariant-models,1433,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1519,interoperability,share,share,1519,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:50,performance,failur,failure,50,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:214,performance,failur,failures,214,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:783,performance,error,error,783,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1280,performance,improved perform,improved performance,1280,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:50,reliability,fail,failure,50,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:214,reliability,fail,failures,214,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:274,safety,updat,updated,274,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:310,safety,sanit,sanity,310,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:783,safety,error,error,783,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:274,security,updat,updated,274,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:295,security,model,models,295,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:310,security,sanit,sanity,310,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1048,security,model,models,1048,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1165,security,model,model,1165,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1266,security,sign,significantly,1266,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1454,security,model,models,1454,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1478,security,model,model,1478,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:350,usability,command,command,350,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:783,usability,error,error,783,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:807,usability,help,helpful,807,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:853,usability,document,document,853,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1289,usability,perform,performance,1289,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:47,deployability,releas,release,47,"Hi @gunjanbaid, thank you! I'll try the v0.8.0 release and other recommendations. I’m working on a cannabis variants project with a Googler @allenday. We consulted @AndrewCarroll previously, from his preliminary analysis - seems that default DeepVariant model should work fine with our data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:254,energy efficiency,model,model,254,"Hi @gunjanbaid, thank you! I'll try the v0.8.0 release and other recommendations. I’m working on a cannabis variants project with a Googler @allenday. We consulted @AndrewCarroll previously, from his preliminary analysis - seems that default DeepVariant model should work fine with our data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:254,security,model,model,254,"Hi @gunjanbaid, thank you! I'll try the v0.8.0 release and other recommendations. I’m working on a cannabis variants project with a Googler @allenday. We consulted @AndrewCarroll previously, from his preliminary analysis - seems that default DeepVariant model should work fine with our data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:100,availability,error,errors,100,"@obsh sounds good. I'll close this issue for now, but feel free to reopen if you run into any other errors.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:100,performance,error,errors,100,"@obsh sounds good. I'll close this issue for now, but feel free to reopen if you run into any other errors.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:100,safety,error,errors,100,"@obsh sounds good. I'll close this issue for now, but feel free to reopen if you run into any other errors.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:24,usability,close,close,24,"@obsh sounds good. I'll close this issue for now, but feel free to reopen if you run into any other errors.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:100,usability,error,errors,100,"@obsh sounds good. I'll close this issue for now, but feel free to reopen if you run into any other errors.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/208:0,modifiability,Pac,PacBio,0,"PacBio reads are too long to perform a local assembly on them, therefore --norealign_reads flag has to be added.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:29,performance,perform,perform,29,"PacBio reads are too long to perform a local assembly on them, therefore --norealign_reads flag has to be added.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:29,usability,perform,perform,29,"PacBio reads are too long to perform a local assembly on them, therefore --norealign_reads flag has to be added.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:131,energy efficiency,model,model-case-study,131,There is a case study for PacBio data which may be helpful https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-pacbio-model-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:26,modifiability,Pac,PacBio,26,There is a case study for PacBio data which may be helpful https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-pacbio-model-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:124,modifiability,pac,pacbio-model-case-study,124,There is a case study for PacBio data which may be helpful https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-pacbio-model-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:131,security,model,model-case-study,131,There is a case study for PacBio data which may be helpful https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-pacbio-model-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:51,usability,help,helpful,51,There is a case study for PacBio data which may be helpful https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-pacbio-model-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/209:349,performance,content,content,349,"Hi @aderzelle . Something seems strange in these files. In the DeepVariant output, DeepVariant reports the Allele Depth at these positions as [600819]: 36,15 ; [600831]: 36,15 ; [600834]: 35,15. While the GATK output reports the positions as: [600819]: 49,0 ; [600831]: 49, 0 ; [600834]: 49,0. Those are quite different reports about the underlying content of the reads in the region.. DeepVariant conducts a re-assembly of the region, so it may be the case that the reassembler identifies a different haplotype. I think to be conclusive about these differences, we'd need to see the BAM. But we'd definitely be interested to take a look at this if you don't mind sharing.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:479,security,ident,identifies,479,"Hi @aderzelle . Something seems strange in these files. In the DeepVariant output, DeepVariant reports the Allele Depth at these positions as [600819]: 36,15 ; [600831]: 36,15 ; [600834]: 35,15. While the GATK output reports the positions as: [600819]: 49,0 ; [600831]: 49, 0 ; [600834]: 49,0. Those are quite different reports about the underlying content of the reads in the region.. DeepVariant conducts a re-assembly of the region, so it may be the case that the reassembler identifies a different haplotype. I think to be conclusive about these differences, we'd need to see the BAM. But we'd definitely be interested to take a look at this if you don't mind sharing.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:61,availability,down,download,61,"Hello,. it's ok for me to share, where should I send you the download link?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:26,interoperability,share,share,26,"Hello,. it's ok for me to share, where should I send you the download link?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:247,availability,replic,replicated,247,@AndrewCarroll You can get a sample bam from the initial discussion thread on the rtg-users group: https://groups.google.com/a/realtimegenomics.com/forum/#!topic/rtg-users/U0UQnR2LRtw. I just ran deepvariant 0.8.0 on the sample bam from there and replicated the results that @aderzelle reported. ![image](https://user-images.githubusercontent.com/282098/63824884-c6e58800-c9ac-11e9-8e26-9be5ba6a5a4b.png).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:156,integrability,topic,topic,156,@AndrewCarroll You can get a sample bam from the initial discussion thread on the rtg-users group: https://groups.google.com/a/realtimegenomics.com/forum/#!topic/rtg-users/U0UQnR2LRtw. I just ran deepvariant 0.8.0 on the sample bam from there and replicated the results that @aderzelle reported. ![image](https://user-images.githubusercontent.com/282098/63824884-c6e58800-c9ac-11e9-8e26-9be5ba6a5a4b.png).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:86,usability,user,users,86,@AndrewCarroll You can get a sample bam from the initial discussion thread on the rtg-users group: https://groups.google.com/a/realtimegenomics.com/forum/#!topic/rtg-users/U0UQnR2LRtw. I just ran deepvariant 0.8.0 on the sample bam from there and replicated the results that @aderzelle reported. ![image](https://user-images.githubusercontent.com/282098/63824884-c6e58800-c9ac-11e9-8e26-9be5ba6a5a4b.png).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:166,usability,user,users,166,@AndrewCarroll You can get a sample bam from the initial discussion thread on the rtg-users group: https://groups.google.com/a/realtimegenomics.com/forum/#!topic/rtg-users/U0UQnR2LRtw. I just ran deepvariant 0.8.0 on the sample bam from there and replicated the results that @aderzelle reported. ![image](https://user-images.githubusercontent.com/282098/63824884-c6e58800-c9ac-11e9-8e26-9be5ba6a5a4b.png).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:313,usability,user,user-images,313,@AndrewCarroll You can get a sample bam from the initial discussion thread on the rtg-users group: https://groups.google.com/a/realtimegenomics.com/forum/#!topic/rtg-users/U0UQnR2LRtw. I just ran deepvariant 0.8.0 on the sample bam from there and replicated the results that @aderzelle reported. ![image](https://user-images.githubusercontent.com/282098/63824884-c6e58800-c9ac-11e9-8e26-9be5ba6a5a4b.png).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:222,availability,consist,consistent,222,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:696,deployability,releas,release,696,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:119,integrability,event,event,119,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:667,performance,time,time,667,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:686,safety,test,test,686,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:409,testability,context,context,409,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:686,testability,test,test,686,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:104,usability,visual,visualize,104,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:222,usability,consist,consistent,222,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:480,usability,support,support,480,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:22,deployability,continu,continuing,22,"Hi @aderzelle , we're continuing to look into this issue. I'm leaving this open for now, and will give you an update later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:110,deployability,updat,update,110,"Hi @aderzelle , we're continuing to look into this issue. I'm leaving this open for now, and will give you an update later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:110,safety,updat,update,110,"Hi @aderzelle , we're continuing to look into this issue. I'm leaving this open for now, and will give you an update later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:110,security,updat,update,110,"Hi @aderzelle , we're continuing to look into this issue. I'm leaving this open for now, and will give you an update later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:35,deployability,updat,update,35,"Hi @pichuan . thanks a lot for the update. No worries ... in the meanwhile I am working on improving the genome assembly, it's a very complex one (in short, I haven't moved on forgetting about deepvariants ;) ).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:35,safety,updat,update,35,"Hi @pichuan . thanks a lot for the update. No worries ... in the meanwhile I am working on improving the genome assembly, it's a very complex one (in short, I haven't moved on forgetting about deepvariants ;) ).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:134,safety,compl,complex,134,"Hi @pichuan . thanks a lot for the update. No worries ... in the meanwhile I am working on improving the genome assembly, it's a very complex one (in short, I haven't moved on forgetting about deepvariants ;) ).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:35,security,updat,update,35,"Hi @pichuan . thanks a lot for the update. No worries ... in the meanwhile I am working on improving the genome assembly, it's a very complex one (in short, I haven't moved on forgetting about deepvariants ;) ).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:134,security,compl,complex,134,"Hi @pichuan . thanks a lot for the update. No worries ... in the meanwhile I am working on improving the genome assembly, it's a very complex one (in short, I haven't moved on forgetting about deepvariants ;) ).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1171,availability,avail,available,1171,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:25,deployability,releas,released,25,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:58,deployability,contain,contains,58,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:128,deployability,releas,release,128,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:273,deployability,observ,observed,273,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:104,energy efficiency,model,models,104,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:877,interoperability,Specif,Specifically,877,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1119,modifiability,paramet,parameter,1119,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1171,reliability,availab,available,1171,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:523,safety,valid,valid,523,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1171,safety,avail,available,1171,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:104,security,model,models,104,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1106,security,expos,exposed,1106,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1171,security,availab,available,1171,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:273,testability,observ,observed,273,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:553,usability,support,supports,553,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:711,usability,support,supported,711,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:759,usability,support,support,759,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1428,usability,feedback,feedback,1428,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1437,usability,confirm,confirming,1437,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:184,deployability,scale,scale,184,"Thanks a lot! . I am not surprised by your explanation, the organism I am working with is notoriously known to be a nightmare to assemble. Therefore I am not surprised at its ""little"" scale it fooled Deepvariant. . I will certainly let you know if the fix solved that kind of issues. In the meanwhile, we have sequenced more samples and are now refining our assembly. Therefore I am not planning to relaunch deepvariant in the coming weeks but it wil be done within a month. . thanks again for having looked into this issue and I will let you know if I come across other strange cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:184,energy efficiency,scale,scale,184,"Thanks a lot! . I am not surprised by your explanation, the organism I am working with is notoriously known to be a nightmare to assemble. Therefore I am not surprised at its ""little"" scale it fooled Deepvariant. . I will certainly let you know if the fix solved that kind of issues. In the meanwhile, we have sequenced more samples and are now refining our assembly. Therefore I am not planning to relaunch deepvariant in the coming weeks but it wil be done within a month. . thanks again for having looked into this issue and I will let you know if I come across other strange cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:184,modifiability,scal,scale,184,"Thanks a lot! . I am not surprised by your explanation, the organism I am working with is notoriously known to be a nightmare to assemble. Therefore I am not surprised at its ""little"" scale it fooled Deepvariant. . I will certainly let you know if the fix solved that kind of issues. In the meanwhile, we have sequenced more samples and are now refining our assembly. Therefore I am not planning to relaunch deepvariant in the coming weeks but it wil be done within a month. . thanks again for having looked into this issue and I will let you know if I come across other strange cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:184,performance,scale,scale,184,"Thanks a lot! . I am not surprised by your explanation, the organism I am working with is notoriously known to be a nightmare to assemble. Therefore I am not surprised at its ""little"" scale it fooled Deepvariant. . I will certainly let you know if the fix solved that kind of issues. In the meanwhile, we have sequenced more samples and are now refining our assembly. Therefore I am not planning to relaunch deepvariant in the coming weeks but it wil be done within a month. . thanks again for having looked into this issue and I will let you know if I come across other strange cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:387,testability,plan,planning,387,"Thanks a lot! . I am not surprised by your explanation, the organism I am working with is notoriously known to be a nightmare to assemble. Therefore I am not surprised at its ""little"" scale it fooled Deepvariant. . I will certainly let you know if the fix solved that kind of issues. In the meanwhile, we have sequenced more samples and are now refining our assembly. Therefore I am not planning to relaunch deepvariant in the coming weeks but it wil be done within a month. . thanks again for having looked into this issue and I will let you know if I come across other strange cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/210:139,deployability,pipelin,pipeline,139,"Hi @case3526, we recommend running DeepVariant v0.8.0 using the Docker image or prebuilt binaries, instead of the `gcp_deepvariant_runner` pipeline. Here are links to case studies that show how you can run using Docker or binaries. Note: we recommend running the binaries on an Ubuntu 16.04 machine. * [DeepVariant quickstart with Docker](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md). * [Script to run WGS case study using binaries](https://github.com/google/deepvariant/blob/r0.8/scripts/run_wgs_case_study_binaries.sh)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:139,integrability,pipelin,pipeline,139,"Hi @case3526, we recommend running DeepVariant v0.8.0 using the Docker image or prebuilt binaries, instead of the `gcp_deepvariant_runner` pipeline. Here are links to case studies that show how you can run using Docker or binaries. Note: we recommend running the binaries on an Ubuntu 16.04 machine. * [DeepVariant quickstart with Docker](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md). * [Script to run WGS case study using binaries](https://github.com/google/deepvariant/blob/r0.8/scripts/run_wgs_case_study_binaries.sh)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/211:4,energy efficiency,current,currently,4,"Hi, currently DeepVariant is a germline variant caller so it's not designed to call somatic variants in cancer samples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/211
https://github.com/google/deepvariant/issues/212:444,deployability,build,building,444,"Hi, I'm not sure I fully understand the question -- do any of the [3 Official Solutions](https://github.com/google/deepvariant#official-solutions) work for you? Using [the docker image](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) is the recommended way, but there are other options listed as well. If you don't want that, and the pre-built binary option (option 3) doesn't work, there is also the option of building your own binary from source (option 2).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:402,reliability,doe,doesn,402,"Hi, I'm not sure I fully understand the question -- do any of the [3 Official Solutions](https://github.com/google/deepvariant#official-solutions) work for you? Using [the docker image](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) is the recommended way, but there are other options listed as well. If you don't want that, and the pre-built binary option (option 3) doesn't work, there is also the option of building your own binary from source (option 2).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:25,testability,understand,understand,25,"Hi, I'm not sure I fully understand the question -- do any of the [3 Official Solutions](https://github.com/google/deepvariant#official-solutions) work for you? Using [the docker image](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) is the recommended way, but there are other options listed as well. If you don't want that, and the pre-built binary option (option 3) doesn't work, there is also the option of building your own binary from source (option 2).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:17,deployability,updat,update,17,"@hamidqaedi Just update the architecture to `--copt=-march=native` in [settings.sh](https://github.com/google/deepvariant/blob/r0.8/settings.sh#L102), and use the same option when compiling Tensorflow from source and you should be fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:28,interoperability,architectur,architecture,28,"@hamidqaedi Just update the architecture to `--copt=-march=native` in [settings.sh](https://github.com/google/deepvariant/blob/r0.8/settings.sh#L102), and use the same option when compiling Tensorflow from source and you should be fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:17,safety,updat,update,17,"@hamidqaedi Just update the architecture to `--copt=-march=native` in [settings.sh](https://github.com/google/deepvariant/blob/r0.8/settings.sh#L102), and use the same option when compiling Tensorflow from source and you should be fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:17,security,updat,update,17,"@hamidqaedi Just update the architecture to `--copt=-march=native` in [settings.sh](https://github.com/google/deepvariant/blob/r0.8/settings.sh#L102), and use the same option when compiling Tensorflow from source and you should be fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:143,energy efficiency,cpu,cpu,143,"Hi @pgrosu ,. Thank you for reply. Iwill check and let you know about. @sidharthgoel ,. Actually the question is , Does Deepvariant works on a cpu like what i have on my machine (Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors)? . Thank you guys for your time. Hamid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:196,energy efficiency,CPU,CPU,196,"Hi @pgrosu ,. Thank you for reply. Iwill check and let you know about. @sidharthgoel ,. Actually the question is , Does Deepvariant works on a cpu like what i have on my machine (Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors)? . Thank you guys for your time. Hamid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:143,performance,cpu,cpu,143,"Hi @pgrosu ,. Thank you for reply. Iwill check and let you know about. @sidharthgoel ,. Actually the question is , Does Deepvariant works on a cpu like what i have on my machine (Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors)? . Thank you guys for your time. Hamid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:196,performance,CPU,CPU,196,"Hi @pgrosu ,. Thank you for reply. Iwill check and let you know about. @sidharthgoel ,. Actually the question is , Does Deepvariant works on a cpu like what i have on my machine (Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors)? . Thank you guys for your time. Hamid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:258,performance,time,time,258,"Hi @pgrosu ,. Thank you for reply. Iwill check and let you know about. @sidharthgoel ,. Actually the question is , Does Deepvariant works on a cpu like what i have on my machine (Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors)? . Thank you guys for your time. Hamid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:115,reliability,Doe,Does,115,"Hi @pgrosu ,. Thank you for reply. Iwill check and let you know about. @sidharthgoel ,. Actually the question is , Does Deepvariant works on a cpu like what i have on my machine (Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors)? . Thank you guys for your time. Hamid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/213:20,reliability,doe,does,20,"HI,. 1) DeepVariant does not treat homopolymer repeats differently. So, to answer your question DeepVariant assign read to one of the alleles in this case. It is a known problem and we have plans to address it. If read does not completely overlap a homopolymer repeat then it should not be counted. 2) DeepVariant does local reassembly for some regions (decided by algorithm). In that case reads are realigned to the haplotype, not the reference. In your example with long insertion realigned read cigar will correctly support part of the insertion, and then allele_counter will work with the ""correct"" cigar.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:219,reliability,doe,does,219,"HI,. 1) DeepVariant does not treat homopolymer repeats differently. So, to answer your question DeepVariant assign read to one of the alleles in this case. It is a known problem and we have plans to address it. If read does not completely overlap a homopolymer repeat then it should not be counted. 2) DeepVariant does local reassembly for some regions (decided by algorithm). In that case reads are realigned to the haplotype, not the reference. In your example with long insertion realigned read cigar will correctly support part of the insertion, and then allele_counter will work with the ""correct"" cigar.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:314,reliability,doe,does,314,"HI,. 1) DeepVariant does not treat homopolymer repeats differently. So, to answer your question DeepVariant assign read to one of the alleles in this case. It is a known problem and we have plans to address it. If read does not completely overlap a homopolymer repeat then it should not be counted. 2) DeepVariant does local reassembly for some regions (decided by algorithm). In that case reads are realigned to the haplotype, not the reference. In your example with long insertion realigned read cigar will correctly support part of the insertion, and then allele_counter will work with the ""correct"" cigar.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:228,safety,compl,completely,228,"HI,. 1) DeepVariant does not treat homopolymer repeats differently. So, to answer your question DeepVariant assign read to one of the alleles in this case. It is a known problem and we have plans to address it. If read does not completely overlap a homopolymer repeat then it should not be counted. 2) DeepVariant does local reassembly for some regions (decided by algorithm). In that case reads are realigned to the haplotype, not the reference. In your example with long insertion realigned read cigar will correctly support part of the insertion, and then allele_counter will work with the ""correct"" cigar.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:228,security,compl,completely,228,"HI,. 1) DeepVariant does not treat homopolymer repeats differently. So, to answer your question DeepVariant assign read to one of the alleles in this case. It is a known problem and we have plans to address it. If read does not completely overlap a homopolymer repeat then it should not be counted. 2) DeepVariant does local reassembly for some regions (decided by algorithm). In that case reads are realigned to the haplotype, not the reference. In your example with long insertion realigned read cigar will correctly support part of the insertion, and then allele_counter will work with the ""correct"" cigar.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:190,testability,plan,plans,190,"HI,. 1) DeepVariant does not treat homopolymer repeats differently. So, to answer your question DeepVariant assign read to one of the alleles in this case. It is a known problem and we have plans to address it. If read does not completely overlap a homopolymer repeat then it should not be counted. 2) DeepVariant does local reassembly for some regions (decided by algorithm). In that case reads are realigned to the haplotype, not the reference. In your example with long insertion realigned read cigar will correctly support part of the insertion, and then allele_counter will work with the ""correct"" cigar.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:519,usability,support,support,519,"HI,. 1) DeepVariant does not treat homopolymer repeats differently. So, to answer your question DeepVariant assign read to one of the alleles in this case. It is a known problem and we have plans to address it. If read does not completely overlap a homopolymer repeat then it should not be counted. 2) DeepVariant does local reassembly for some regions (decided by algorithm). In that case reads are realigned to the haplotype, not the reference. In your example with long insertion realigned read cigar will correctly support part of the insertion, and then allele_counter will work with the ""correct"" cigar.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:225,availability,avail,available,225,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:163,integrability,filter,filters,163,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:225,reliability,availab,available,225,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:225,safety,avail,available,225,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:225,security,availab,available,225,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:373,usability,confirm,confirming,373,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:563,usability,support,supported,563,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:728,usability,support,supports,728,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:166,availability,sli,slightly,166,"Resulting image that is fed into CNN contains multiple layers. Two of those are 'Read supports allele', and 'Read supports ref'. By removing an ambiguous read we may slightly improve the accuracy (in theory). Yes, your last example is difficult to make it right and we don't have a near future plans to address those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:37,deployability,contain,contains,37,"Resulting image that is fed into CNN contains multiple layers. Two of those are 'Read supports allele', and 'Read supports ref'. By removing an ambiguous read we may slightly improve the accuracy (in theory). Yes, your last example is difficult to make it right and we don't have a near future plans to address those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:55,modifiability,layer,layers,55,"Resulting image that is fed into CNN contains multiple layers. Two of those are 'Read supports allele', and 'Read supports ref'. By removing an ambiguous read we may slightly improve the accuracy (in theory). Yes, your last example is difficult to make it right and we don't have a near future plans to address those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:166,reliability,sli,slightly,166,"Resulting image that is fed into CNN contains multiple layers. Two of those are 'Read supports allele', and 'Read supports ref'. By removing an ambiguous read we may slightly improve the accuracy (in theory). Yes, your last example is difficult to make it right and we don't have a near future plans to address those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:294,testability,plan,plans,294,"Resulting image that is fed into CNN contains multiple layers. Two of those are 'Read supports allele', and 'Read supports ref'. By removing an ambiguous read we may slightly improve the accuracy (in theory). Yes, your last example is difficult to make it right and we don't have a near future plans to address those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:86,usability,support,supports,86,"Resulting image that is fed into CNN contains multiple layers. Two of those are 'Read supports allele', and 'Read supports ref'. By removing an ambiguous read we may slightly improve the accuracy (in theory). Yes, your last example is difficult to make it right and we don't have a near future plans to address those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:114,usability,support,supports,114,"Resulting image that is fed into CNN contains multiple layers. Two of those are 'Read supports allele', and 'Read supports ref'. By removing an ambiguous read we may slightly improve the accuracy (in theory). Yes, your last example is difficult to make it right and we don't have a near future plans to address those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:42,usability,help,helpful,42,I see. Thank you. Your responses are very helpful.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/214:180,deployability,releas,releasing,180,This is an [issue](https://github.com/googlegenomics/gcp-deepvariant-runner/issues/27) of [DeepVariantRunner](https://github.com/googlegenomics/gcp-deepvariant-runner). We will be releasing a new docker image later this week that will resolve it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
