id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/358:8188,security,updat,updating,8188,"e_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8740,security,updat,updating,8740,", num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic librar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11029,security,model,models,11029,"c library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11040,security,model,model,11040,"ibcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11265,security,model,modeling,11265,"u/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metada",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11383,security,model,models,11383,"/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolut",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11394,security,model,model,11394,".cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11942,security,session,session,11942,"0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another except",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12072,security,session,session,12072,"0325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12211,security,session,session,12211,"al_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12489,security,log,log,12489,"cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12719,security,log,log,12719," tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15089,security,session,session,15089,"py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15214,security,session,session,15214,"ng/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15364,security,session,session,15364,"monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15490,security,session,session,15490,"ix_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15780,security,log,log,15780,"ng/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16103,security,log,log,16103,"e 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17709,security,model,modeling,17709,"v, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17874,security,model,modeling,17874,"el.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18042,security,model,modeling,18042,"variant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18443,security,stride,stride,18443,"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22625,security,model,models,22625,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22636,security,model,model,22636,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1465,testability,trace,trace,1465,".06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11831,testability,Trace,Traceback,11831,"> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_303",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12489,testability,log,log,12489,"cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12719,testability,log,log,12719," tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12961,testability,Trace,Traceback,12961,"in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15780,testability,log,log,15780,"ng/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16103,testability,log,log,16103,"e 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16384,testability,trace,trace,16384," in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in pred",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21805,testability,Trace,Traceback,21805,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:382,usability,tool,tools,382,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:674,usability,Command,Command,674,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:766,usability,input,input,766,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1131,usability,input,input,1131,"riants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1267,usability,input,input,1267,"ler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1292,usability,input,input,1292," 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1459,usability,Error,Error,1459,"450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2285,usability,user,user,2285,"ds=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.44499",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2333,usability,command,command,2333,"VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2653,usability,input,input,2653,"uld not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2774,usability,support,supports,2774,"te variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3874,usability,memor,memoryClockRate,3874,"7:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5720,usability,memor,memory,5720,"form/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9126,usability,memor,memoryClockRate,9126,"will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10825,usability,memor,memory,10825,"rm/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERRO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12335,usability,error,error,12335,"aver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12876,usability,error,errors,12876,"ocal/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15626,usability,error,error,15626,"itored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16353,usability,error,errors,16353,"/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18416,usability,input,inputs,18416,"EDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Laye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18977,usability,input,inputs,18977,"runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19266,usability,input,inputs,19266,"=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(input",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19437,usability,input,inputs,19437,"], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20264,usability,input,inputs,20264,"nputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21707,usability,user,user,21707,"thon3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22221,usability,command,command,22221,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22404,usability,Command,Command,22404,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22672,usability,statu,status,22672,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/359:166,availability,Servic,Services,166,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1016,availability,Operat,Operating,1016,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:166,deployability,Servic,Services,166,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:426,deployability,contain,container,426,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1062,deployability,version,version,1062,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1080,deployability,Instal,Installation,1080,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:166,integrability,Servic,Services,166,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:182,integrability,configur,configured,182,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1062,integrability,version,version,1062,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:166,modifiability,Servic,Services,166,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:182,modifiability,configur,configured,182,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1062,modifiability,version,version,1062,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1173,reliability,Doe,Does,1173,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1194,safety,test,test,1194,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:182,security,configur,configured,182,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:334,testability,understand,understand,334,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:900,testability,understand,understand,900,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/359:1194,testability,test,test,1194,"Unsolved References/Imports Using The Provided Docker; **Issue**. I am using the docker you provided, while working on a remote machine. Using Pycharm Professional's Services tab, I configured my interpreter to run the code I have on my local clone of the entire git. . I am trying to run the ""make_examples.py"" file line-by-line, to understand it better. The entire clone is on my remote machine, and it runs with the docker container's interpreter. When I debug the code, there are many unresolved references. . Some examples are:. `from third_party.nucleus.protos import reads_pb2`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import pileup_image_native`. `from deepvariant.protos import deepvariant_pb2`. `from deepvariant.python import allelecounter`. `from third_party.nucleus.io.python import hts_verbose`. ... I looked for these files, and they aren't there. I understand there is something very basic that I misunderstand, so thanks in advance for your patience! **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: irrelevant. **Does the quick start test work on your system?**. I have succeeded in running the quick start example on the remote machine, through the terminal.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/359
https://github.com/google/deepvariant/issues/360:889,availability,Operat,Operating,889,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:936,deployability,version,version,936,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:954,deployability,Instal,Installation,954,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:532,energy efficiency,CPU,CPU,532,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:560,integrability,event,eventually,560,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:936,integrability,version,version,936,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:936,modifiability,version,version,936,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:40,performance,memor,memory,40,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:204,performance,memor,memory,204,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:532,performance,CPU,CPU,532,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:605,performance,memor,memory,605,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:40,usability,memor,memory,40,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:204,usability,memor,memory,204,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:427,usability,tool,tools,427,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/360:605,usability,memor,memory,605,"Shuffle script for training runs out of memory; **Describe the issue:**. Shuffle script for tfrecords (https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-training-case-study.md) runs out of memory when using a training set from multiple BAM files. This is what I followed:. - Run make_examples for each BAM file to obtain tfrecords. - Run shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on all the records from all the BAM files. This requires over 230 GB of CPU RAM, and the process is eventually killed. I do not know whether the memory requirement will keep growing beyond this point. Is there another way to deal with this situation? For example, it would be possible to run shuffling for data from each bam file independently. However, I am not sure what the flow would look like after that point. **Setup**. - Operating system: Ubuntu Bionic. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/360
https://github.com/google/deepvariant/issues/361:35,energy efficiency,cpu,cpu,35,"Is there still no way to limit the cpu usage?; Hello,. whatever the number of shards, DeepVariant invariably ends up taking the whole 48 threads on our machine. Is there a fix or a planned fix for that?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/361
https://github.com/google/deepvariant/issues/361:35,performance,cpu,cpu,35,"Is there still no way to limit the cpu usage?; Hello,. whatever the number of shards, DeepVariant invariably ends up taking the whole 48 threads on our machine. Is there a fix or a planned fix for that?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/361
https://github.com/google/deepvariant/issues/361:181,testability,plan,planned,181,"Is there still no way to limit the cpu usage?; Hello,. whatever the number of shards, DeepVariant invariably ends up taking the whole 48 threads on our machine. Is there a fix or a planned fix for that?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/361
https://github.com/google/deepvariant/issues/362:0,availability,error,error,0,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:30,availability,down,downloaded,30,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:295,availability,error,error,295,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:316,availability,Error,Error,316,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:505,availability,error,error,505,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:597,availability,error,error,597,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:363,deployability,fail,failed,363,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:404,deployability,contain,container,404,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:523,deployability,contain,container,523,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:0,performance,error,error,0,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:295,performance,error,error,295,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:316,performance,Error,Error,316,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:505,performance,error,error,505,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:597,performance,error,error,597,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:363,reliability,fail,failed,363,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:0,safety,error,error,0,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:295,safety,error,error,295,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:316,safety,Error,Error,316,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:505,safety,error,error,505,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:597,safety,error,error,597,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:534,testability,context,context,534,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:0,usability,error,error,0,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:14,usability,help,help,14,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:19,usability,command,command,19,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:215,usability,command,command,215,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:264,usability,help,help,264,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:295,usability,error,error,295,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:316,usability,Error,Error,316,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:440,usability,help,help,440,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:505,usability,error,error,505,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:542,usability,cancel,canceled,542,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:577,usability,command,command,577,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/issues/362:597,usability,error,error,597,"error running help command; I downloaded your docker ( `docker pull google/deepvariant:1.0.0` ) and it runs perfectly and I am really happy with it. However, I wanted to check out some options, so I run your readme command:. `docker run google/deepvariant:1.0.0 --help`. which lead to following error:. ```. docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""exec: \""--help\"": executable file not found in $PATH"": unknown. ERRO[0000] error waiting for container: context canceled. ```. should I change the command or is it an error with the image ? . do not worry it is not urgent, but I would be really keen on checking out more options. thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/362
https://github.com/google/deepvariant/pull/363:9,deployability,integr,integration,9,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:24,deployability,Build,Build,24,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:78,deployability,build,build,78,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:103,deployability,build,build-arg,103,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:9,integrability,integr,integration,9,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:9,interoperability,integr,integration,9,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:9,modifiability,integr,integration,9,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:9,reliability,integr,integration,9,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:191,safety,test,testdata,191,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:282,safety,input,input,282,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:404,safety,input,input,404,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:453,safety,input,input,453,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:9,security,integr,integration,9,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:9,testability,integr,integration,9,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:191,testability,test,testdata,191,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:426,testability,unit,unittest,426,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:57,usability,support,support,57,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:282,usability,input,input,282,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:404,usability,input,input,404,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/pull/363:453,usability,input,input,453,"OpenVINO integration; * Build Docker image with OpenVINO support. ```. docker build -t deepvariant . --build-arg DV_OPENVINO_BUILD=1. ```. * Run. ```bash. export INPUT_DIR=""${PWD}/quickstart-testdata"". export OUTPUT_DIR=""${PWD}/quickstart-output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. deepvariant \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --call_variants_extra_args=""use_openvino=True"" \. --num_shards=1. ```. (added extra flag `--call_variants_extra_args=""use_openvino=True""` comparing to original Getting Started).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/363
https://github.com/google/deepvariant/issues/364:540,deployability,stack,stackoverflow,540,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:464,interoperability,mismatch,mismatch,464,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:602,reliability,doe,doesnt-flatten-files-with-sparkrunner-but-does-so-wi,602,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:411,safety,input,input,411,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:760,safety,sanit,sanity,760,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:760,security,sanit,sanity,760,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:738,testability,simpl,simply,738,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:810,testability,simpl,simply,810,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:874,testability,simpl,simply,874,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:160,usability,tool,tools,160,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:411,usability,input,input,411,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:738,usability,simpl,simply,738,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:810,usability,simpl,simply,810,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/issues/364:874,usability,simpl,simply,874,"(TRAINING) Expected number of output files from shuffle script; Hi,. I am running the shuffle script (https://raw.githubusercontent.com/google/deepvariant/r1.0/tools/shuffle_tfrecords_beam.py) on some training data. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as [well](https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi)). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/364
https://github.com/google/deepvariant/pull/365:0,deployability,Updat,Updates,0,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:396,integrability,sub,submitting,396,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:251,modifiability,Portab,PortableRunner,251,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:88,performance,perform,performed,88,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:379,performance,perform,performed,379,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:0,safety,Updat,Updates,0,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:341,safety,test,testing,341,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:0,security,Updat,Updates,0,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:60,testability,understand,understand,60,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:341,testability,test,testing,341,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:88,usability,perform,performed,88,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/pull/365:379,usability,perform,performed,379,"Updates to shuffle_tfrecords_beam script for SparkRunner; I understand that PRs are not performed on github. So, I just wanted to recommend/discuss some potential changes for the shuffle_tfrecords_beam.py script to enable running it with SparkRunner (PortableRunner). Without these changes the script works only in LOOPBACK mode (which is a testing mode where the actual work is performed on the submitting host).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/365
https://github.com/google/deepvariant/issues/366:96,deployability,version,version,96,"SNP that looks real through IGV is not called; **Describe the issue:**. hi . I used deepvariant version 1.0.0 to analyze the ccs data of mitochondria, but a snp was not called. The details are as follows：. ![image](https://user-images.githubusercontent.com/25741799/96946498-20930500-1513-11eb-988c-d308fe52db80.png). ![image](https://user-images.githubusercontent.com/25741799/96946551-44eee180-1513-11eb-8d3a-c57b532cef58.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/366
https://github.com/google/deepvariant/issues/366:96,integrability,version,version,96,"SNP that looks real through IGV is not called; **Describe the issue:**. hi . I used deepvariant version 1.0.0 to analyze the ccs data of mitochondria, but a snp was not called. The details are as follows：. ![image](https://user-images.githubusercontent.com/25741799/96946498-20930500-1513-11eb-988c-d308fe52db80.png). ![image](https://user-images.githubusercontent.com/25741799/96946551-44eee180-1513-11eb-8d3a-c57b532cef58.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/366
https://github.com/google/deepvariant/issues/366:96,modifiability,version,version,96,"SNP that looks real through IGV is not called; **Describe the issue:**. hi . I used deepvariant version 1.0.0 to analyze the ccs data of mitochondria, but a snp was not called. The details are as follows：. ![image](https://user-images.githubusercontent.com/25741799/96946498-20930500-1513-11eb-988c-d308fe52db80.png). ![image](https://user-images.githubusercontent.com/25741799/96946551-44eee180-1513-11eb-8d3a-c57b532cef58.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/366
https://github.com/google/deepvariant/issues/366:223,usability,user,user-images,223,"SNP that looks real through IGV is not called; **Describe the issue:**. hi . I used deepvariant version 1.0.0 to analyze the ccs data of mitochondria, but a snp was not called. The details are as follows：. ![image](https://user-images.githubusercontent.com/25741799/96946498-20930500-1513-11eb-988c-d308fe52db80.png). ![image](https://user-images.githubusercontent.com/25741799/96946551-44eee180-1513-11eb-8d3a-c57b532cef58.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/366
https://github.com/google/deepvariant/issues/366:335,usability,user,user-images,335,"SNP that looks real through IGV is not called; **Describe the issue:**. hi . I used deepvariant version 1.0.0 to analyze the ccs data of mitochondria, but a snp was not called. The details are as follows：. ![image](https://user-images.githubusercontent.com/25741799/96946498-20930500-1513-11eb-988c-d308fe52db80.png). ![image](https://user-images.githubusercontent.com/25741799/96946551-44eee180-1513-11eb-8d3a-c57b532cef58.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/366
https://github.com/google/deepvariant/issues/367:141,availability,Operat,Operating,141,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:925,availability,Error,Error,925,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:181,deployability,version,version,181,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:199,deployability,Instal,Installation,199,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:3771,deployability,Fail,Failed,3771,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4549,energy efficiency,model,model,4549,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:181,integrability,version,version,181,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1028,integrability,buffer,buffer,1028,"rence genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:181,modifiability,version,version,181,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:305,modifiability,Pac,PacBio,305,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:622,modifiability,PAC,PACBIO,622,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:2497,modifiability,deco,decode,2497,"_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1023 11:00:14.638878 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4538,modifiability,Pac,PacBio,4538,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:925,performance,Error,Error,925,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:993,performance,time,time,993,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1009,performance,parallel,parallel,1009,"iant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:3771,reliability,Fail,Failed,3771,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4203,reliability,Doe,Does,4203,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:471,safety,input,input,471,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:639,safety,input,input,639,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:680,safety,input,input,680,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:925,safety,Error,Error,925,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1093,safety,input,input,1093,"ription of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Wri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1133,safety,input,input,1133,"*. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1474,safety,input,input,1474," \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1630,safety,input,inputs,1630,"-ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Settin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1709,safety,input,input,1709,".primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1023 11:00:14.638878 140022713169664 genomi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:2472,safety,input,input,2472,"nput/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1023 11:00:14.638878 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:2739,safety,input,input,2739,"primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1023 11:00:14.638878 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4224,safety,test,test,4224,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4260,safety,test,test,4260,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4549,security,model,model,4549,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:293,testability,instrument,instrument,293,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:931,testability,trace,trace,931,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4224,testability,test,test,4224,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4260,testability,test,test,4260,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:4440,testability,context,context,4440,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:74,usability,clear,clear,74,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:417,usability,Command,Command,417,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:471,usability,input,input,471,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:639,usability,input,input,639,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:680,usability,input,input,680,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:925,usability,Error,Error,925,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:978,usability,command,command,978,"Using deepvariant with non-reference genomes; **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1093,usability,input,input,1093,"ription of what the issue is.). **Setup**. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Wri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1133,usability,input,input,1133,"*. - Operating system: Ubuntu. - DeepVariant version: 0.9.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: sample: CHM13, instrument: PacBio Sequel CCS sequencing, reference genome: CHM13 draft genome from T2T project. **Steps to reproduce:**. - Command:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1474,usability,input,input,1474," \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1630,usability,input,inputs,1630,"-ref=/input/chm13.draft_v1.0.fasta \. --reads=/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Settin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:1709,usability,input,input,1709,".primary_alignments.sorted.bam \. --output_vcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.vcf.gz \. --output_gvcf=/output/CHM13.CHM13.minimap2_asm20.deepvariant_0.9.0.g.vcf.gz \. --num_shards=29. ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time seq 0 28 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chm13.draft_v1.0.fasta"" --reads ""/input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp. I1023 11:00:14.182121 140022713169664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1023 11:00:14.268690 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1023 11:00:14.638878 140022713169664 genomi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:2472,usability,input,input,2472,"nput/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.297683 140022713169664 make_examples.py:1324] Preparing inputs. I1023 11:00:14.382807 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1023 11:00:14.638878 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:2739,usability,input,input,2739,"primary_alignments.sorted.bam with NativeSamReader. I1023 11:00:14.425673 140022713169664 make_examples.py:1248] Common contigs are [u'chr1', u'chr2', u'chr3', u'chr4', u'chr5', u'chr6', u'chr7', u'chr8', u'chr9', u'chr10', u'chr11', u'chr12', u'chr13', u'chr14', u'chr15', u'chr16', u'ch. I1023 11:00:14.435336 140022713169664 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00029.gz. I1023 11:00:14.436027 140022713169664 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00029.gz. I1023 11:00:14.446223 140022713169664 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-23 11:00:14.446701: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1023 11:00:14.638878 140022713169664 genomics_reader.py:223] Reading /input/CHM13.CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:3880,usability,statu,statusor,3880,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:3903,usability,statu,status,3903,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/367:3919,usability,statu,status,3919,"CHM13.minimap2_asm20.primary_alignments.sorted.bam with NativeSamReader. W1023 11:00:14.858257 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:9. W1023 11:00:14.858535 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:30. W1023 11:00:14.858640 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:63. W1023 11:00:14.858738 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:107. W1023 11:00:14.858865 140022713169664 make_examples.py:1145] Could not create PileupImage for candidate at chr1:109. I1023 11:00:14.943413 140022713169664 make_examples.py:1363] Task 0: 26 candidates (21 examples) [0.51s elapsed]. I1023 11:00:34.047770 140022713169664 make_examples.py:1363] Task 0: 100 candidates (123 examples) [19.10s elapsed]. I1023 11:00:53.403723 140022713169664 make_examples.py:1363] Task 0: 200 candidates (255 examples) [19.36s elapsed]. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2020-10-23 11:01:17.042772: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 26013000 end: 26014000. I1023 11:00:13.973792 139819486582528 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes . **Any additional context:** . Deepvariant was successful on grch37 and grch38 reference genomes. I assume that the PacBio CCS model was trained on grch37 and grch38 reference genome and might not be applicable to other reference genomes. Can someone recommend a tweak to run deepvariant on CHM13 draft genome? Regards,. Sangjin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/367
https://github.com/google/deepvariant/issues/369:1170,energy efficiency,model,model,1170,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:33,modifiability,Pac,PacBio,33,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:134,modifiability,Pac,PacBio,134,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:415,modifiability,Pac,PacBio,415,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:824,modifiability,pac,pacbio,824,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:983,reliability,doe,does,983,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:782,safety,input,input,782,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:1170,security,model,model,1170,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:60,testability,understand,understanding,60,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/369:782,usability,input,input,782,"Question on Haplotag sorting for PacBio and Hybrid data; My understanding is that DeepVariant requires two steps to call variants for PacBio data. First step is to call variants directly on the BAM files and haplotag the BAM file with this first order call set, and the second step is to call variants on the haplotagged BAM files. Based on this, I have a few questions on how data is prepared for training. 1. For PacBio v1.0 training data, are haplotagged bams prepared based on v0.10 DeepVariant variant calls? 2. Are both haplotagged and non-haplotagged BAM files passed to DeepVariant to prepare two different sets of training data? Or can Deepvariant (make_examples) prepare two types of training data (haplotag sorted and unsorted images) based on a the same haplotagged BAM input? 3. For Hybrid variant calling, are pacbio reads haplotagged based on v0.10 DeepVariant? If the BAM preparation steps are shown that would be great. 4. How is training data prepared for hybrid - does it also have both haplotag sorted and unsorted images, and is this taken care-of by make_examples, or is this manually accomplished? 5. What are the genomes used to train the hybrid model (e.g., is it all of HG001-HG007)? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/369
https://github.com/google/deepvariant/issues/370:394,availability,avail,available,394,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:511,deployability,log,log,511,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:1467,deployability,log,log,1467,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:1074,integrability,buffer,buffer,1074,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:229,interoperability,specif,specific,229,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:857,interoperability,specif,specific,857,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:210,modifiability,concern,concerned,210,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:682,performance,disk,disk,682,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:1049,performance,parallel,parallel,1049,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:394,reliability,availab,available,394,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:183,safety,input,input,183,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:301,safety,input,input,301,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:394,safety,avail,available,394,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:511,safety,log,log,511,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:1467,safety,log,log,1467,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:394,security,availab,available,394,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:511,security,log,log,511,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:623,security,access,access,623,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:1467,security,log,log,1467,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:210,testability,concern,concerned,210,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:511,testability,log,log,511,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:1467,testability,log,log,1467,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:183,usability,input,input,183,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:301,usability,input,input,301,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:771,usability,efficien,efficient,771,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/370:992,usability,command,command,992,"Writing realigned reads causes storage issues; I'm attempting to write a bam file of the realigned reads, as I'm seeing ADs in the vcf that do not line up with what is present in the input bam file. I'm mainly concerned with two specific locations in the genome. The full genome is approx 11 Gbp, the input bam file is about 190 GB, and the drive I'm attempting to output to has more than 4 TB available. When using `-emit_realigned_reads` and using `-realigner_diagnostics` to provide an output directory, the log file tells me that deepvariant attempts to write more than seven million bam files, making it impossible to access the directory before crashing due to running out of disk space. Is there some way of getting around this? I'm thinking either a more storage efficient way of getting the entire bam file, or a way of getting the bam file of the specific regions I'm interested in. I'm using deepvariant 1.0 from docker on Ubuntu 18.04. The data is short read Illumina data. . The command I'm using to run this:. ```. seq 0 $((60-1)) |\. parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples \. --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \. --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \. --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord@60.gz \. --sample_name sample --task {} 2> results/sample/deepvariant/tmp/make_examples.log . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/370
https://github.com/google/deepvariant/issues/371:235,deployability,modul,module,235,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:44,energy efficiency,model,model,44,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:31,modifiability,layer,layer,31,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:159,modifiability,layer,layer,159,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:235,modifiability,modul,module,235,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:235,safety,modul,module,235,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:321,safety,input,input,321,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:44,security,model,model,44,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:106,usability,learn,learning,106,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/371:321,usability,input,input,321,"Is there a way to get the last layer of the model as output?; My goal is to use DeepVariant in a transfer learning application. Is it possible to get the last layer as an embedding output? If yes:. Is it possible to use it as a Python module to get these embeddings? Also, is it possible to run DeepVariant in with a VCF input? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/371
https://github.com/google/deepvariant/issues/372:171,availability,error,error,171,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1158,deployability,log,login,1158,"ered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.57",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:6358,deployability,modul,module,6358,"4 make_examples.py:587] 9099 candidates (9197 examples) [1.93s elapsed]. I1027 14:37:09.049840 140702132172544 make_examples.py:587] 9819 candidates (9919 examples) [1.54s elapsed]. I1027 14:37:09.783628 140702132172544 make_examples.py:587] 10300 candidates (10400 examples) [0.73s elapsed]. I1027 14:37:10.211517 140702132172544 make_examples.py:587] 10544 candidates (10644 examples) [0.43s elapsed]. I1027 14:37:11.778766 140702132172544 make_examples.py:587] 11247 candidates (11359 examples) [1.57s elapsed]. I1027 14:37:13.667338 140702132172544 make_examples.py:587] 11967 candidates (12083 examples) [1.89s elapsed]. I1027 14:37:13.906970 140702132172544 make_examples.py:587] 12077 candidates (12193 examples) [0.24s elapsed]. I1027 14:37:15.383114 140702132172544 make_examples.py:587] 12826 candidates (12948 examples) [1.48s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1503, in process. example for candidate in candidates. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504, in <listcomp>. for example in self.create_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8118,deployability,fail,failed,8118,"l.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504, in <listcomp>. for example in self.create_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8496,deployability,modul,module,8496,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1144,energy efficiency,Power,Power,1144," never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:763,integrability,buffer,buffer,763,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1068,integrability,pub,publication,1068," 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8792,integrability,sub,subprocess,8792,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8885,integrability,sub,subprocess,8885,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8966,integrability,sub,subprocess,8966,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:9049,integrability,buffer,buffer,9049,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:565,modifiability,interm,intermediate,565,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:613,modifiability,Interm,Intermediate,613,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:2312,modifiability,deco,decode,2312,"ree to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-27 14:35:56.578184: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1027 14:35:56.653103 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:56.683220 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. W1027 14:35:58.065773 140702132172544 make_examples.py:1773] Could not create PileupImage for candidate at chrM:72. I1027 14:35:58.091689 140702132172544 make_examples.py:587] 6 candidates (5 examples) [1.51s elapsed]. W1027 14:36:44.979548 140702132172544 make_examples.py:1773] Could not create PileupImage for candidate at chrM:16520. I1027 14:36:47.744649 140702132172544 make_examples.py:587] 472 candidates (516 examples) [49.65s elapsed]. I1027 14:36:48.139883 140702132172544 make_examples.py:587] 690 candidates (734 examples) [0.39s elapsed]. I1027 14:36:49.490540 140702132172544 make_examples.py:587] 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:6358,modifiability,modul,module,6358,"4 make_examples.py:587] 9099 candidates (9197 examples) [1.93s elapsed]. I1027 14:37:09.049840 140702132172544 make_examples.py:587] 9819 candidates (9919 examples) [1.54s elapsed]. I1027 14:37:09.783628 140702132172544 make_examples.py:587] 10300 candidates (10400 examples) [0.73s elapsed]. I1027 14:37:10.211517 140702132172544 make_examples.py:587] 10544 candidates (10644 examples) [0.43s elapsed]. I1027 14:37:11.778766 140702132172544 make_examples.py:587] 11247 candidates (11359 examples) [1.57s elapsed]. I1027 14:37:13.667338 140702132172544 make_examples.py:587] 11967 candidates (12083 examples) [1.89s elapsed]. I1027 14:37:13.906970 140702132172544 make_examples.py:587] 12077 candidates (12193 examples) [0.24s elapsed]. I1027 14:37:15.383114 140702132172544 make_examples.py:587] 12826 candidates (12948 examples) [1.48s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1503, in process. example for candidate in candidates. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504, in <listcomp>. for example in self.create_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8496,modifiability,modul,module,8496,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8556,modifiability,pac,packages,8556,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8656,modifiability,pac,packages,8656,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:171,performance,error,error,171,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:720,performance,time,time,720,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:735,performance,parallel,parallel,735,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1039,performance,Parallel,Parallel,1039,"quence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1116,performance,Parallel,Parallel,1116,".reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1330,performance,Parallel,Parallel,1330,"n/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1393,performance,parallel,parallel,1393,"12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-27 14:35:56.578184:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8099,performance,parallel,parallel,8099,"s. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504, in <listcomp>. for example in self.create_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:9006,performance,time,time,9006,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:9021,performance,parallel,parallel,9021,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:80,reliability,doe,doesn,80,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8037,reliability,doe,doesn,8037,".py"", line 1503, in process. example for candidate in candidates. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504, in <listcomp>. for example in self.create_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8118,reliability,fail,failed,8118,"l.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504, in <listcomp>. for example in self.create_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:171,safety,error,error,171,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1158,safety,log,login,1158,"ered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.57",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1594,safety,input,inputs,1594,"s6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-27 14:35:56.578184: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1027 14:35:56.653103 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:2287,safety,input,input,2287,"000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-27 14:35:56.578184: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1027 14:35:56.653103 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:56.683220 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. W1027 14:35:58.065773 140702132172544 make_examples.py:1773] Could not create PileupImage for candidate at chrM:72. I1027 14:35:58.091689 140702132172544 make_examples.py:587] 6 candidates (5 examples) [1.51s elapsed]. W1027 14:36:44.979548 140702132172544 make_examples.py:1773] Could not create PileupImage for candidate at chrM:16520. I1027 14:36:47.744649 140702132172544 make_examples.py:587] 472 candidates (516 examples) [49.65s elapsed]. I1027 14:36:48.139883 140702132172544 make_examples.py:587] 690 candidates (734 examples) [0.39s elapsed]. I1027 14:36:49.490540 14070213217254",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:6358,safety,modul,module,6358,"4 make_examples.py:587] 9099 candidates (9197 examples) [1.93s elapsed]. I1027 14:37:09.049840 140702132172544 make_examples.py:587] 9819 candidates (9919 examples) [1.54s elapsed]. I1027 14:37:09.783628 140702132172544 make_examples.py:587] 10300 candidates (10400 examples) [0.73s elapsed]. I1027 14:37:10.211517 140702132172544 make_examples.py:587] 10544 candidates (10644 examples) [0.43s elapsed]. I1027 14:37:11.778766 140702132172544 make_examples.py:587] 11247 candidates (11359 examples) [1.57s elapsed]. I1027 14:37:13.667338 140702132172544 make_examples.py:587] 11967 candidates (12083 examples) [1.89s elapsed]. I1027 14:37:13.906970 140702132172544 make_examples.py:587] 12077 candidates (12193 examples) [0.24s elapsed]. I1027 14:37:15.383114 140702132172544 make_examples.py:587] 12826 candidates (12948 examples) [1.48s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1503, in process. example for candidate in candidates. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504, in <listcomp>. for example in self.create_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8496,safety,modul,module,8496,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1131,security,Command-Lin,Command-Line,1131,"(T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1158,security,log,login,1158,"ered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.57",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1158,testability,log,login,1158,"ered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.57",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:6209,testability,Trace,Traceback,6209,". I1027 14:37:05.586354 140702132172544 make_examples.py:587] 8367 candidates (8461 examples) [1.72s elapsed]. I1027 14:37:07.514431 140702132172544 make_examples.py:587] 9099 candidates (9197 examples) [1.93s elapsed]. I1027 14:37:09.049840 140702132172544 make_examples.py:587] 9819 candidates (9919 examples) [1.54s elapsed]. I1027 14:37:09.783628 140702132172544 make_examples.py:587] 10300 candidates (10400 examples) [0.73s elapsed]. I1027 14:37:10.211517 140702132172544 make_examples.py:587] 10544 candidates (10644 examples) [0.43s elapsed]. I1027 14:37:11.778766 140702132172544 make_examples.py:587] 11247 candidates (11359 examples) [1.57s elapsed]. I1027 14:37:13.667338 140702132172544 make_examples.py:587] 11967 candidates (12083 examples) [1.89s elapsed]. I1027 14:37:13.906970 140702132172544 make_examples.py:587] 12077 candidates (12193 examples) [0.24s elapsed]. I1027 14:37:15.383114 140702132172544 make_examples.py:587] 12826 candidates (12948 examples) [1.48s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1503, in process. example for candidate in candidates. File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1504,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8398,testability,Trace,Traceback,8398,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:171,usability,error,error,171,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:291,usability,user,user,291,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:705,usability,command,command,705,"ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1131,usability,Command,Command-Line,1131,"(T).; I've never encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1150,usability,Tool,Tool,1150,"r encountered this error previously and I cannot figure out what is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1212,usability,help,helps,1212,"t is causing the issue. Looks like something to do with the reference file? user@node1784:~/MyData$ /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=./hg19.fa --reads=./NA12878_S1.bam --output_vcf=./NA12878_DeepVariant_output.vcf.gz --num_shards=1 . I1027 14:35:49.384760 139774463268608 run_deepvariant.py:273] Re-using the directory for intermediate results in /tmp/tmps6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:1594,usability,input,inputs,1594,"s6oyff7s. ***** Intermediate results will be written to /tmp/tmps6oyff7s in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-27 14:35:56.578184: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1027 14:35:56.653103 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:2287,usability,input,input,2287,"000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I1027 14:35:51.541710 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.552782 140702132172544 make_examples.py:587] Preparing inputs. I1027 14:35:51.576705 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:51.590540 140702132172544 make_examples.py:587] Common contigs are ['chrM', 'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']. I1027 14:35:56.576697 140702132172544 make_examples.py:587] Writing examples to /tmp/tmps6oyff7s/make_examples.tfrecord-00000-of-00001.gz. I1027 14:35:56.577845 140702132172544 make_examples.py:587] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-10-27 14:35:56.578184: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1027 14:35:56.653103 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. I1027 14:35:56.683220 140702132172544 genomics_reader.py:223] Reading ./NA12878_S1.bam with NativeSamReader. W1027 14:35:58.065773 140702132172544 make_examples.py:1773] Could not create PileupImage for candidate at chrM:72. I1027 14:35:58.091689 140702132172544 make_examples.py:587] 6 candidates (5 examples) [1.51s elapsed]. W1027 14:36:44.979548 140702132172544 make_examples.py:1773] Could not create PileupImage for candidate at chrM:16520. I1027 14:36:47.744649 140702132172544 make_examples.py:587] 472 candidates (516 examples) [49.65s elapsed]. I1027 14:36:48.139883 140702132172544 make_examples.py:587] 690 candidates (734 examples) [0.39s elapsed]. I1027 14:36:49.490540 14070213217254",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8300,usability,user,user,8300,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8814,usability,command,command,8814,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:8997,usability,Command,Command,8997,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/issues/372:9243,usability,statu,status,9243,"eate_pileup_examples(candidate). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1768, in create_pileup_examples. haplotype_sequences=haplotype_sequences). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 507, in create_pileup_images. pileup = _pileup_for_pair_of_alts(alts). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 467, in _pileup_for_pair_of_alts. alt_alleles=alt_alleles). File ""/tmp/Bazel.runfiles_e62sjnjy/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 345, in build_pileup. dv_call.variant.reference_bases)). ValueError: The middle base of reference sequence in the window (A at base 110) doesn't match first character of variant.reference_bases (T). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./hg19.fa --reads ./NA12878_S1.bam --examples /tmp/tmps6oyff7s/make_examples.tfrecord@1.gz --task 0. real	1m26.899s. user	1m25.200s. sys	0m1.679s. I1027 14:37:16.286230 139774463268608 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./hg19.fa"" --reads ""./NA12878_S1.bam"" --examples ""/tmp/tmps6oyff7s/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/372
https://github.com/google/deepvariant/pull/373:0,deployability,Updat,Update,0,Update the README.md.; PiperOrigin-RevId: 339282065. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/373
https://github.com/google/deepvariant/pull/373:93,performance,time,time,93,Update the README.md.; PiperOrigin-RevId: 339282065. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/373
https://github.com/google/deepvariant/pull/373:0,safety,Updat,Update,0,Update the README.md.; PiperOrigin-RevId: 339282065. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/373
https://github.com/google/deepvariant/pull/373:0,security,Updat,Update,0,Update the README.md.; PiperOrigin-RevId: 339282065. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/373
https://github.com/google/deepvariant/pull/373:143,security,team,team,143,Update the README.md.; PiperOrigin-RevId: 339282065. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/373
https://github.com/google/deepvariant/issues/374:124,availability,Operat,Operating,124,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:631,availability,Error,Error,631,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1542,availability,error,error,1542,"/opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:4248,availability,error,error,4248,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:13,deployability,fail,fail,13,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:85,deployability,fail,fail,85,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:168,deployability,version,version,168,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:186,deployability,Instal,Installation,186,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1398,deployability,Fail,Failed,1398,"ling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1473,deployability,Fail,Failed,1473,"/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1698,deployability,modul,module,1698,"e index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:168,integrability,version,version,168,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1535,interoperability,format,format,1535,"amples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:168,modifiability,version,version,168,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1698,modifiability,modul,module,1698,"e index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:38,performance,content,content,38,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:631,performance,Error,Error,631,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1542,performance,error,error,1542,"/opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:4248,performance,error,error,4248,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:13,reliability,fail,fail,13,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:85,reliability,fail,fail,85,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1398,reliability,Fail,Failed,1398,"ling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1473,reliability,Fail,Failed,1473,"/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:3968,reliability,Doe,Does,3968,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:631,safety,Error,Error,631,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:943,safety,input,inputs,943,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1542,safety,error,error,1542,"/opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1698,safety,modul,module,1698,"e index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:3989,safety,test,test,3989,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:4025,safety,test,test,4025,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:4248,safety,error,error,4248,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:637,testability,trace,trace,637,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1549,testability,Trace,Traceback,1549,"and/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:3989,testability,test,test,3989,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:4025,testability,test,test,4025,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:4199,testability,context,context,4199,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:311,usability,Command,Command,311,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:420,usability,command,command,420,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:460,usability,command,command,460,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:503,usability,command,command,503,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:550,usability,command,command,550,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:596,usability,command,command,596,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:631,usability,Error,Error,631,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:724,usability,command,command,724,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:826,usability,command,command,826,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:943,usability,input,inputs,943,"Make_Example fail because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1014,usability,command,command,1014,"because of bed.file content; **Describe the issue:**. Make_Example fail because of bed.file. **Setup**. - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1116,usability,command,command,1116,". - Operating system:ubuntu18.04. - DeepVariant version:v1.0.0. - Installation method (Docker, built from source, etc.):Docker. - Type of data: same as case study. **Steps to reproduce:**. - Command:. /usr/local/seqslab/deepvariant/bazel-bin/deepvariant/make_examples \. --mode calling \. --ref /opt/command/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qcca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1423,usability,command,command,1423,"/test_dir/ref.fa \. --reads /opt/command/test_dir/0-0.bam \. --regions /opt/command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. option",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1499,usability,command,command,1499,"command/test_dir/part_0.bed \. --examples /opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:1542,usability,error,error,1542,"/opt/command/test_dir/expl_tfrecord \. --gvcf /opt/command/test_dir/gvcf_tfrecord . - Error trace: (if applicable). [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.842471 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.844546 139811846457152 make_examples.py:587] Preparing inputs. [E::idx_find_and_load] Could not retrieve index file for '/opt/command/test_dir/0-0.bam'. I1028 05:56:59.845231 139811846457152 genomics_reader.py:223] Reading /opt/command/test_dir/0-0.bam with NativeSamReader. I1028 05:56:59.854553 139811846457152 make_examples.py:587] Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. [E::hts_hopen] Failed to open file /opt/command/test_dir/part_0.bed. [E::hts_open_format] Failed to open file ""/opt/command/test_dir/part_0.bed"" : Exec format error. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1984, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1879, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:3937,usability,command,command,3937,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/issues/374:4248,usability,error,error,4248,"g_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1065, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_qccapoh4/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: Not found: Could not open /opt/command/test_dir/part_0.bed. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. My part_0.bed has 5 columns and goes error. chrm start end name (option). 1 0 1005000 0 5000. But when I change my part_0.bed to 4 columns , it works. chrm start end name . 1 0 1005000 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/374
https://github.com/google/deepvariant/pull/375:0,deployability,Updat,Update,0,Update README.; PiperOrigin-RevId: 339478022. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/375
https://github.com/google/deepvariant/pull/375:86,performance,time,time,86,Update README.; PiperOrigin-RevId: 339478022. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/375
https://github.com/google/deepvariant/pull/375:0,safety,Updat,Update,0,Update README.; PiperOrigin-RevId: 339478022. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/375
https://github.com/google/deepvariant/pull/375:0,security,Updat,Update,0,Update README.; PiperOrigin-RevId: 339478022. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/375
https://github.com/google/deepvariant/pull/375:136,security,team,team,136,Update README.; PiperOrigin-RevId: 339478022. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/375
https://github.com/google/deepvariant/issues/376:136,safety,valid,valid,136,Is the TPU training case-study deprecated?; In v0.9 there is a TPU training case-study. Are the tpu-based options/setup given there not valid from v0.10 onwards?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/376
https://github.com/google/deepvariant/issues/377:968,availability,Operat,Operating,968,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:277,deployability,version,version,277,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:1006,deployability,version,version,1006,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:1022,deployability,Instal,Installation,1022,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:277,integrability,version,version,277,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:586,integrability,discover,discovery,586,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:1006,integrability,version,version,1006,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:586,interoperability,discover,discovery,586,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:765,interoperability,compatib,compatible,765,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:943,interoperability,compatib,compatible,943,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:277,modifiability,version,version,277,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:1006,modifiability,version,version,1006,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:1130,modifiability,Pac,PacBio,1130,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:864,safety,input,input,864,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:115,security,auth,authors,115,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:1193,testability,context,context,1193,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:586,usability,discov,discovery,586,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/377:864,usability,input,input,864,"HG002-HG003-HG004 trio deepvariant and de novo mutation calling; **_Describe the issue:_**. I was wondering if the authors have recommended method for generating a set of high-confidence de novo germline mutations from trio-deepvariant vcf files. I have used DeepVariant 0.9.0 version for calling the germline mutations and I have merged HG002, HG003 and HG004 .g.vcf.gz files using GLnexus. If there isn't a recommendation calling de novo germline mutations from trio-deepvariant vcf files, I am hoping to implement the method described in DeNovoGear: de novo indel and point mutation discovery and phasing. _**Miscellaneous**_. - I was hoping to use GATK GenotypeGVCFs for merging the HG002, HG003 and HG004 .g.vcf.gz files, but deepvariant .g.vcf.gz file is not compatible with GATK GenotypeGVCFs. . - I was hoping to use the HG002-HG003-HG004 trio vcf file as input towards strelka2 de novo mutation caller, but the vcf file was again not compatible. **_Setup_**. Operating system: Ubuntu. DeepVariant version: 0.9.0. Installation method (Docker, built from source, etc.): Docker. Type of data: sample: HG002, HG003 and HG004 PacBio CCS fastq. **_Steps to reproduce:_**. **_Any additional context:_**. Regards,. Sangjin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/377
https://github.com/google/deepvariant/issues/378:32,availability,checkpoint,checkpoints,32,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:174,availability,checkpoint,checkpoint,174,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:198,availability,checkpoint,checkpoints,198,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:265,availability,checkpoint,checkpoints,265,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:112,performance,concurren,concurrently,112,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:32,reliability,checkpoint,checkpoints,32,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:174,reliability,checkpoint,checkpoint,174,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:198,reliability,checkpoint,checkpoints,198,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:265,reliability,checkpoint,checkpoints,265,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:147,testability,simpl,simply,147,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/378:147,usability,simpl,simply,147,"Training: How to reevaluate all checkpoints?; I launched a training run, but the evaluation run wasn't launched concurrently. When I launch it, it simply evaluates the final checkpoint, not all the checkpoints in between. Is there an option force evaluation of all checkpoints in model_eval?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/378
https://github.com/google/deepvariant/issues/379:749,deployability,log,logic,749,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:1256,deployability,log,logic,1256,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:582,safety,test,testdata,582,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:749,safety,log,logic,749,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:1256,safety,log,logic,1256,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:749,security,log,logic,749,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:1256,security,log,logic,1256,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:0,testability,Understand,Understanding,0,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:71,testability,understand,understanding,71,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:207,testability,understand,understand,207,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:582,testability,test,testdata,582,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:749,testability,log,logic,749,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:1230,testability,understand,understand,1230,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:1256,testability,log,logic,1256,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:542,usability,visual,visualized,542,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:895,usability,indicat,indicates,895,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:1527,usability,clear,clear,1527,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/379:1610,usability,user,user-images,1610,"Understanding insertions in DeepVariant; Hi,. I am trying to deepen my understanding of DeepVariant (pun unintended), similar to what is written here (https://github.com/google/deepvariant/issues/306). If I understand the discussion above correctly, whenever there is an insertion, the insertion itself will not be present in the pileup image, and the preceding pixel will be zero'd out. So if we have a cigar 6M3I1M such as:. ref: ACGCCT T. alt: ACGCCTCCCT. this will actually be represented in the pileup as:. ref: ACGCCTT. alt: ACGCC0T. I visualized the examples you provided in testdata, and on the 3rd example [fig1] (chr20:10001436-10001436) there is a case in which an insertion occurs right after the variant's position. Following the above logic, the center column should be zero'd out. However, it seems to not be the case. What happens instead is that the last channels center column indicates a diversion from the reference genome (a pixel is 'lit' up). So it looks like the bam read is a basic SNP, even though it actually is a length 5 insertion (the bam is an indel and the variant in the vcf is an snp). In fact, I haven't seen any case of zero'd out pixels which aren't deletions. Some options are:. 1. Did I not understand the insertions logic correctly? Whas it changed since the above git issue in April? 2. Am I possibly working with the wrong files? I use the NA12878_S1.chr20.10_10p1mb.bam/.bai bam file with the golden.training_examples.tfrecord for your examples. Sorry for the long post, I hope I was clear but let me know if more information/explanations are needed. ![fig1](https://user-images.githubusercontent.com/52149642/98434660-6ab2e380-20da-11eb-887c-4683bb759d1c.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/379
https://github.com/google/deepvariant/issues/380:232,availability,operat,operation,232,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:420,availability,error,error,420,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:544,availability,error,error,544,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:572,availability,error,error,572,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1875,availability,Operat,Operating,1875,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2177,availability,Error,Error,2177,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:7,deployability,build,build,7,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:37,deployability,depend,dependency,37,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:90,deployability,build,build,90,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:252,deployability,instal,install,252,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:268,deployability,depend,dependencies,268,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:306,deployability,version,version,306,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:347,deployability,build,building,347,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:433,deployability,instal,installation,433,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:494,deployability,build,building,494,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:535,deployability,build,building,535,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:585,deployability,instal,installation,585,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:606,deployability,INSTAL,INSTALL,606,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:629,deployability,depend,dependencies,629,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:673,deployability,Build,Building,673,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1917,deployability,version,version,1917,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1940,deployability,version,version,1940,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1951,deployability,Instal,Installation,1951,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2006,deployability,build,building,2006,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:37,integrability,depend,dependency,37,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:268,integrability,depend,dependencies,268,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:306,integrability,version,version,306,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:629,integrability,depend,dependencies,629,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1917,integrability,version,version,1917,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1940,integrability,version,version,1940,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:37,modifiability,depend,dependency,37,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:268,modifiability,depend,dependencies,268,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:306,modifiability,version,version,306,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:629,modifiability,depend,dependencies,629,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1917,modifiability,version,version,1917,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:1940,modifiability,version,version,1940,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:420,performance,error,error,420,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:544,performance,error,error,544,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:572,performance,error,error,572,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2177,performance,Error,Error,2177,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2209,reliability,Doe,Does,2209,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:37,safety,depend,dependency,37,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:268,safety,depend,dependencies,268,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:420,safety,error,error,420,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:544,safety,error,error,544,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:572,safety,error,error,572,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:629,safety,depend,dependencies,629,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2177,safety,Error,Error,2177,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2230,safety,test,test,2230,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2266,safety,test,test,2266,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:37,testability,depend,dependency,37,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:268,testability,depend,dependencies,268,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:629,testability,depend,dependencies,629,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2056,testability,instrument,instrument,2056,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2183,testability,trace,trace,2183,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2230,testability,test,test,2230,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2266,testability,test,test,2266,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2440,testability,context,context,2440,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:420,usability,error,error,420,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:544,usability,error,error,544,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:572,usability,error,error,572,"Cannot build on Centos 7 due to CLIF dependency ; **Describe the issue:**. I am trying to build deepvariant on my machine that has Centos 7 and it seems there are no instructions to do that. All the instructions are based on Ubuntu operation system. I install all the dependencies but it seems there is no version of CLIF for Centos 7. So I tried building CLIF on my machine using clang/llvm 11.0.0. I get the following error during installation of that. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2165,usability,Command,Command,2165,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/380:2177,usability,Error,Error,2177,"at. Is it possible to have instruction for building deepvariant on Centos 7. . CLIF building error - I get the following error during installation using ./INSTALL.sh. . Scanning dependencies of target clif-matcher. [100%] Building CXX object clif/backend/CMakeFiles/clif-matcher.dir/matcher_main.cc.o. [100%] Linking CXX executable clif-matcher. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE[_ZTIN4llvm2cl4listINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEbNS0_6parserIS7_EEEE]+0x18): undefined reference to typeinfo for llvm::cl::Option' CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyIbEE[_ZTIN4llvm2cl15OptionValueCopyIbEE]+0x10): undefined reference to typeinfo for llvm:🆑:GenericOptionValue'. CMakeFiles/clif-matcher.dir/matcher_main.cc.o:(.data.rel.ro._ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE[_ZTIN4llvm2cl15OptionValueCopyINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE]+0x10): undefined reference to typeinfo for llvm::cl::GenericOptionValue' libclifMatcher.a(ast.cc.o):(.data.rel.ro._ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE[_ZTIN4clif18TranslationUnitAST24ConversionFunctionFinderE]+0x10): undefined reference to typeinfo for clang::ast_matchers::MatchFinder::MatchCallback'. **Setup**. - Operating system: Centos 7. - DeepVariant version: Latest github version. - Installation method (Docker, built from source, etc.): building from source. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/380
https://github.com/google/deepvariant/issues/381:304,availability,avail,available,304,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:469,availability,avail,available,469,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:425,deployability,version,version,425,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:37,energy efficiency,model,models,37,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:135,energy efficiency,model,models,135,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:591,energy efficiency,model,models,591,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:674,energy efficiency,model,model,674,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:295,integrability,pub,publicly,295,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:425,integrability,version,version,425,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:153,interoperability,Specif,Specifically,153,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:30,modifiability,Pac,PacBio,30,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:128,modifiability,Pac,PacBio,128,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:425,modifiability,version,version,425,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:610,modifiability,Pac,PacBio,610,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:667,modifiability,Pac,PacBio,667,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:304,reliability,availab,available,304,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:469,reliability,availab,available,469,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:304,safety,avail,available,304,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:469,safety,avail,available,469,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:37,security,model,models,37,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:135,security,model,models,135,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:304,security,availab,available,304,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:469,security,availab,available,469,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:591,security,model,models,591,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/issues/381:674,security,model,model,674,"Information about pre-trained PacBio models in v1.0.0; Hi, is it possible to get some information regarding training of default PacBio models in v1.0.0? Specifically,. 1. What genomes were used in training? 2. What was the source of BAM or FASTQ files of genomes used for training, and are they publicly available? 3. What ground truth variant call set was used for training? If GIAB benchmark variants were used, then which version was used? I see this information is available [here ](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md)for Illumina models but not for PacBio. Also, can you please tell us which is the latest PacBio model trained on v3.3.2 of GIAB benchmark variant calls?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/381
https://github.com/google/deepvariant/pull/382:7,availability,error,error,7,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:44,energy efficiency,model,model,44,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:37,modifiability,Pac,PacBio,37,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:7,performance,error,error,7,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:218,performance,time,time,218,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:7,safety,error,error,7,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:44,security,model,model,44,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:268,security,team,team,268,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/pull/382:7,usability,error,error,7,"Fix an error in description: In v1.0 PacBio model, we actually only u…; …sed 2 HG002 BAMs instead of 9. The number of training examples is correct. PiperOrigin-RevId: 342301797. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/382
https://github.com/google/deepvariant/issues/383:76,availability,checkpoint,checkpoint,76,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:147,availability,checkpoint,checkpoint,147,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:173,availability,checkpoint,checkpoint-first,173,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:284,availability,checkpoint,checkpoint-first,284,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:392,availability,checkpoint,checkpoint-first,392,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:491,availability,checkpoint,checkpoint,491,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:646,availability,checkpoint,checkpoint-first,646,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:697,availability,checkpoint,checkpoint,697,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:11,energy efficiency,model,model-ckpt-,11,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:53,energy efficiency,load,loaded,53,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:141,energy efficiency,model,model,141,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:315,energy efficiency,model,model-ckpt-,315,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:509,energy efficiency,model,model-ckpt-,509,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:538,energy efficiency,model,model-ckpt-N,538,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:590,energy efficiency,model,model-ckpt-,590,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:621,energy efficiency,load,loading,621,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:670,energy efficiency,model,model-ckpt-N,670,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:797,energy efficiency,Cloud,Cloud,797,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:629,modifiability,paramet,parameters,629,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:53,performance,load,loaded,53,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:621,performance,load,loading,621,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:76,reliability,checkpoint,checkpoint,76,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:147,reliability,checkpoint,checkpoint,147,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:173,reliability,checkpoint,checkpoint-first,173,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:284,reliability,checkpoint,checkpoint-first,284,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:392,reliability,checkpoint,checkpoint-first,392,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:491,reliability,checkpoint,checkpoint,491,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:574,reliability,Doe,Does,574,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:646,reliability,checkpoint,checkpoint-first,646,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:697,reliability,checkpoint,checkpoint,697,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:11,security,model,model-ckpt-,11,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:141,security,model,model,141,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:315,security,model,model-ckpt-,315,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:509,security,model,model-ckpt-,509,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:538,security,model,model-ckpt-N,538,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:590,security,model,model-ckpt-,590,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/383:670,security,model,model-ckpt-N,670,"(TRAINING) model-ckpt-0 shows low accuracy even when loaded from a previous checkpoint; I ran training for a number of epochs and obtained a model checkpoint (lets call it `checkpoint-first`) with accuracy > 0.99 (F1/All). Then I launched training again with `--start_from_checkpoint=checkpoint-first`. I expected `model-ckpt-0` for the second training run to show the same high accuracy as `checkpoint-first`. But it shows very low accuracy instead (F1/All is 0.85 or so). However the next checkpoint after `model-ckpt-0` (lets call it `model-ckpt-N`) shows high accuracy. Does this mean `model-ckpt-0` is dumped before loading parameters from `checkpoint-first`, and `model-ckpt-N` is the first checkpoint I should be looking at for meaningful results for the second training run? I used Google Cloud TPU for both training runs. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/383
https://github.com/google/deepvariant/issues/384:37,integrability,filter,filter,37,"PCR duplicates; Hi, Does Deepvariant filter out (i.e. exclude) read duplicates, assuming they are flagged in the BAM/CRAM file? This is not mentioned in the documentation.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/384
https://github.com/google/deepvariant/issues/384:20,reliability,Doe,Does,20,"PCR duplicates; Hi, Does Deepvariant filter out (i.e. exclude) read duplicates, assuming they are flagged in the BAM/CRAM file? This is not mentioned in the documentation.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/384
https://github.com/google/deepvariant/issues/384:157,usability,document,documentation,157,"PCR duplicates; Hi, Does Deepvariant filter out (i.e. exclude) read duplicates, assuming they are flagged in the BAM/CRAM file? This is not mentioned in the documentation.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/384
https://github.com/google/deepvariant/issues/385:20,availability,error,error,20,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:126,availability,error,error,126,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:12,deployability,version,version,12,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:27,deployability,Modul,ModuleNotFoundError,27,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:281,deployability,modul,module,281,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:415,deployability,modul,module,415,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:559,deployability,modul,module,559,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:999,deployability,modul,module,999,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1332,deployability,Modul,ModuleNotFoundError,1332,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1356,deployability,modul,module,1356,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1025,energy efficiency,core,core,1025,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:12,integrability,version,version,12,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:12,modifiability,version,version,12,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:27,modifiability,Modul,ModuleNotFoundError,27,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:281,modifiability,modul,module,281,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:367,modifiability,pac,packages,367,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:415,modifiability,modul,module,415,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:507,modifiability,pac,packages,507,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:559,modifiability,modul,module,559,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:636,modifiability,pac,packages,636,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:884,modifiability,pac,package,884,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:953,modifiability,pac,packages,953,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:999,modifiability,modul,module,999,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1067,modifiability,pac,packages,1067,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1315,modifiability,pac,package,1315,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1332,modifiability,Modul,ModuleNotFoundError,1332,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1356,modifiability,modul,module,1356,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:20,performance,error,error,20,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:126,performance,error,error,126,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:20,safety,error,error,20,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:27,safety,Modul,ModuleNotFoundError,27,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:126,safety,error,error,126,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:281,safety,modul,module,281,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:415,safety,modul,module,415,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:559,safety,modul,module,559,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:999,safety,modul,module,999,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1332,safety,Modul,ModuleNotFoundError,1332,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:1356,safety,modul,module,1356,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:134,testability,Trace,Traceback,134,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:20,usability,error,error,20,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/385:126,usability,error,error,126,"Singularity version error: ModuleNotFoundError; Hi,. I'm using the docker Deepvariant 1.0.0 via singularity, and getting this error:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_nug2d3l9/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>. import tensorflow as tf. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>. from tensorflow_core import *. File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 33, in <module>. import distutils as _distutils. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/setuptools/__init__.py"", line 6, in <module>. import distutils.core. File ""/usr/local/lib/python3.6/dist-packages/_distutils_hack/__init__.py"", line 82, in create_module. return importlib.import_module('._distutils', 'setuptools'). File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). ModuleNotFoundError: No module named 'setuptools._distutils'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/385
https://github.com/google/deepvariant/issues/386:276,interoperability,specif,specifications,276,"REFCALL and GLnexus merging; Hi, Two questions:. 1) What does REFCALL mean? I saw another issue explaining it, but I'm still not understanding. If Deepvariant thinks a site is reference, why is it being reported at all? gVCF is supposed to report reference calls, but per VCF specifications, Deepvariant should not report reference calls. Furthermore, if it is a reference call, why is there an ALT allele? 2) Does your GLNexus merging/multi-sample genotyping workflow know to exclude REFCALL variants? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/386
https://github.com/google/deepvariant/issues/386:57,reliability,doe,does,57,"REFCALL and GLnexus merging; Hi, Two questions:. 1) What does REFCALL mean? I saw another issue explaining it, but I'm still not understanding. If Deepvariant thinks a site is reference, why is it being reported at all? gVCF is supposed to report reference calls, but per VCF specifications, Deepvariant should not report reference calls. Furthermore, if it is a reference call, why is there an ALT allele? 2) Does your GLNexus merging/multi-sample genotyping workflow know to exclude REFCALL variants? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/386
https://github.com/google/deepvariant/issues/386:410,reliability,Doe,Does,410,"REFCALL and GLnexus merging; Hi, Two questions:. 1) What does REFCALL mean? I saw another issue explaining it, but I'm still not understanding. If Deepvariant thinks a site is reference, why is it being reported at all? gVCF is supposed to report reference calls, but per VCF specifications, Deepvariant should not report reference calls. Furthermore, if it is a reference call, why is there an ALT allele? 2) Does your GLNexus merging/multi-sample genotyping workflow know to exclude REFCALL variants? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/386
https://github.com/google/deepvariant/issues/386:129,testability,understand,understanding,129,"REFCALL and GLnexus merging; Hi, Two questions:. 1) What does REFCALL mean? I saw another issue explaining it, but I'm still not understanding. If Deepvariant thinks a site is reference, why is it being reported at all? gVCF is supposed to report reference calls, but per VCF specifications, Deepvariant should not report reference calls. Furthermore, if it is a reference call, why is there an ALT allele? 2) Does your GLNexus merging/multi-sample genotyping workflow know to exclude REFCALL variants? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/386
https://github.com/google/deepvariant/issues/386:460,usability,workflow,workflow,460,"REFCALL and GLnexus merging; Hi, Two questions:. 1) What does REFCALL mean? I saw another issue explaining it, but I'm still not understanding. If Deepvariant thinks a site is reference, why is it being reported at all? gVCF is supposed to report reference calls, but per VCF specifications, Deepvariant should not report reference calls. Furthermore, if it is a reference call, why is there an ALT allele? 2) Does your GLNexus merging/multi-sample genotyping workflow know to exclude REFCALL variants? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/386
https://github.com/google/deepvariant/issues/388:75,safety,detect,detected,75,"Missed variant - Illumina WGS; Hi, The attached variant was missed. It was detected in 39 / 39 reads (100%) at the locus, and all reads have high MAPQ. Very strange, but warrants an explanation. It was not even a RefCall variant. Appreciate any advice. <img width=""943"" alt=""Screen Shot 2020-11-24 at 4 31 05 PM"" src=""https://user-images.githubusercontent.com/47928628/100153865-bd2e2700-2e72-11eb-9af1-c182b3fd57ee.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/388
https://github.com/google/deepvariant/issues/388:75,security,detect,detected,75,"Missed variant - Illumina WGS; Hi, The attached variant was missed. It was detected in 39 / 39 reads (100%) at the locus, and all reads have high MAPQ. Very strange, but warrants an explanation. It was not even a RefCall variant. Appreciate any advice. <img width=""943"" alt=""Screen Shot 2020-11-24 at 4 31 05 PM"" src=""https://user-images.githubusercontent.com/47928628/100153865-bd2e2700-2e72-11eb-9af1-c182b3fd57ee.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/388
https://github.com/google/deepvariant/issues/388:326,usability,user,user-images,326,"Missed variant - Illumina WGS; Hi, The attached variant was missed. It was detected in 39 / 39 reads (100%) at the locus, and all reads have high MAPQ. Very strange, but warrants an explanation. It was not even a RefCall variant. Appreciate any advice. <img width=""943"" alt=""Screen Shot 2020-11-24 at 4 31 05 PM"" src=""https://user-images.githubusercontent.com/47928628/100153865-bd2e2700-2e72-11eb-9af1-c182b3fd57ee.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/388
https://github.com/google/deepvariant/issues/389:219,availability,restor,restore,219,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:380,availability,down,download,380,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:44,energy efficiency,model,model,44,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:58,energy efficiency,model,models,58,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:69,energy efficiency,model,model,69,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:140,energy efficiency,model,model,140,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:151,energy efficiency,model,model,151,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:242,energy efficiency,model,model,242,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:256,energy efficiency,model,model,256,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:287,energy efficiency,model,model,287,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:350,energy efficiency,model,model,350,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:396,energy efficiency,model,model,396,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:219,reliability,restor,restore,219,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:44,security,model,model,44,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:58,security,model,models,58,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:69,security,model,model,69,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:140,security,model,model,140,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:151,security,model,model,151,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:242,security,model,model,242,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:256,security,model,model,256,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:287,security,model,model,287,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:350,security,model,model,350,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/389:396,security,model,model,396,"call variant with fp16; hi . i want to cast model in /opt/models/wgs/model.ckpt to fp16 to satisfy my poor machine，. but can not reload the model from model.ckpt.meta. I try to get graph from source code ,so that i can restore and save a new model,but the model i saved did not math the model tensorname in the source code. how can i convert trained model to fp16? or where i can download a fp16 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/389
https://github.com/google/deepvariant/issues/390:35,safety,input,input,35,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:116,safety,input,input,116,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:130,safety,input,input,130,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:201,safety,input,input,201,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:278,safety,input,input,278,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:931,safety,input,input,931,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1068,safety,input,input,1068,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1206,safety,input,input,1206,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1236,safety,input,input,1236,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1485,safety,input,input,1485,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:35,usability,input,input,35,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:116,usability,input,input,116,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:130,usability,input,input,130,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:201,usability,input,input,201,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:278,usability,input,input,278,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:931,usability,input,input,931,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1068,usability,input,input,1068,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1206,usability,input,input,1206,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1236,usability,input,input,1236,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1400,usability,help,helpshort,1400,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1415,usability,help,helpfull,1415,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1431,usability,help,help,1431,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/390:1485,usability,input,input,1485,"""no such file or directory: --ref=/input/Hg19ChrY.fa""; Hello ... On Mac, OSX ... When I run deepvariant with ls -l /input ... the input directory is recognized ... ```. docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. ls -l /input. total 86276. -rw-r--r-- 1 root root 1816 Dec 2 12:55 GRCh37ToHg19.over.chain.gz. -rw-r--r-- 1 root root 162 Dec 2 14:04 Hg19ChrY.dict. -rw-r----- 1 root root 60561044 Dec 2 14:04 Hg19ChrY.fa. -rw-r--r-- 1 root root 22 Dec 2 14:04 Hg19ChrY.fa.fai. -rw-r--r-- 1 root root 13086641 Dec 2 12:57 VK446chrYx19.bam. -rw-r--r-- 1 root root 38296 Dec 2 12:57 VK446chrYx19.bam.bai. drwxr-xr-x 2 root root 64 Dec 2 14:19 VK446chrYx19_dv. -rw-r----- 1 root root 13023881 Dec 2 12:45 VK446chrYx37.bam. -rw-r--r-- 1 root root 37880 Dec 2 12:44 VK446chrYx37.bam.bai. ```. However, when I attempt deepvariant run, I am getting ""no such file or directory: --ref=/input/Hg19ChrY.fa"". ```. BAMName=""VK446chrYx19"". INPUT_DIR=""${PWD}/"". OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \. -v ""${INPUT_DIR}:/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""1.0.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/Hg19ChrY.fa \. --reads=/input/${BAMName}.bam \. --output_vcf=/output/${BAMName}.vcf.gz \. --output_gvcf=/output/${BAMName}.g.vcf.gz \. --num_shards=24. ```. ```. --ref is required. Pass --helpshort or --helpfull to see help on flags. zsh: no such file or directory: --ref=/input/Hg19ChrY.fa. ```. Thanks for any suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/390
https://github.com/google/deepvariant/issues/391:194,availability,cluster,cluster,194,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:202,availability,servic,service,202,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:416,availability,cluster,cluster,416,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:424,availability,servic,service,424,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:507,availability,servic,service,507,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1203,availability,cluster,cluster,1203,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1211,availability,servic,service,1211,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1390,availability,cluster,cluster,1390,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1398,availability,servic,service,1398,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:6,deployability,instal,installed,6,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:39,deployability,version,version,39,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:158,deployability,updat,update,158,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:168,deployability,instal,install,168,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:194,deployability,cluster,cluster,194,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:202,deployability,servic,service,202,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:259,deployability,updat,update,259,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:315,deployability,updat,update,315,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:416,deployability,cluster,cluster,416,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:424,deployability,servic,service,424,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:470,deployability,updat,update,470,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:507,deployability,servic,service,507,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:583,deployability,instal,install,583,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:653,deployability,version,version,653,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:875,deployability,version,version,875,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1081,deployability,updat,update,1081," of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1190,deployability,updat,update,1190," cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1203,deployability,cluster,cluster,1203,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1211,deployability,servic,service,1211,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1315,deployability,instal,install,1315,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1390,deployability,cluster,cluster,1390,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1398,deployability,servic,service,1398,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1420,deployability,updat,update,1420,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1495,deployability,version,version,1495,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1978,deployability,version,version,1978,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:2056,deployability,version,version,2056,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:39,integrability,version,version,39,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:202,integrability,servic,service,202,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:424,integrability,servic,service,424,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:507,integrability,servic,service,507,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:653,integrability,version,version,653,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:875,integrability,version,version,875,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1211,integrability,servic,service,1211,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1398,integrability,servic,service,1398,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1495,integrability,version,version,1495,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1978,integrability,version,version,1978,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:2056,integrability,version,version,2056,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:39,modifiability,version,version,39,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:202,modifiability,servic,service,202,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:424,modifiability,servic,service,424,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:507,modifiability,servic,service,507,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:653,modifiability,version,version,653,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:875,modifiability,version,version,875,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1211,modifiability,servic,service,1211,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1398,modifiability,servic,service,1398,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1495,modifiability,version,version,1495,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1978,modifiability,version,version,1978,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:2056,modifiability,version,version,2056,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:111,safety,permiss,permission,111,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:158,safety,updat,update,158,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:259,safety,updat,update,259,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:315,safety,updat,update,315,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:448,safety,permiss,permission,448,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:470,safety,updat,update,470,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1081,safety,updat,update,1081," of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1190,safety,updat,update,1190," cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1338,safety,permiss,permission,1338,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1420,safety,updat,update,1420,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:158,security,updat,update,158,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:259,security,updat,update,259,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:315,security,updat,update,315,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:470,security,updat,update,470,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1081,security,updat,update,1081," of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1190,security,updat,update,1190," cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1420,security,updat,update,1420,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:2015,testability,mock,mockbuild,2015,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:271,usability,tool,tools,271,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:301,usability,user,users,301,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:329,usability,tool,tools,329,"conda installed deepvariant libm.so.6: version `GLIBC_2.23' not found; Hello,. first of all ,i do not have the permission to run docker on my machine or sudo update or install. And as i work on cluster service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:1235,usability,user,users,1235,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/391:2192,usability,help,help,2192,"r service,so i hardly can try to tell the Administrator to update some tools because there are other users and any update to key tools may cause them some troublesome.AS i know,many people work on bioinformation use cluster service and do not have permission to do sudo update or maybe not have a docker in service,but conda can do. so i try search conda deepvariant,and i try conda install -c bioconda deepvariant=1.0.0(on python3,and i also try other version on python2),and i find dv_make_examples.py, and i see many other guys also try conda.(https://github.com/google/deepvariant/issues/9). when i run dv_make_examples.py on python3,i get ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and i know it is wrong with GLIBC and the solution is to update GLIBC to GLIBC_2.23 ,but i can not . i ask my Administrator and he say the glibc is too important and update it on cluster service may cause other users bug. . so is there any chance i can use deepvatiant ? and again,i can not install from source(no permission to sudo ) or docker(don't have docker on cluster service ),and i can't update glibc . And the info are like this:. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /var/tmp/Bazel.runfiles_okfco2gt/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so). and strings /lib64/libc.so.6 |grep GLIBC:. GLIBC_2.2.5. GLIBC_2.2.6. GLIBC_2.3. GLIBC_2.3.2. GLIBC_2.3.3. GLIBC_2.3.4. GLIBC_2.4. GLIBC_2.5. GLIBC_2.6. GLIBC_2.7. GLIBC_2.8. GLIBC_2.9. GLIBC_2.10. GLIBC_2.11. GLIBC_2.12. GLIBC_2.13. GLIBC_2.14. GLIBC_2.15. GLIBC_2.16. GLIBC_2.17. GLIBC_PRIVATE. and the other information is :. Linux version 3.10.0-1127.18.2.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Sun Jul 26 15:27:06 UTC 2020. conda 4.9.2. Python 3.7.6. i really hope you can help me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/391
https://github.com/google/deepvariant/issues/392:556,availability,checkpoint,checkpoint,556,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:694,availability,error,error,694,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1175,availability,failur,failure,1175,"DIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1184,availability,Unavail,Unavailable,1184,"/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1197,availability,Error,Error,1197,"HARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1283,availability,error,error,1283,". -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2278,availability,checkpoint,checkpoint,2278,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2311,availability,checkpoint,checkpoint,2311,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2386,availability,checkpoint,checkpoint,2386,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:176,deployability,LOG,LOGDIR,176,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:191,deployability,log,log,191,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:961,deployability,fail,failed,961,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1023,deployability,fail,failed,1023,"et; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1114,deployability,fail,failed,1114,".0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1158,deployability,fail,failed,1158,"{PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1175,deployability,fail,failure,1175,"DIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1481,deployability,modul,module,1481,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:10,energy efficiency,model,model,10,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:256,energy efficiency,gpu,gpus,256,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:383,energy efficiency,gpu,gpu,383,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:585,energy efficiency,model,models,585,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:662,energy efficiency,model,model,662,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:855,energy efficiency,core,core,855,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:869,energy efficiency,cloud,cloud,869,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2439,energy efficiency,model,model,2439,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:860,interoperability,platform,platform,860,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1582,interoperability,platform,platform,1582,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1481,modifiability,modul,module,1481,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1550,modifiability,pac,packages,1550,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:256,performance,gpu,gpus,256,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:383,performance,gpu,gpu,383,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:694,performance,error,error,694,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1175,performance,failur,failure,1175,"DIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1197,performance,Error,Error,1197,"HARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1283,performance,error,error,1283,". -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:556,reliability,checkpoint,checkpoint,556,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:961,reliability,fail,failed,961,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1023,reliability,fail,failed,1023,"et; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1114,reliability,fail,failed,1114,".0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1158,reliability,fail,failed,1158,"{PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1175,reliability,fail,failure,1175,"DIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2278,reliability,checkpoint,checkpoint,2278,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2311,reliability,checkpoint,checkpoint,2311,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2386,reliability,checkpoint,checkpoint,2386,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:176,safety,LOG,LOGDIR,176,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:191,safety,log,log,191,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:308,safety,input,input,308,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:694,safety,error,error,694,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:783,safety,input,input,783,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1197,safety,Error,Error,1197,"HARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1283,safety,error,error,1283,". -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1481,safety,modul,module,1481,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:10,security,model,model,10,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:176,security,LOG,LOGDIR,176,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:191,security,log,log,191,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:585,security,model,models,585,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:662,security,model,model,662,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:933,security,authenticat,authentication,933,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:955,security,token,token,955,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:988,security,token,token,988,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1006,security,token,token,1006," model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1099,security,token,token,1099,"IN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2439,security,model,model,2439,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:176,testability,LOG,LOGDIR,176,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:191,testability,log,log,191,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1333,testability,Trace,Traceback,1333,"utput"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:81,usability,command,command,81,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:308,usability,input,input,308,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:694,usability,error,error,694,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:783,usability,input,input,783,"Incorrect model in GS bucket; Hello, when running Deepvariant with the following command: . ```bash. BIN_VERSION=""1.0.0""`. INPUT_DIR=""${PWD}/data"". OUTPUT_DIR=""${PWD}/output"". LOGDIR=""${PWD}/log"". N_SHARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1197,usability,Error,Error,1197,"HARDS=$( /bin/ls output/ | wc -l ). . sudo docker run --gpus 1 \. -v ${HOME}:${HOME} \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:1283,usability,error,error,1283,". -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}-gpu"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${OUTPUT_DIR}/call_variants_output.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/issues/392:2423,usability,command,command,2423,"tput.tfrecord.gz"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" \. --checkpoint ""gs://deepvariant/models/DeepVariant/1.0.0/DeepVariant-inception_v3-1.0.0+data-pacbio_standard/model.ckpt"". ```. the following error occurs:. ```. I1203 17:49:21.931325 140389904897792 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-12-03 17:49:32.284722: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_a7fwubx_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 8 channels while the examples have 6. ```. Running with the checkpoint for 0.9.0 works with this command. Is the model on the GS bucket correct?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/392
https://github.com/google/deepvariant/pull/393:100,deployability,log,logging,100,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:383,deployability,patch,patch,383,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:100,safety,log,logging,100,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:320,safety,test,test,320,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:383,safety,patch,patch,383,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:407,safety,valid,validation,407,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:100,security,log,logging,100,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:383,security,patch,patch,383,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:407,security,validat,validation,407,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:100,testability,log,logging,100,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:320,testability,test,test,320,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/pull/393:347,usability,workflow,workflows,347,OpenVINO processing in thread; Run OpenVINO processing in separate thread which let's to use common logging (https://github.com/google/deepvariant/pull/363/commits/3cfa6c563824bddc84e36373f65f2620160d6eb5 + https://github.com/google/deepvariant/pull/363/commits/9e69c4096fac8ddb788c3d29e4405fc50e85d1e3) . Please ignore test scripts from `.github/workflows` - they are not a part of patch but just used for validation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/393
https://github.com/google/deepvariant/issues/394:339,availability,error,error,339,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:6,deployability,instal,installation,6,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:93,deployability,upgrad,upgrade,93,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:117,deployability,instal,installation,117,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:144,deployability,releas,release,144,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:190,deployability,instal,installation,190,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:400,deployability,instal,installing,400,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:476,deployability,build,build-prereq,476,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:497,deployability,fail,fail,497,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:585,deployability,version,versions,585,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:861,deployability,updat,update,861,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:868,deployability,version,version,868,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:886,deployability,instal,installing,886,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:932,deployability,instal,installation,932,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:1188,deployability,releas,released,1188,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:585,integrability,version,versions,585,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:868,integrability,version,version,868,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:93,modifiability,upgrad,upgrade,93,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:585,modifiability,version,versions,585,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:868,modifiability,version,version,868,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:339,performance,error,error,339,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:497,reliability,fail,fail,497,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:339,safety,error,error,339,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:861,safety,updat,update,861,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:920,safety,test,tested,920,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:46,security,team,team,46,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:861,security,updat,update,861,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:750,testability,understand,understand,750,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:920,testability,test,tested,920,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:69,usability,tool,tool,69,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/394:339,usability,error,error,339,"Numpy installation problem; Hello DeepVariant team, thanks for great tool. After we tried to upgrade our deepvariant installation to the latest release we encountered a problem with `numpy` installation, which I described [here](https://github.com/pypa/wheel/issues/389). The problem is caused by `wheel` - not by `numpy` itself, but this error raised several questions for me:. - For now looks like installing deepvariant with https://github.com/google/deepvariant/blob/r1.1/build-prereq.sh will fail on non `Ubuntu 16.04` due to `numpy` problem. This problem won't be fixed in older versions of `numpy` I think - only `wheel` can fix it now. Or you can switch `numpy 1.18.5` for `1.19.3+`? - Part of this problem origins from using Python 3.6 if I understand correctly [this](https://github.com/pypa/wheel/issues/331#issuecomment-579285573), maybe you should update version of Python installing by script? - I've just tested your installation script with one change: I added `Ubuntu 18.04` to this [check](https://github.com/google/deepvariant/blob/r1.1/run-prereq.sh#L120) - looks like all good. If a problem was in `Ubuntu 14.04` - maybe wide this check a bit? Even `Ubuntu 20.04` is released half a year ago.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/394
https://github.com/google/deepvariant/issues/395:6,deployability,instal,install,6,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:61,deployability,instal,install,61,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:25,energy efficiency,model,model,25,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:467,energy efficiency,model,model,467,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:168,integrability,pub,published,168,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:31,modifiability,PAC,PACBIO,31,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:186,modifiability,pac,package,186,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:237,modifiability,paramet,parameters,237,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:273,modifiability,PAC,PACBIO,273,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:108,safety,test,test,108,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:25,security,model,model,25,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:44,security,Auth,Authors,44,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:467,security,model,model,467,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:108,testability,test,test,108,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/395:420,usability,close,close,420,"conda install dv without model PACBIO; Dear Authors,. I just install deepvariant using conda and prepare to test the software with HiFi data. I noticed in the recently published DipAsm [package](https://github.com/shilpagarg/DipAsm) the parameters 'model_type' was set as 'PACBIO' in 'dv.sh' file, but there are only two options supplied in conda-deepvariant(wgs & wes). Since the alleged HiFidata base accuracy is very close to Illumina data, I wonder can I use wgs model for now? . Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/395
https://github.com/google/deepvariant/issues/396:773,availability,error,error,773,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:697,deployability,fail,failed,697,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2043,deployability,modul,module,2043,"gle_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2071,deployability,fail,failed,2071,"realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2488,deployability,modul,module,2488,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:789,energy efficiency,Current,Current,789,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2784,integrability,sub,subprocess,2784,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2877,integrability,sub,subprocess,2877,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2958,integrability,sub,subprocess,2958,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:3038,integrability,buffer,buffer,3038,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2043,modifiability,modul,module,2043,"gle_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2488,modifiability,modul,module,2488,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2548,modifiability,pac,packages,2548,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2648,modifiability,pac,packages,2648,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:773,performance,error,error,773,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2052,performance,parallel,parallel,2052,"riant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2998,performance,time,time,2998,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:3013,performance,parallel,parallel,3013,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:697,reliability,fail,failed,697,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2071,reliability,fail,failed,2071,"realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:773,safety,error,error,773,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2043,safety,modul,module,2043,"gle_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2488,safety,modul,module,2488,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2390,testability,Trace,Traceback,2390,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:5,usability,statu,status,5,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:773,usability,error,error,773,"Exit status 250 Could not read base quality scores; I am running on BAM generated with BWA. The fastq that was used had one reads file with less sequences. Docker latest image. . /opt/deepvariant/bin/run_deepvariant --model_type WGS --num_shards 5 --output_vcf 19CT030668_deepvariant.vcf --reads 19CT030668.bam --ref ../human_g1k_v37.fasta --sample_name 19CT030668. The processe starts but when it gets to end of the BAM it exits. . 2020-12-11 15:45:32.928477: W third_party/nucleus/io/sam_reader.cc:532] Could not read base quality scores A00215:130:HK3H2DSXX:2:2549:4869:24768: Not found: Could not read base quality scores. 2020-12-11 15:45:32.931412: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (1 vs. 0). Fatal Python error: Aborted. Current thread 0x00007f38280a8700 (most recent call first):. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 237 in select_windows. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 574 in realign_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2290,usability,user,user,2290,"k22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can igno",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2806,usability,command,command,2806,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:2989,usability,Command,Command,2989,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/issues/396:3270,usability,statu,status,3270,"t/make_examples.py"", line 1129 in region_reads. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1055 in process. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1377 in make_examples_runner. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500 in main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_pfk22dn_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ../human_g1k_v37.fasta --reads 19CT030668.bam --examples /tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz --sample_name 19CT030668 --task 3. real 102m9.946s. user 101m6.868s. sys 0m54.452s. I1211 15:45:33.976910 139868428207872 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""../human_g1k_v37.fasta"" --reads ""19CT030668.bam"" --examples ""/tmp/tmpy0c9vszu/make_examples.tfrecord@5.gz"" --sample_name ""19CT030668"" --task {}' returned non-zero exit status 250. **can ignore read quality scores check and give results?**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/396
https://github.com/google/deepvariant/pull/397:0,deployability,Updat,Update,0,Update documentation.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/397
https://github.com/google/deepvariant/pull/397:63,performance,time,time,63,Update documentation.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/397
https://github.com/google/deepvariant/pull/397:0,safety,Updat,Update,0,Update documentation.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/397
https://github.com/google/deepvariant/pull/397:0,security,Updat,Update,0,Update documentation.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/397
https://github.com/google/deepvariant/pull/397:123,security,team,team,123,Update documentation.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/397
https://github.com/google/deepvariant/pull/397:7,usability,document,documentation,7,Update documentation.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/397
https://github.com/google/deepvariant/issues/398:209,interoperability,format,formation,209,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:390,safety,safe,safe,390,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:0,testability,Simpl,Simple,0,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:44,testability,simpl,simple,44,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:0,usability,Simpl,Simple,0,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:44,usability,simpl,simple,44,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:71,usability,person,persons,71,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:230,usability,Person,Personally,230,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:356,usability,user,user,356,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:361,usability,experien,experience,361,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/398:426,usability,tool,tool,426,"Simple suggestion; Hello! . not an issue, a simple suggestion: several persons I know are put off by DeepVariant because they can't get a gVCF with a line per base, basically they would like to deactivate the formation of blocks. Personally, blocks have never worried me and I guess computationally it has its advantages. . But just to tlet you know as a ""user experience"". Cheers and stay safe. DeepVariant is a very awesome tool.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/398
https://github.com/google/deepvariant/issues/399:458,availability,error,error,458,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:644,availability,error,error,644,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:142,deployability,pipelin,pipeline,142,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:55,energy efficiency,Cloud,Cloud,55,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:165,energy efficiency,cloud,cloud,165,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:219,energy efficiency,cloud,cloud,219,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:296,energy efficiency,cloud,cloud,296,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:142,integrability,pipelin,pipeline,142,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:650,integrability,messag,messages,650,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:650,interoperability,messag,messages,650,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:458,performance,error,error,458,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:644,performance,error,error,644,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:458,safety,error,error,458,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:644,safety,error,error,644,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:401,usability,command,command,401,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:458,usability,error,error,458,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:477,usability,indicat,indicates,477,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:631,usability,command,commands,631,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/399:644,usability,error,error,644,"Discrepancies with Deepvariant instructions for Google Cloud; Hi,. I don't know if this is the place to report issues with running the docker pipeline on the google cloud, I have been following instructions at [https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant#console_1) and it mostly works, but the second command within the big docker call dies with some python error. . That page indicates I should email google directly at google-genomics-contact@google.com, but this address bounces, which is why I came here. Anyway I have all the commands and error messages etc, so let me know if this is the right place for that and I will post. Thanks,. Ariel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/399
https://github.com/google/deepvariant/issues/400:146,availability,Operat,Operating,146,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:846,availability,Error,Error,846,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:886,availability,Error,Error,886,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:981,availability,Error,Error,981,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:211,deployability,version,version,211,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:229,deployability,version,version,229,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1351,deployability,modul,module,1351,"type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2579,deployability,CONTAIN,CONTAINER,2579,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2597,energy efficiency,CPU,CPU,2597,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:17,integrability,buffer,buffer,17,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:211,integrability,version,version,211,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:229,integrability,version,version,229,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:932,integrability,buffer,buffer,932,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1653,integrability,sub,subprocess,1653,"--output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1746,integrability,sub,subprocess,1746,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1827,integrability,sub,subprocess,1827,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1910,integrability,buffer,buffer,1910,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:211,modifiability,version,version,211,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:229,modifiability,version,version,229,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1351,modifiability,modul,module,1351,"type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1411,modifiability,pac,packages,1411,"87706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_imag",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1511,modifiability,pac,packages,1511,"_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:45,performance,disk,disk,45,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:846,performance,Error,Error,846,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:876,performance,parallel,parallel,876,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:886,performance,Error,Error,886,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:960,performance,disk,disk,960,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:971,performance,parallel,parallel,971,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:981,performance,Error,Error,981,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1867,performance,time,time,1867,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1882,performance,parallel,parallel,1882,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2505,performance,memor,memory,2505,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2597,performance,CPU,CPU,2597,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2631,performance,I/O,I/O,2631,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2641,performance,I/O,I/O,2641,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:846,safety,Error,Error,846,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:886,safety,Error,Error,886,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:981,safety,Error,Error,981,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1351,safety,modul,module,1351,"type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:852,testability,trace,trace,852,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1247,testability,Trace,Traceback,1247," data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:61,usability,Statu,Status,61,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:292,usability,Command,Command,292,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:846,usability,Error,Error,846,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:886,usability,Error,Error,886,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:981,usability,Error,Error,981,"Cannot append to buffer file in /tmp. Is the disk full? Exit Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1055,usability,close,close,1055,"it Status 255; I am running the Docker google/deepvariant:latest-deeptrio. **Setup**. - Operating system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1151,usability,user,user,1151,"ng system: Docker Desktop 3.0 (Windows 10). - DeepVariant version: DeepTrio version 1.1.0. Trio WGS data HG37 (bams aligned with BWA MEM). Command: . /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type=WGS --ref=human_g1k_v37.fasta --reads_child=DS187706-DS187706_39743_S1_261735.bam --reads_parent1=19CT021737-19CT021737-20190619_64683_S7_346963.bam --reads_parent2=19CT021740-19CT021740-20190619_64686_S8_346962.bam --output_vcf_child DS187706_proband.vcf --output_vcf_parent1 19CT021737_mother.vcf --output_vcf_parent2 19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1675,usability,command,command,1675,"19CT021740_father.vcf --sample_name_child 'DS187706_proband' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:1858,usability,Command,Command,1858,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2470,usability,statu,status,2470,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/400:2505,usability,memor,memory,2505,"' --sample_name_parent1 '19CT021737_mother.vcf' --sample_name_parent2 '19CT021740_father' --num_shards 6. - Error trace: (if applicable). parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 438m45.227s. user 0m12.742s. sys 0m12.847s. I1220 22:21:36.502776 140568143795968 run_deeptrio.py:584] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 600, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 582, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""human_g1k_v37.fasta"" --reads_parent1 ""19CT021737-19CT021737-20190619_64683_S7_346963.bam"" --reads_parent2 ""19CT021740-19CT021740-20190619_64686_S8_346962.bam"" --reads ""DS187706-DS187706_39743_S1_261735.bam"" --examples ""/tmp/tmpgyn9dtrr/make_examples.tfrecord@6.gz"" --sample_name ""DS187706_proband"" --sample_name_parent1 ""19CT021737_mother.vcf"" --sample_name_parent2 ""19CT021740_father"" --pileup_image_height_child ""60"" --pileup_image_height_parent ""40"" --task {}' returned non-zero exit status 255. It looks like there is memory in Docker and in my virtual folder so it shouldn't be running out. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. bc855d19a65d musing_saha 0.00% 35.36GiB / 93.81GiB 37.69% 3.13kB / 0B 313MB / 28.7kB 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/400
https://github.com/google/deepvariant/issues/401:90,safety,input,input,90,About 6 channels; Incept V3 only accept no more than 3 channel. How deepvariant process 6 input channels,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/401
https://github.com/google/deepvariant/issues/401:90,usability,input,input,90,About 6 channels; Incept V3 only accept no more than 3 channel. How deepvariant process 6 input channels,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/401
https://github.com/google/deepvariant/issues/402:1175,availability,Operat,Operating,1175,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1200,availability,cluster,cluster,1200,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1421,availability,Error,Error,1421,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1200,deployability,cluster,cluster,1200,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1223,deployability,version,version,1223,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1241,deployability,Instal,Installation,1241,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1223,integrability,version,version,1223,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1223,modifiability,version,version,1223,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:193,performance,cach,cached,193,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1421,performance,Error,Error,1421,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1447,reliability,Doe,Does,1447,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:351,safety,test,testdata,351,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:595,safety,test,testdata,595,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1421,safety,Error,Error,1421,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1468,safety,test,test,1468,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1504,safety,test,test,1504,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:351,testability,test,testdata,351,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:376,testability,unit,unittest,376,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:595,testability,test,testdata,595,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:857,testability,unit,unittest,857,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1427,testability,trace,trace,1427,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1468,testability,test,test,1468,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1504,testability,test,test,1504,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1712,testability,context,context,1712,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:134,usability,document,document,134,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:237,usability,help,helpshort,237,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:252,usability,help,helpfull,252,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:268,usability,help,help,268,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1399,usability,Command,Command,1399,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/402:1421,usability,Error,Error,1421,"DeepVariant not finding reference genome; **Describe the issue:**. When I try to run DeepVariant using the examples in the quickstart document I receive the following output:. ```. INFO: Using cached SIF image. --ref is required. Pass --helpshort or --helpfull to see help on flags.run_deepvariant.sh: line 13: --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. ```. I am able to open the FASTA file at that path, so I know that it exists. The full script I am using is:. ```. #!/bin/sh. BIN_VERSION=""1.0.0"". INPUT_DIR=""${PWD}/quickstart-testdata"". OUTPUT_DIR=""${PWD}/quickstart-output"". singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```. **Setup**. - Operating system: Linux, cluster. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Docker, through Singularity. - Type of data: The data from the quickstart . **Steps to reproduce:**. - Command: See above. - Error trace: See above. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? My issue is with the quickstart. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/402
https://github.com/google/deepvariant/issues/403:320,energy efficiency,model,model,320,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:523,interoperability,specif,specifically,523,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:187,modifiability,Deco,DecodeGenetics,187,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:313,modifiability,PAC,PACBIO,313,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:320,security,model,model,320,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:506,testability,understand,understand,506,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:665,testability,understand,understand,665,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:769,testability,understand,understanding,769,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:707,usability,clear,clearly,707,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/403:715,usability,indicat,indicate,715,"DeepVariant on corrected ONT in difficult to map regions; Hi,. So I am trying a little bit of a peculiar setup in which I am using ONT corrected reads (with [Ratatosk](https://github.com/DecodeGenetics/Ratatosk)) to call variants with DeepVariant 1.1 in difficult to map regions. For that, I am using the default PACBIO model which works pretty well in the non-difficult to map regions from what I've seen so far. Now in the difficult to map regions, it is a little bit of a mixed bag which I am trying to understand. More specifically, I get variants in my GVCFs such as:. ```. chr1	26740	.	C	<*>	0	.	END=26740	GT:GQ:MIN_DP:PL	./.:0:7:38,0,128. ```. What I do not understand is that the PL values seems to clearly indicate 0/1, yet the genotype is undefined. Also, my understanding of GQ is that it is derived from the PL values as the difference between most likely and second most likely genotypes. Yet, the GQ is 0 in this example. . I would really appreciate if you could shed some light on this. Thank you very much. Guillaume .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/403
https://github.com/google/deepvariant/issues/404:405,availability,error,error,405,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2580,availability,checkpoint,checkpoint,2580," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:60,deployability,contain,container,60,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:588,deployability,updat,updating,588,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:820,deployability,modul,module,820,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2465,deployability,contain,container,2465," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2488,deployability,updat,updated,2488," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:446,energy efficiency,model,model,446,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:557,energy efficiency,model,model,557,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:1625,energy efficiency,model,model,1625,"remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` para",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:1631,energy efficiency,model,model,1631,"_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:1797,energy efficiency,model,model,1797," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2388,energy efficiency,model,model,2388," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2444,energy efficiency,model,model,2444," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2597,energy efficiency,model,models,2597," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2611,energy efficiency,model,model,2611," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:916,interoperability,platform,platform,916,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:545,modifiability,pac,pacbio,545,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:820,modifiability,modul,module,820,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:889,modifiability,pac,packages,889,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2061,modifiability,pac,packages,2061," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2188,modifiability,pac,packages,2188," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2604,modifiability,pac,pacbio,2604," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2624,modifiability,paramet,parameter,2624," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:405,performance,error,error,405,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2580,reliability,checkpoint,checkpoint,2580," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:405,safety,error,error,405,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:588,safety,updat,updating,588,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:820,safety,modul,module,820,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2365,safety,Permiss,PermissionDeniedError,2365," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2488,safety,updat,updated,2488," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:446,security,model,model,446,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:557,security,model,model,557,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:588,security,updat,updating,588,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:1625,security,model,model,1625,"remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` para",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:1631,security,model,model,1631,"_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:1797,security,model,model,1797," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2388,security,model,model,2388," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2444,security,model,model,2444," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2488,security,updat,updated,2488," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2597,security,model,models,2597," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:2611,security,model,model,2611," File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_def.SerializeToString()). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 101, in write. self._prewrite_check(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 87, in _prewrite_check. compat.as_bytes(self.__name), compat.as_bytes(self.__mode)). tensorflow.python.framework.errors_impl.PermissionDeniedError: model.pb; Read-only file system. ```. I guess since the model resides in the container, it can't be updated as singularity is read-only without sudo. Would there be some way of passing the `--checkpoint ""/opt/models/pacbio/model.ckpt""` parameter, but allowing it to be saved elsewhere? Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:652,testability,Trace,Traceback,652,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:202,usability,progress,progress,202,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/404:405,usability,error,error,405,"Using openvino needs to write, causes issues with read-only container; Hi,. I've been encountering an issue when using the `openvino` extra arg for calling variants. When I do not use this flag, things progress as expected. When using the extra flag, both via `--call_variants_extra_args ""use_openvino=true""` to *run_deepvariant* as well as the `--use_openvino` to *call_variants*, there is the following error about being unable to save the new model due to read-only system. This is running V1.1.0 via singularity on a linux system, using the pacbio hifi model. . ```. Instructions for updating:. Use `tf.compat.v1.graph_util.remove_training_nodes`. Traceback (most recent call last):. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/scratch/13530063.tmpdir/Bazel.runfiles_69_p3nci/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 81, in freeze_graph. f.write(graph_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/404
https://github.com/google/deepvariant/issues/405:249,availability,avail,available,249,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:198,deployability,pipelin,pipeline,198,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:456,energy efficiency,power,power,456,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:475,energy efficiency,frequenc,frequencies,475,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:198,integrability,pipelin,pipeline,198,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:435,performance,time,time,435,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:249,reliability,availab,available,249,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:249,safety,avail,available,249,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:249,security,availab,available,249,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/issues/405:375,usability,help,help,375,"DeepVariant+GLnexus; Dear,. I tried the combination of the DeepVariant and GLnexus and they are working perfectly fine. I would like to know is there a way to incrementally add to the output of the pipeline? of course, if all the previous gvcfs are available in case of new variants. I mean something like the genomicsDB which is now being used by GATK. This will be a great help in case of a large cohort because it can save a lot of time and computation power to calculate frequencies. Kind regards. Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/405
https://github.com/google/deepvariant/pull/407:370,deployability,contain,contains,370,Add external post ability and DV 1.0 Post; Adds the ability to link to external posts. Add an `external_url` and `source` to the frontmatter of a post and it will use the external link and list the source like this:. ![image](https://user-images.githubusercontent.com/1536935/105360574-be57a800-5bc6-11eb-98f9-f3bccc3a1100.png). A blank page is created for the post but contains a redirect tag for users that access the post via RSS.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/407
https://github.com/google/deepvariant/pull/407:409,security,access,access,409,Add external post ability and DV 1.0 Post; Adds the ability to link to external posts. Add an `external_url` and `source` to the frontmatter of a post and it will use the external link and list the source like this:. ![image](https://user-images.githubusercontent.com/1536935/105360574-be57a800-5bc6-11eb-98f9-f3bccc3a1100.png). A blank page is created for the post but contains a redirect tag for users that access the post via RSS.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/407
https://github.com/google/deepvariant/pull/407:234,usability,user,user-images,234,Add external post ability and DV 1.0 Post; Adds the ability to link to external posts. Add an `external_url` and `source` to the frontmatter of a post and it will use the external link and list the source like this:. ![image](https://user-images.githubusercontent.com/1536935/105360574-be57a800-5bc6-11eb-98f9-f3bccc3a1100.png). A blank page is created for the post but contains a redirect tag for users that access the post via RSS.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/407
https://github.com/google/deepvariant/pull/407:398,usability,user,users,398,Add external post ability and DV 1.0 Post; Adds the ability to link to external posts. Add an `external_url` and `source` to the frontmatter of a post and it will use the external link and list the source like this:. ![image](https://user-images.githubusercontent.com/1536935/105360574-be57a800-5bc6-11eb-98f9-f3bccc3a1100.png). A blank page is created for the post but contains a redirect tag for users that access the post via RSS.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/407
https://github.com/google/deepvariant/issues/408:167,deployability,contain,container,167,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:256,deployability,version,version,256,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:463,deployability,CONTAIN,CONTAINER,463,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:481,energy efficiency,CPU,CPU,481,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:256,integrability,version,version,256,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:256,modifiability,version,version,256,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:0,performance,perform,performance,0,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:59,performance,perform,performance,59,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:336,performance,perform,performance,336,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:481,performance,CPU,CPU,481,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:515,performance,I/O,I/O,515,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:525,performance,I/O,I/O,525,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:0,usability,perform,performance,0,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:59,usability,perform,performance,59,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/408:336,usability,perform,performance,336,"performance re:openvino; I would like to clarify about the performance improvements re:--call_variants_extra_args ""use_openvino=true"". I am running the Docker Desktop container of the DeepVariant with the openvino feature on Windows 10. I am not sure what version deepvariant is at moment. Below is the output and how can I know if the performance boost is actually working. It seems to be taking just as long. the data is from WGS illumina. . docker stats. ```. CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS. 81c4c886a344 lucid_brown 499.35% 3.191GiB / 44.34GiB 7.20% 3.06kB / 0B 197MB / 0B 20. ```. ```. I0122 00:06:38.538676 140590877263616 make_examples.py:535] Task 2/5: 1501 candidates (1558 examples) [521.15s elapsed]. I0122 00:13:25.409308 139769488508672 make_examples.py:535] Task 1/5: 2300 candidates (2377 examples) [2030.76s elapsed]. I0122 00:14:08.258885 140590877263616 make_examples.py:535] Task 2/5: 1600 candidates (1665 examples) [449.72s elapsed]. I0122 00:17:39.217728 139769488508672 make_examples.py:535] Task 1/5: 2400 candidates (2477 examples) [253.81s elapsed]. I0122 00:24:45.306580 139769488508672 make_examples.py:535] Task 1/5: 2500 candidates (2579 examples) [426.09s elapsed]. I0122 00:33:59.351311 139769488508672 make_examples.py:535] Task 1/5: 2600 candidates (2685 examples) [554.04s elapsed]. I0122 00:36:39.138627 139769488508672 make_examples.py:535] Task 1/5: 2702 candidates (2796 examples) [159.79s elapsed]. I0122 00:44:51.534385 140120745805568 make_examples.py:535] Task 3/5: 1900 candidates (1966 examples) [4131.79s elapsed]. I0122 00:51:27.674227 140590877263616 make_examples.py:535] Task 2/5: 1700 candidates (1765 examples) [2239.42s elapsed]. I0122 01:07:23.046070 139769488508672 make_examples.py:535] Task 1/5: 2808 candidates (2902 examples) [1843.91s elapsed]. I0122 01:14:33.716036 140590877263616 make_examples.py:535] Task 2/5: 1800 candidates (1872 examples) [1386.04s elapsed]. I0122 01:20:36.708237 13976948850",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/408
https://github.com/google/deepvariant/issues/410:120,availability,down,download,120,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:222,availability,down,download-,222,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:34,energy efficiency,model,model,34,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:77,energy efficiency,model,model,77,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:662,energy efficiency,model,model,662,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:668,interoperability,specif,specifically,668,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:377,modifiability,pac,pacbio,377,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:470,modifiability,pac,pacbio,470,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:655,modifiability,pac,pacbio,655,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:34,security,model,model,34,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:77,security,model,model,77,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/410:662,security,model,model,662,"Clarifying docs on running hybrid model with phased bam files; In the hybrid model case study, the example bam files to download [here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-hybrid-case-study.md#download-hg003-chr20-bam) are labeled `HG003_hybrid_35x_ilmn_35x_pacb.grch38.phased.chr20.bam`. Have these bam files been phased in the same way as in the pacbio case study? If so, is the merged bam file able to be phased via `whatshap`, or is the pacbio bam phased independently and then merged with the short read bam. Digging through the `run_deepvariant.py` script makes it seem like the phasing information only pertains to the pacbio model specifically, but just wanted to check. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/410
https://github.com/google/deepvariant/issues/411:282,availability,Operat,Operating,282,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:478,availability,Error,Error,478,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1098,availability,error,error,1098,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:331,deployability,version,version,331,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:349,deployability,Instal,Installation,349,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1195,deployability,log,log,1195,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1258,deployability,log,log,1258,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:331,integrability,version,version,331,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1104,integrability,messag,message,1104,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1104,interoperability,messag,message,1104,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:331,modifiability,version,version,331,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:995,modifiability,paramet,parameterized,995,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:478,performance,Error,Error,478,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1098,performance,error,error,1098,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:52,reliability,doe,doesn,52,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:211,reliability,doe,doesn,211,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:510,reliability,Doe,Does,510,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:567,reliability,doe,does,567,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:478,safety,Error,Error,478,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:531,safety,test,test,531,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1098,safety,error,error,1098,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1195,safety,log,log,1195,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1258,safety,log,log,1258,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1195,security,log,log,1195,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1258,security,log,log,1258,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:484,testability,trace,trace,484,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:531,testability,test,test,531,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:660,testability,context,context,660,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1195,testability,log,log,1195,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1258,testability,log,log,1258,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:465,usability,Command,Command,465,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:478,usability,Error,Error,478,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:922,usability,command,command,922,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/411:1098,usability,error,error,1098,"The middle base of reference sequence in the window doesn't match first character of variant.reference_bases; **Describe the issue:**. In ```make_examples```: The middle base of reference sequence in the window doesn't match first character of variant.reference_bases. **Setup**. - Operating system: CentOS Linux v7. - DeepVariant version: 1.1.0. - Installation method: Docker. - Type of data: WGS (Illumina 150nt pairs from GIAB HG002). **Steps to reproduce:**. - Command: . - Error trace: (if applicable). **Does the quick start test work on your system?** Yes, it does. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. The goal is to call SNPs and indels in GIAB HG002 WGS data, and to compare the results with a truthset. High-confidence intervals and the truthset are at https://github.com/genome-in-a-bottle/giab_latest_release. Please see the attached bash script (command line) and output files. Two questions:. - Is ```make_examples``` parameterized correctly (see attached script and output files)? - Can someone please explain what this error message means and suggest an appropriate approach to troubleshooting and fixing it? [vcall.log](https://github.com/google/deepvariant/files/5858295/vcall.log). [vcall.sh.txt](https://github.com/google/deepvariant/files/5858303/vcall.sh.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/411
https://github.com/google/deepvariant/issues/412:446,availability,Error,Error,446,"RNA Seq failed exit status 247; I thought I should be able to call variants from short reads aligned to the human genome (hg19) with hisat2. So I gave it a try. Windows 10 Docker desktop. . `/opt/deepvariant/bin/run_deepvariant --model_type=WGS --output_vcf=CDAR-016_run0124_deepvariant.vcf --reads=CDAR-016_human37_align.bam --ref=./CFM032/human_g1k_v37.fasta --novcf_stats_report --num_shards=5 --call_variants_extra_args ""use_openvino=true""`. Error:. ```. I0123 08:06:11.771944 139769488508672 make_examples.py:535] Task 1/5: 9704 candidates (9978 examples) [651.40s elapsed]. I0123 08:07:25.050816 140120745805568 make_examples.py:535] Task 3/5: 9400 candidates (9710 examples) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:8,deployability,fail,failed,8,"RNA Seq failed exit status 247; I thought I should be able to call variants from short reads aligned to the human genome (hg19) with hisat2. So I gave it a try. Windows 10 Docker desktop. . `/opt/deepvariant/bin/run_deepvariant --model_type=WGS --output_vcf=CDAR-016_run0124_deepvariant.vcf --reads=CDAR-016_human37_align.bam --ref=./CFM032/human_g1k_v37.fasta --novcf_stats_report --num_shards=5 --call_variants_extra_args ""use_openvino=true""`. Error:. ```. I0123 08:06:11.771944 139769488508672 make_examples.py:535] Task 1/5: 9704 candidates (9978 examples) [651.40s elapsed]. I0123 08:07:25.050816 140120745805568 make_examples.py:535] Task 3/5: 9400 candidates (9710 examples) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:1693,deployability,fail,failed,1693,"ed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2141,deployability,modul,module,2141,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2437,integrability,sub,subprocess,2437,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2530,integrability,sub,subprocess,2530,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2611,integrability,sub,subprocess,2611,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2691,integrability,buffer,buffer,2691,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2141,modifiability,modul,module,2141,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2201,modifiability,pac,packages,2201,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2301,modifiability,pac,packages,2301,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:446,performance,Error,Error,446,"RNA Seq failed exit status 247; I thought I should be able to call variants from short reads aligned to the human genome (hg19) with hisat2. So I gave it a try. Windows 10 Docker desktop. . `/opt/deepvariant/bin/run_deepvariant --model_type=WGS --output_vcf=CDAR-016_run0124_deepvariant.vcf --reads=CDAR-016_human37_align.bam --ref=./CFM032/human_g1k_v37.fasta --novcf_stats_report --num_shards=5 --call_variants_extra_args ""use_openvino=true""`. Error:. ```. I0123 08:06:11.771944 139769488508672 make_examples.py:535] Task 1/5: 9704 candidates (9978 examples) [651.40s elapsed]. I0123 08:07:25.050816 140120745805568 make_examples.py:535] Task 3/5: 9400 candidates (9710 examples) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:1674,performance,parallel,parallel,1674,"es) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2651,performance,time,time,2651,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2666,performance,parallel,parallel,2666,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:8,reliability,fail,failed,8,"RNA Seq failed exit status 247; I thought I should be able to call variants from short reads aligned to the human genome (hg19) with hisat2. So I gave it a try. Windows 10 Docker desktop. . `/opt/deepvariant/bin/run_deepvariant --model_type=WGS --output_vcf=CDAR-016_run0124_deepvariant.vcf --reads=CDAR-016_human37_align.bam --ref=./CFM032/human_g1k_v37.fasta --novcf_stats_report --num_shards=5 --call_variants_extra_args ""use_openvino=true""`. Error:. ```. I0123 08:06:11.771944 139769488508672 make_examples.py:535] Task 1/5: 9704 candidates (9978 examples) [651.40s elapsed]. I0123 08:07:25.050816 140120745805568 make_examples.py:535] Task 3/5: 9400 candidates (9710 examples) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:1693,reliability,fail,failed,1693,"ed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:446,safety,Error,Error,446,"RNA Seq failed exit status 247; I thought I should be able to call variants from short reads aligned to the human genome (hg19) with hisat2. So I gave it a try. Windows 10 Docker desktop. . `/opt/deepvariant/bin/run_deepvariant --model_type=WGS --output_vcf=CDAR-016_run0124_deepvariant.vcf --reads=CDAR-016_human37_align.bam --ref=./CFM032/human_g1k_v37.fasta --novcf_stats_report --num_shards=5 --call_variants_extra_args ""use_openvino=true""`. Error:. ```. I0123 08:06:11.771944 139769488508672 make_examples.py:535] Task 1/5: 9704 candidates (9978 examples) [651.40s elapsed]. I0123 08:07:25.050816 140120745805568 make_examples.py:535] Task 3/5: 9400 candidates (9710 examples) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2141,safety,modul,module,2141,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2043,testability,Trace,Traceback,2043,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:20,usability,statu,status,20,"RNA Seq failed exit status 247; I thought I should be able to call variants from short reads aligned to the human genome (hg19) with hisat2. So I gave it a try. Windows 10 Docker desktop. . `/opt/deepvariant/bin/run_deepvariant --model_type=WGS --output_vcf=CDAR-016_run0124_deepvariant.vcf --reads=CDAR-016_human37_align.bam --ref=./CFM032/human_g1k_v37.fasta --novcf_stats_report --num_shards=5 --call_variants_extra_args ""use_openvino=true""`. Error:. ```. I0123 08:06:11.771944 139769488508672 make_examples.py:535] Task 1/5: 9704 candidates (9978 examples) [651.40s elapsed]. I0123 08:07:25.050816 140120745805568 make_examples.py:535] Task 3/5: 9400 candidates (9710 examples) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:446,usability,Error,Error,446,"RNA Seq failed exit status 247; I thought I should be able to call variants from short reads aligned to the human genome (hg19) with hisat2. So I gave it a try. Windows 10 Docker desktop. . `/opt/deepvariant/bin/run_deepvariant --model_type=WGS --output_vcf=CDAR-016_run0124_deepvariant.vcf --reads=CDAR-016_human37_align.bam --ref=./CFM032/human_g1k_v37.fasta --novcf_stats_report --num_shards=5 --call_variants_extra_args ""use_openvino=true""`. Error:. ```. I0123 08:06:11.771944 139769488508672 make_examples.py:535] Task 1/5: 9704 candidates (9978 examples) [651.40s elapsed]. I0123 08:07:25.050816 140120745805568 make_examples.py:535] Task 3/5: 9400 candidates (9710 examples) [246.46s elapsed]. I0123 08:09:37.633983 140665948894976 make_examples.py:535] Task 4/5: 6501 candidates (6671 examples) [1447.91s elapsed]. I0123 08:10:30.871732 140590877263616 make_examples.py:535] Task 2/5: 7503 candidates (7798 examples) [1754.74s elapsed]. I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:1941,usability,user,user,1941,". I0123 08:14:47.526611 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2459,usability,command,command,2459,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2642,usability,Command,Command,2642,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/412:2949,usability,statu,status,2949,"11 139645822764800 make_examples.py:535] Task 0/5: 8701 candidates (9015 examples) [4857.13s elapsed]. I0123 08:16:17.660391 140590877263616 make_examples.py:535] Task 2/5: 7600 candidates (7895 examples) [346.79s elapsed]. I0123 08:17:25.425076 140120745805568 make_examples.py:535] Task 3/5: 9501 candidates (9813 examples) [600.37s elapsed]. I0123 08:23:17.762356 140590877263616 make_examples.py:535] Task 2/5: 7700 candidates (8000 examples) [420.10s elapsed]. I0123 08:28:08.231647 140590877263616 make_examples.py:535] Task 2/5: 7800 candidates (8102 examples) [290.47s elapsed]. I0123 08:33:41.777438 139769488508672 make_examples.py:535] Task 1/5: 9800 candidates (10074 examples) [1650.01s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ./CFM032/human_g1k_v37.fasta --reads run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam --examples /tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz --task 1. real 2480m8.473s. user 2463m44.983s. sys 2m30.474s. I0123 08:51:28.346467 139763485337344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 4 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""./CFM032/human_g1k_v37.fasta"" --reads ""run0124_lane9_indexUDI0001-UDI0001=CDAR-016_human37_align.bam"" --examples ""/tmp/tmpfh_b9v77/make_examples.tfrecord@5.gz"" --task {}' returned non-zero exit status 247. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/412
https://github.com/google/deepvariant/issues/413:0,availability,Error,Error,0,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1287,availability,Error,Error,1287,"hing goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4253,availability,Error,Error,4253,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4324,availability,Error,Error,4324,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:143,deployability,resourc,resources,143,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:780,deployability,version,version,780,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:798,deployability,Instal,Installation,798,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2785,deployability,modul,module,2785,"45306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:143,energy efficiency,resourc,resources,143,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:780,integrability,version,version,780,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2067,integrability,Transform,Transforming,2067,"tput.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2067,interoperability,Transform,Transforming,2067,"tput.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2886,interoperability,platform,platform,2886,"26 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:780,modifiability,version,version,780,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2785,modifiability,modul,module,2785,"45306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2854,modifiability,pac,packages,2854,"ngle_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:0,performance,Error,Error,0,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:143,performance,resourc,resources,143,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:260,performance,time,time,260,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1287,performance,Error,Error,1287,"hing goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1315,performance,time,time,1315,"stprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4253,performance,Error,Error,4253,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4324,performance,Error,Error,4324,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4448,reliability,Doe,Does,4448,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:0,safety,Error,Error,0,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:103,safety,test,test,103,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:143,safety,resourc,resources,143,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1051,safety,input,input,1051,"; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1173,safety,input,input,1173,"he bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1287,safety,Error,Error,1287,"hing goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1415,safety,input,input,1415,"vcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1537,safety,input,input,1537,"ge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1727,safety,input,input,1727,"of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2563,safety,input,input,2563,"gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2785,safety,modul,module,2785,"45306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4253,safety,Error,Error,4253,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4324,safety,Error,Error,4324,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4346,safety,input,input,4346,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4469,safety,test,test,4469,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:103,testability,test,test,103,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:143,testability,resourc,resources,143,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1293,testability,trace,trace,1293,"oes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2629,testability,Trace,Traceback,2629,"ort=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4469,testability,test,test,4469,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4520,testability,context,context,4520,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:0,usability,Error,Error,0,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:945,usability,Command,Command,945,"Error on Post processing from 2 different gvcf sources; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1051,usability,input,input,1051,"; **Describe the issue:**. I'm doing a series of test of how can I run DV faster with my resources. I'm trying splitting the bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1173,usability,input,input,1173,"he bam file - run make examples on separate - run Call Variants of both at the same time and call variants. Everything goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1287,usability,Error,Error,1287,"hing goes fine until the postprocess The 2 different gvcf are name as followed:. SPLIT2.gvcf.tfrecord-00000-of-00030.gz. SPLIT.gvcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1415,usability,input,input,1415,"vcf.tfrecord-00000-of-00030.gz. Both in the same directory. I know that ideally would run on separate all the way then merge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1537,usability,input,input,1537,"ge the two gvcf, but I'm,m asking if there is any tweak I can do to overcome this problem... I tought on rename the files from 0:59-of-00060.gz but can someone also tell me the implications of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:1727,usability,input,input,1727,"of that move? . **Setup**. - Linux. - DeepVariant version: 1.0.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS from shallow resequencing data. **Steps to reproduce:**. - Command: "" /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False"" . . - Error trace: . Singularity> time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/100kbPrad_v1_scaffolds.fasta"" --infile ""/input/call_variants_output.tfrecord.gz"" --outfile ""/output/MergedSplited.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" --gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:2563,usability,input,input,2563,"gvcf_outfile ""/output/MergedSplited.output.g.vcf.gz"" --vcf_stats_report=False. 2021-01-26 15:54:17.883294: I deepvariant/postprocess_variants.cc:88] Read from: /input/call_variants_output.tfrecord.gz. 2021-01-26 16:15:59.645306: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 144590159. I0126 17:29:21.938455 140157300115200 postprocess_variants.py:1079] CVO sorting took 95.07083837985992 minutes. I0126 17:29:21.940265 140157300115200 postprocess_variants.py:1081] Transforming call_variants_output to variants. I0126 17:29:22.052276 140157300115200 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF. I0126 17:29:22.509974 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.vcf.gz with NativeVcfWriter. I0126 17:29:22.844680 140157300115200 genomics_writer.py:172] Writing /output/MergedSplited.output.g.vcf.gz with NativeVcfWriter. 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4253,usability,Error,Error,4253,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4324,usability,Error,Error,4324,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4346,usability,input,input,4346,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4414,usability,user,user,4414,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/413:4547,usability,help,help,4547,"] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1122, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 953, in merge_and_write_variants_and_nonvariants. nonvariant = next_or_none(nonvariant_iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 948, in next_or_none. return next(iterable). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 139, in read_shard_sorted_tfrecords. protos = Reader(path, proto, compression_type=compression_type).iterate(). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 60, in Reader. path, proto, compression_type=compression_type). File ""/tmp/Bazel.runfiles_88m2azo2/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 174, in __init__. 'Error trying to open %s for reading' % input_path). OSError: [Errno 5] Error trying to open /input/gvcf.tfrecord-00000-of-00030.gz for reading. real 95m15.549s. user 89m30.039s. sys 5m49.495s. **Does the quick start test work on your system?**. yes. **Any additional context:**. Appreciate any help. Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/413
https://github.com/google/deepvariant/issues/414:193,interoperability,convers,conversion,193,"ENH: add samtools to docker image; Since deepvariant allows sending cram directly, it's no longer strictly necessary to convert bam to cram. . But, I find it's still faster to do the bam->cram conversion for exome data (especially when no regions file is specified). For that, it would be nice to have samtools binary in the official image. I understand if you want to keep the docker image to a minimal size and it's easy to derive from your image but thought it might be generally useful to have samtools in the base DV docker image.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/414
https://github.com/google/deepvariant/issues/414:255,interoperability,specif,specified,255,"ENH: add samtools to docker image; Since deepvariant allows sending cram directly, it's no longer strictly necessary to convert bam to cram. . But, I find it's still faster to do the bam->cram conversion for exome data (especially when no regions file is specified). For that, it would be nice to have samtools binary in the official image. I understand if you want to keep the docker image to a minimal size and it's easy to derive from your image but thought it might be generally useful to have samtools in the base DV docker image.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/414
https://github.com/google/deepvariant/issues/414:343,testability,understand,understand,343,"ENH: add samtools to docker image; Since deepvariant allows sending cram directly, it's no longer strictly necessary to convert bam to cram. . But, I find it's still faster to do the bam->cram conversion for exome data (especially when no regions file is specified). For that, it would be nice to have samtools binary in the official image. I understand if you want to keep the docker image to a minimal size and it's easy to derive from your image but thought it might be generally useful to have samtools in the base DV docker image.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/414
https://github.com/google/deepvariant/issues/414:396,usability,minim,minimal,396,"ENH: add samtools to docker image; Since deepvariant allows sending cram directly, it's no longer strictly necessary to convert bam to cram. . But, I find it's still faster to do the bam->cram conversion for exome data (especially when no regions file is specified). For that, it would be nice to have samtools binary in the official image. I understand if you want to keep the docker image to a minimal size and it's easy to derive from your image but thought it might be generally useful to have samtools in the base DV docker image.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/414
https://github.com/google/deepvariant/issues/415:31,energy efficiency,model,model,31,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:247,energy efficiency,model,model,247,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:319,energy efficiency,model,model,319,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:420,energy efficiency,model,models,420,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:24,modifiability,Pac,PacBio,24,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:132,modifiability,Pac,PacBio,132,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:240,modifiability,Pac,PacBio,240,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:312,modifiability,Pac,PacBio,312,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:31,security,model,model,31,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:247,security,model,model,247,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:319,security,model,model,319,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:420,security,model,models,420,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:503,security,sign,significant,503,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:607,usability,close,closely,607,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/415:734,usability,help,help,734,"Using the human-trained PacBio model for zebrafish data; Dear developers,. we have generated reads from zebrafish (danio rerio) via PacBio HiFi sequencing and are now wondering whether or not we should attempt to re-train the human-trained PacBio model using existent zebrafish data or whether the human-trained PacBio model is precise enough to further process and analyse our data. We are aware that the human-trained models work well in other mammals but, as you know, studies in mosquitoes showed a significant increase in accuracy upon re-training from mosquito data. Of course, mammals are a lot more closely related to zebrafish than to mosquitoes, so we wanted to hear your opinion on the questions. Thanks in advance for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/415
https://github.com/google/deepvariant/issues/416:183,availability,error,error,183,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:207,availability,error,error,207,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:267,availability,error,error,267,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:324,availability,error,error,324,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1305,availability,error,error,1305,"g the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like tha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1935,availability,error,error,1935," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:111,deployability,contain,containers,111,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:135,deployability,version,version,135,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:2158,deployability,fail,fails,2158," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:2188,deployability,instal,installed,2188," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:2205,deployability,contain,container,2205," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:388,energy efficiency,model,model,388,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1481,energy efficiency,model,model,1481," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1487,energy efficiency,model,model,1487," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1633,energy efficiency,model,model,1633," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:135,integrability,version,version,135,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:276,interoperability,mismatch,mismatched,276,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:461,interoperability,standard,standard,461,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:494,interoperability,standard,standard,494,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:135,modifiability,version,version,135,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:381,modifiability,PAC,PACBIO,381,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:183,performance,error,error,183,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:207,performance,error,error,207,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:267,performance,error,error,267,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:324,performance,error,error,324,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1305,performance,error,error,1305,"g the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like tha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1935,performance,error,error,1935," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:2158,reliability,fail,fails,2158," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:183,safety,error,error,183,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:207,safety,error,error,207,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:267,safety,error,error,267,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:324,safety,error,error,324,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:437,safety,input,input,437,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1305,safety,error,error,1305,"g the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like tha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1935,safety,error,error,1935," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1980,safety,valid,valid,1980," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:2000,safety,except,except,2000," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:388,security,model,model,388,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1481,security,model,model,1481," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1487,security,model,model,1487," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1633,security,model,model,1633," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:183,usability,error,error,183,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:207,usability,error,error,207,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:267,usability,error,error,267,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:324,usability,error,error,324,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:354,usability,command,command,354,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:437,usability,input,input,437,"Deeptrio pileup height being incorrectly set and missing openvino; Hi,. This is all done using the singularity containers of the 1.1.0 version, on a linux system. . I encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1161,usability,support,supported,1161," encountered one error and one potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails be",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1190,usability,command,command,1190,"ne potential error when experimenting with DeepTrio. The first potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not instal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1249,usability,command,command,1249,"rst potential error is mismatched pileup heights, giving the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1305,usability,error,error,1305,"g the following error when running the single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like tha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/416:1935,usability,error,error,1935," single command deeptrio under the PACBIO model. ` call_variants.py:355] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio).`. There are references to the pileup height defaulting to 0 and thus taking the value in **dv_constants.py**, but it appears in the **run_deeptrio.py** script [here](https://github.com/google/deepvariant/blob/5bee15713085316ae706c7f61274cd438b0006dc/scripts/run_deeptrio.py#L315), that the pileup is set to 60 and 40 **unless** being run in WES mode, then it is 100 each. I then reran the make_examples with explicit pileupheights for child and parent as 100, and the warning went away. The second issue is using openvino in deeptrio. When checking the **deeptrio_metric.md** doc, I didn't see any reference to openvino, so it may not be fully supported still, but it is a command line option. However, when using the same style of command that I got working in #404, I got the following error. ```. File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_fmlnwqjy/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```. The error is a bit misleading, as that import is valid, but in a try/except block [here](https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L37) which actually fails because openvino is not installed in the container. . In the deepvariant image, there is `/opt/intel/openvino/`, while there is nothing like that in the deeptrio image. Thanks,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/416
https://github.com/google/deepvariant/issues/418:251,usability,help,help,251,Running DeepVariant without the reference genome; **DeepVariant without Reference:**. I am trying to phase a diploid genome. But i don't have a reference genome. How would deepvariant work without the reference genome. (How to get the bam file?). Any help would be great. Thanks,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/418
https://github.com/google/deepvariant/issues/419:248,availability,Operat,Operating,248,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:842,availability,Error,Error,842,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2724,availability,error,errors,2724,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:279,deployability,releas,release,279,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:316,deployability,version,version,316,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:351,deployability,version,version,351,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:369,deployability,Instal,Installation,369,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:900,deployability,fail,failed,900,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1416,deployability,modul,module,1416,"c.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:173,energy efficiency,Core,Core,173,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:297,energy efficiency,Core,Core,297,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:316,integrability,version,version,316,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:351,integrability,version,version,351,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1712,integrability,sub,subprocess,1712,"type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1805,integrability,sub,subprocess,1805,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1886,integrability,sub,subprocess,1886,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1972,integrability,buffer,buffer,1972,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:593,interoperability,bind,bind,593,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:101,modifiability,Pac,PacBio,101,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:316,modifiability,version,version,316,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:351,modifiability,version,version,351,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:505,modifiability,Pac,PacBio,505,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:593,modifiability,bind,bind,593,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:722,modifiability,PAC,PACBIO,722,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1416,modifiability,modul,module,1416,"c.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1476,modifiability,pac,packages,1476,"t:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1576,modifiability,pac,packages,1576,"arity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
