id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/issues/1:102,availability,servic,service,102,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:163,availability,servic,services,163,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:102,deployability,servic,service,102,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:163,deployability,servic,services,163,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:102,integrability,servic,service,102,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:163,integrability,servic,services,163,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:102,modifiability,servic,service,102,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:163,modifiability,servic,services,163,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:126,usability,user,users,126,"Hi,. Issues should only be reported in JIRA and not on github. The GitHub repo is a mirror and only a service for some GitHub users, not for other project related services. Cheers, Fons. On 30 Jun 2013, at 00:37, Benjamin Bannier notifications@github.com wrote:. > Hi,. > . > I am not sure if having both the JIRA and github issue trackers will be a good idea. It might create confusion, make it more work to follow developments, and might historic investigations harder. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:110,integrability,sub,submission,110,New issues are now reported *only* on GitHub. We keep Jira open for existing issues. We will close Jira issue submission to the public in about a year; until then there's a message telling people to go to GitHub instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:128,integrability,pub,public,128,New issues are now reported *only* on GitHub. We keep Jira open for existing issues. We will close Jira issue submission to the public in about a year; until then there's a message telling people to go to GitHub instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:173,integrability,messag,message,173,New issues are now reported *only* on GitHub. We keep Jira open for existing issues. We will close Jira issue submission to the public in about a year; until then there's a message telling people to go to GitHub instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:173,interoperability,messag,message,173,New issues are now reported *only* on GitHub. We keep Jira open for existing issues. We will close Jira issue submission to the public in about a year; until then there's a message telling people to go to GitHub instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:93,usability,close,close,93,New issues are now reported *only* on GitHub. We keep Jira open for existing issues. We will close Jira issue submission to the public in about a year; until then there's a message telling people to go to GitHub instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/issues/1:31,usability,help,help,31,"This is great, will definitely help with open source contributions. Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/1
https://github.com/root-project/root/pull/9:9,safety,review,reviewed,9,Merged / reviewed through my pull req against my repo.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9
https://github.com/root-project/root/pull/9:9,testability,review,reviewed,9,Merged / reviewed through my pull req against my repo.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9
https://github.com/root-project/root/pull/10:43,safety,avoid,avoid,43,"@pcanal Philippe, here's another change to avoid a race condition found by helgrind.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10
https://github.com/root-project/root/pull/16:24,deployability,patch,patches,24,Merged in root-v5-34-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16
https://github.com/root-project/root/pull/16:24,safety,patch,patches,24,Merged in root-v5-34-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16
https://github.com/root-project/root/pull/16:24,security,patch,patches,24,Merged in root-v5-34-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16
https://github.com/root-project/root/pull/18:13,deployability,patch,patch,13,AFAIK Bill's patch has been removed from CMS and Vincenzo's has been merged. Thus closing. Thanks for informing us of your changes through this pull request!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/18
https://github.com/root-project/root/pull/18:13,safety,patch,patch,13,AFAIK Bill's patch has been removed from CMS and Vincenzo's has been merged. Thus closing. Thanks for informing us of your changes through this pull request!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/18
https://github.com/root-project/root/pull/18:13,security,patch,patch,13,AFAIK Bill's patch has been removed from CMS and Vincenzo's has been merged. Thus closing. Thanks for informing us of your changes through this pull request!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/18
https://github.com/root-project/root/pull/20:19,deployability,patch,patches,19,pushed on v5-34-00-patches branch and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/20
https://github.com/root-project/root/pull/20:19,safety,patch,patches,19,pushed on v5-34-00-patches branch and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/20
https://github.com/root-project/root/pull/20:19,security,patch,patches,19,pushed on v5-34-00-patches branch and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/20
https://github.com/root-project/root/pull/25:0,deployability,Integr,Integrated,0,Integrated with some enhancements in master. Please follow https://sft.its.cern.ch/jira/browse/ROOT-7132 for more information.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:0,integrability,Integr,Integrated,0,Integrated with some enhancements in master. Please follow https://sft.its.cern.ch/jira/browse/ROOT-7132 for more information.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:0,interoperability,Integr,Integrated,0,Integrated with some enhancements in master. Please follow https://sft.its.cern.ch/jira/browse/ROOT-7132 for more information.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:0,modifiability,Integr,Integrated,0,Integrated with some enhancements in master. Please follow https://sft.its.cern.ch/jira/browse/ROOT-7132 for more information.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:0,reliability,Integr,Integrated,0,Integrated with some enhancements in master. Please follow https://sft.its.cern.ch/jira/browse/ROOT-7132 for more information.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:0,security,Integr,Integrated,0,Integrated with some enhancements in master. Please follow https://sft.its.cern.ch/jira/browse/ROOT-7132 for more information.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/25:0,testability,Integr,Integrated,0,Integrated with some enhancements in master. Please follow https://sft.its.cern.ch/jira/browse/ROOT-7132 for more information.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/25
https://github.com/root-project/root/pull/26:16,deployability,patch,patch,16,"Thanks for your patch, Chris - and apologies for not getting this in while it's relevant :-( I'd prefer to not touch v5.34 anymore. Objections against closing this without merge?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/26
https://github.com/root-project/root/pull/26:16,safety,patch,patch,16,"Thanks for your patch, Chris - and apologies for not getting this in while it's relevant :-( I'd prefer to not touch v5.34 anymore. Objections against closing this without merge?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/26
https://github.com/root-project/root/pull/26:16,security,patch,patch,16,"Thanks for your patch, Chris - and apologies for not getting this in while it's relevant :-( I'd prefer to not touch v5.34 anymore. Objections against closing this without merge?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/26
https://github.com/root-project/root/pull/26:97,usability,prefer,prefer,97,"Thanks for your patch, Chris - and apologies for not getting this in while it's relevant :-( I'd prefer to not touch v5.34 anymore. Objections against closing this without merge?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/26
https://github.com/root-project/root/pull/34:170,availability,error,error,170,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:453,availability,operat,operator,453,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:676,availability,operat,operator,676,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:730,availability,error,error,730,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:792,availability,Error,Error,792,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:334,deployability,Toolchain,Toolchains,334,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:557,deployability,Toolchain,Toolchains,557,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:57,energy efficiency,core,core,57,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:501,energy efficiency,load,load,501,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:715,energy efficiency,load,load,715,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:187,interoperability,convers,conversion,187,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:416,interoperability,convers,conversion,416,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:639,interoperability,convers,conversion,639,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:170,performance,error,error,170,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:315,performance,Content,Contents,315,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:501,performance,load,load,501,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:538,performance,Content,Contents,538,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:715,performance,load,load,715,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:730,performance,error,error,730,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:792,performance,Error,Error,792,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:170,safety,error,error,170,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:730,safety,error,error,730,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:792,safety,Error,Error,792,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:11,usability,User,Users,11,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:84,usability,User,Users,84,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:170,usability,error,error,170,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:334,usability,Tool,Toolchains,334,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:557,usability,Tool,Toolchains,557,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:730,usability,error,error,730,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/34:792,usability,Error,Error,792,Compiling /Users/pcanal/root_working/code/v5-34-00-devel/core/base/src/TColor.cxx. /Users/pcanal/root_working/code/v5-34-00-devel/cint/cint/src/FastAllocString.cxx:80:3: error: ambiguous conversion of delete expression of type 'std::__1::atomic<char *>' to a pointer. delete [] _it;. ^ ~~~. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:582:5: note: conversion to pointer type 'char *'. operator _Tp() const volatile _NOEXCEPT {return load();}. ^. /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/atomic:584:5: note: conversion to pointer type 'char *'. operator _Tp() const _NOEXCEPT {return load();}. ^. 1 error generated. make: *_\* [cint/cint/src/FastAllocString.o] Error 1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/34
https://github.com/root-project/root/pull/38:16,deployability,patch,patch,16,merged in v6.02 patch branch and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/38
https://github.com/root-project/root/pull/38:16,safety,patch,patch,16,merged in v6.02 patch branch and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/38
https://github.com/root-project/root/pull/38:16,security,patch,patch,16,merged in v6.02 patch branch and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/38
https://github.com/root-project/root/pull/39:2,testability,understand,understand,2,"I understand that you don't really ""need"" them, but they would make the user's code easier to read (and write).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:72,usability,user,user,72,"I understand that you don't really ""need"" them, but they would make the user's code easier to read (and write).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:85,deployability,version,version,85,We will consider that. May be meanwhile you can provide ( and test) a more optimised version of RemoveAllPoints ? What about just doing fPoints = 0 and leaving the space allocated ? if you what to really remove the point it is faster to remove the TGraph ..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:75,energy efficiency,optim,optimised,75,We will consider that. May be meanwhile you can provide ( and test) a more optimised version of RemoveAllPoints ? What about just doing fPoints = 0 and leaving the space allocated ? if you what to really remove the point it is faster to remove the TGraph ..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:170,energy efficiency,alloc,allocated,170,We will consider that. May be meanwhile you can provide ( and test) a more optimised version of RemoveAllPoints ? What about just doing fPoints = 0 and leaving the space allocated ? if you what to really remove the point it is faster to remove the TGraph ..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:85,integrability,version,version,85,We will consider that. May be meanwhile you can provide ( and test) a more optimised version of RemoveAllPoints ? What about just doing fPoints = 0 and leaving the space allocated ? if you what to really remove the point it is faster to remove the TGraph ..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:85,modifiability,version,version,85,We will consider that. May be meanwhile you can provide ( and test) a more optimised version of RemoveAllPoints ? What about just doing fPoints = 0 and leaving the space allocated ? if you what to really remove the point it is faster to remove the TGraph ..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:62,safety,test,test,62,We will consider that. May be meanwhile you can provide ( and test) a more optimised version of RemoveAllPoints ? What about just doing fPoints = 0 and leaving the space allocated ? if you what to really remove the point it is faster to remove the TGraph ..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:62,testability,test,test,62,We will consider that. May be meanwhile you can provide ( and test) a more optimised version of RemoveAllPoints ? What about just doing fPoints = 0 and leaving the space allocated ? if you what to really remove the point it is faster to remove the TGraph ..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:181,deployability,version,version,181,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:195,deployability,patch,patch,195,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:469,deployability,Updat,Update,469,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:129,energy efficiency,alloc,allocated,129,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:322,energy efficiency,Draw,Draw,322,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:11,integrability,discover,discovered,11,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:64,integrability,messag,message,64,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:181,integrability,version,version,181,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:11,interoperability,discover,discovered,11,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:64,interoperability,messag,message,64,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:181,modifiability,version,version,181,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:195,safety,patch,patch,195,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:222,safety,test,test,222,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:469,safety,Updat,Update,469,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:195,security,patch,patch,195,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:469,security,Updat,Update,469,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:222,testability,test,test,222,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:11,usability,discov,discovered,11,"Oh, I just discovered that Github mailed me just a part of your message, so I didn't got your suggestion about leaving the space allocated. I therefore deleted fX and fY in the new version of my patch and created a little test script:. ```. void TGraphTest(). {. TCanvas *c = new TCanvas();. TGraph *g = new TGraph();. g->Draw();. for (int i = 0; i < 100; i++) {. g->RemoveAllPoints();. for (int k = 0; k < 100; k++) {. g->AppendPoint(k/10., sin(k/10. + i/4.));. }. c->Update();. gSystem->Sleep(20);. }. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:79,energy efficiency,alloc,allocated,79,"Do you really want to destroy the arrays ? It is not better to leave the space allocated in memory to be filled back by other points, like clear() on a std::vector ? . Otherwise, I think this function is not needed. There is already a TGraph::Set(0). Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:92,performance,memor,memory,92,"Do you really want to destroy the arrays ? It is not better to leave the space allocated in memory to be filled back by other points, like clear() on a std::vector ? . Otherwise, I think this function is not needed. There is already a TGraph::Set(0). Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:92,usability,memor,memory,92,"Do you really want to destroy the arrays ? It is not better to leave the space allocated in memory to be filled back by other points, like clear() on a std::vector ? . Otherwise, I think this function is not needed. There is already a TGraph::Set(0). Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/39:139,usability,clear,clear,139,"Do you really want to destroy the arrays ? It is not better to leave the space allocated in memory to be filled back by other points, like clear() on a std::vector ? . Otherwise, I think this function is not needed. There is already a TGraph::Set(0). Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/39
https://github.com/root-project/root/pull/40:4,deployability,updat,updated,4,See updated doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT for building without installing libcmaes (i.e. without running 'make install') nor installing pkg-config.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:87,deployability,build,building,87,See updated doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT for building without installing libcmaes (i.e. without running 'make install') nor installing pkg-config.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:104,deployability,instal,installing,104,See updated doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT for building without installing libcmaes (i.e. without running 'make install') nor installing pkg-config.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:152,deployability,instal,install,152,See updated doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT for building without installing libcmaes (i.e. without running 'make install') nor installing pkg-config.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:166,deployability,instal,installing,166,See updated doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT for building without installing libcmaes (i.e. without running 'make install') nor installing pkg-config.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:4,safety,updat,updated,4,See updated doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT for building without installing libcmaes (i.e. without running 'make install') nor installing pkg-config.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:4,security,updat,updated,4,See updated doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT for building without installing libcmaes (i.e. without running 'make install') nor installing pkg-config.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:151,availability,Error,Error,151,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:520,availability,error,errors,520,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:34,deployability,patch,patch,34,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:67,deployability,instal,installed,67,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:496,integrability,Configur,Configuring,496,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:172,modifiability,variab,variables,172,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:496,modifiability,Configur,Configuring,496,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:151,performance,Error,Error,151,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:520,performance,error,errors,520,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:34,safety,patch,patch,34,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:151,safety,Error,Error,151,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:284,safety,test,tested,284,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:520,safety,error,errors,520,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:34,security,patch,patch,34,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:496,security,Configur,Configuring,496,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:284,testability,test,tested,284,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:151,usability,Error,Error,151,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:520,usability,error,errors,520,"I have tried applying your latest patch. But, when libcmaes is not installed by doing . cmake ../root -Dall=on -Dtesting=on. I get at the end: . CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files:. LIBCMAES_INCLUDE_DIR (ADVANCED). used as include directory in directory /home/moneta/root/math/cmaes. used as include directory in directory /home/moneta/root/math/cmaes. -- Configuring incomplete, errors occurred!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:189,availability,state,stated,189,"You need to do something like:. ```. cmake ../ -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. As stated above, the doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT is up to date with this change. Let me know if this is not the problem. EDIT: I'm not sure what the ""-Dall"" you are using means for cmake and if it can be filled up automatically for the libcmaes. EDIT2: found where 'all' is defined, will be part of next patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:443,deployability,automat,automatically,443,"You need to do something like:. ```. cmake ../ -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. As stated above, the doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT is up to date with this change. Let me know if this is not the problem. EDIT: I'm not sure what the ""-Dall"" you are using means for cmake and if it can be filled up automatically for the libcmaes. EDIT2: found where 'all' is defined, will be part of next patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:533,deployability,patch,patch,533,"You need to do something like:. ```. cmake ../ -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. As stated above, the doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT is up to date with this change. Let me know if this is not the problem. EDIT: I'm not sure what the ""-Dall"" you are using means for cmake and if it can be filled up automatically for the libcmaes. EDIT2: found where 'all' is defined, will be part of next patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:189,integrability,state,stated,189,"You need to do something like:. ```. cmake ../ -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. As stated above, the doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT is up to date with this change. Let me know if this is not the problem. EDIT: I'm not sure what the ""-Dall"" you are using means for cmake and if it can be filled up automatically for the libcmaes. EDIT2: found where 'all' is defined, will be part of next patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:533,safety,patch,patch,533,"You need to do something like:. ```. cmake ../ -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. As stated above, the doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT is up to date with this change. Let me know if this is not the problem. EDIT: I'm not sure what the ""-Dall"" you are using means for cmake and if it can be filled up automatically for the libcmaes. EDIT2: found where 'all' is defined, will be part of next patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:533,security,patch,patch,533,"You need to do something like:. ```. cmake ../ -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. As stated above, the doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT is up to date with this change. Let me know if this is not the problem. EDIT: I'm not sure what the ""-Dall"" you are using means for cmake and if it can be filled up automatically for the libcmaes. EDIT2: found where 'all' is defined, will be part of next patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:443,testability,automat,automatically,443,"You need to do something like:. ```. cmake ../ -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. As stated above, the doc https://github.com/beniz/libcmaes/wiki/using-CMA-ES-in-CERN's-ROOT is up to date with this change. Let me know if this is not the problem. EDIT: I'm not sure what the ""-Dall"" you are using means for cmake and if it can be filled up automatically for the libcmaes. EDIT2: found where 'all' is defined, will be part of next patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:31,deployability,build,build,31,"Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:105,deployability,build,build,105,"Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:48,usability,support,support,48,"Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:33,deployability,build,build,33,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:107,deployability,build,build,107,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:157,deployability,patch,patch,157,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:203,deployability,build,builds,203,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:193,integrability,coupl,couple,193,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:193,modifiability,coupl,couple,193,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:157,safety,patch,patch,157,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:157,security,patch,patch,157,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:193,testability,coupl,couple,193,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:50,usability,support,support,50,"> Yes this is fine, if I want to build the camaes support. But make should work also when I do not want to build with libcmaes. Yes understood, part of next patch, it will ready once I check a couple of builds from scratch...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:157,deployability,build,builds,157,"To active CMA-ES it is now required to do something similar to:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. EDIT: will post the results of the builds when they're finished, along with required patches, if any.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:207,deployability,patch,patches,207,"To active CMA-ES it is now required to do something similar to:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. EDIT: will post the results of the builds when they're finished, along with required patches, if any.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:207,safety,patch,patches,207,"To active CMA-ES it is now required to do something similar to:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. EDIT: will post the results of the builds when they're finished, along with required patches, if any.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:207,security,patch,patches,207,"To active CMA-ES it is now required to do something similar to:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. EDIT: will post the results of the builds when they're finished, along with required patches, if any.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:0,deployability,Build,Builds,0,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:74,deployability,patch,patch,74,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:210,deployability,instal,installed,210,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:344,deployability,instal,installed,344,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:599,deployability,build,building,599,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:57,safety,test,tested,57,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:74,safety,patch,patch,74,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:74,security,patch,patch,74,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:57,testability,test,tested,57,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:31,usability,support,support,31,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:173,usability,support,support,173,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:305,usability,support,support,305,"Builds with and without CMA-ES support both successfully tested with last patch:. - to compile without:. ```. cmake ../ -Dall=on -Dtesting=on. ```. - to compile with CMA-ES support with libcmaes and pkg-config installed:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. - to compiled with CMA-ES support with libcmaes compiled but not installed and without pkg-config:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on -DLIBCMAES_INCLUDE_DIR=""/path/to/libcmaes/src;/path/to/libcmaes/;/path/to/eigen3"" -DLIBCMAES_LIBRARIES=""/path/to/libcmaes/src/.libs"". ```. I expect further issues after building the whole thing, such as the need for pointing LD_LIBRARY_PATH to the libcmaes.so file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:53,availability,down,download,53,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:36,deployability,patch,patch,36,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:88,deployability,instal,installs,88,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:122,deployability,build,build,122,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:302,deployability,build,build,302,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:344,deployability,patch,patch,344,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:234,reliability,doe,does,234,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:36,safety,patch,patch,36,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:330,safety,detect,detected,330,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:344,safety,patch,patch,344,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:359,safety,test,tested,359,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:36,security,patch,patch,36,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:330,security,detect,detected,330,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:344,security,patch,patch,344,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:359,testability,test,tested,359,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:390,usability,support,support,390,"@lmoneta as you suggested, the last patch lets cmake download both eigen3 and libcmaes, installs them locally within ROOT build repo and uses them to compile and run ROOT:. ```. cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. ```. now does not require pkg-config, though uses pkg-config and an existing build of libcmaes if one is detected. The patch has been tested with and without CMA-ES support. Let me know how it goes and what is the next issue (if any :) ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:18,deployability,patch,patch,18,Thank you for the patch. This looks perfect. I will try to test it today.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:18,safety,patch,patch,18,Thank you for the patch. This looks perfect. I will try to test it today.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:59,safety,test,test,59,Thank you for the patch. This looks perfect. I will try to test it today.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:18,security,patch,patch,18,Thank you for the patch. This looks perfect. I will try to test it today.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:59,testability,test,test,59,Thank you for the patch. This looks perfect. I will try to test it today.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:142,availability,down,downloaded,142,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:266,availability,error,error,266,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:478,availability,error,error,478,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:4,deployability,patch,patch,4,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:434,deployability,build,build,434,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:266,performance,error,error,266,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:478,performance,error,error,478,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:4,safety,patch,patch,4,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:64,safety,test,tested,64,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:266,safety,error,error,266,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:478,safety,error,error,478,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:4,security,patch,patch,4,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:64,testability,test,tested,64,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:266,usability,error,error,266,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:478,usability,error,error,478,"The patch now works in the default case (no libcmaes). . I have tested as suggested to do . cmake ../ -Dall=on -Dtesting=on -Dlibcmaes=on. It downloaded the eigen and libcaems, but apparently libcaems is not built locally. Even the include files are not copied. The error I get is . [ 41%] Generating G__cmaes.cxx, ../../lib/libcmaes_rdict.pcm, ../../lib/libcmaes.rootmap. In file included from input_line_12:12:. /home/moneta/master-build/include/CMAESMinimizer.h:33:10: fatal error: 'cmaes.h' file not found. #include ""cmaes.h"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:29,availability,error,errors,29,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:62,deployability,patch,patch,62,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:118,deployability,configurat,configuration,118,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:134,deployability,build,building,134,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:357,deployability,build,builds,357,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:386,deployability,build,building,386,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:297,energy efficiency,core,cores,297,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:118,integrability,configur,configuration,118,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:118,modifiability,configur,configuration,118,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:29,performance,error,errors,29,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:29,safety,error,errors,29,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:62,safety,patch,patch,62,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:62,security,patch,patch,62,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:118,security,configur,configuration,118,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:109,testability,trace,trace,109,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:29,usability,error,errors,29,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:313,usability,confirm,confirm,313,"@lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? To generate it I use:. ```. make VERBOSE=1. ```. thanks! EDIT: note that there may be an issue if you use . ```. make -jx. ```. with x number of cores. I cannot confirm it, but I've witnessed that on some builds make might get to the building of the cmaes part in ROOT before the libcmaes has compiled.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:191,availability,error,errors,191,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:18,deployability,log,log,18,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:224,deployability,patch,patch,224,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:280,deployability,configurat,configuration,280,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:296,deployability,build,building,296,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:280,integrability,configur,configuration,280,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:280,modifiability,configur,configuration,280,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:191,performance,error,errors,191,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:18,safety,log,log,18,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:191,safety,error,errors,191,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:224,safety,patch,patch,224,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:18,security,log,log,18,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:224,security,patch,patch,224,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:280,security,configur,configuration,280,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:18,testability,log,log,18,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:271,testability,trace,trace,271,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:191,usability,error,errors,191,"Hi, . Here is the log of make VERBOSE=1. Lorenzo. > On 24 Nov 2014, at 18:48, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I had many of those errors in my effort to write the patch. Could you either send me or post a full trace of configuration + building please ? > To generate it I use:. > . > make VERBOSE=1. > thanks! > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64233376.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:38,deployability,log,log,38,@lmoneta I cannot see the link to the log ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:38,safety,log,log,38,@lmoneta I cannot see the link to the log ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:38,security,log,log,38,@lmoneta I cannot see the link to the log ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:38,testability,log,log,38,@lmoneta I cannot see the link to the log ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:187,deployability,log,log,187,"Here should be, in the mail you get. > On 24 Nov 2014, at 18:55, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I cannot see the link to the log ? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64234473.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:187,safety,log,log,187,"Here should be, in the mail you get. > On 24 Nov 2014, at 18:55, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I cannot see the link to the log ? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64234473.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:187,security,log,log,187,"Here should be, in the mail you get. > On 24 Nov 2014, at 18:55, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I cannot see the link to the log ? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64234473.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:187,testability,log,log,187,"Here should be, in the mail you get. > On 24 Nov 2014, at 18:55, Emmanuel Benazera notifications@github.com wrote:. > . > @lmoneta https://github.com/lmoneta I cannot see the link to the log ? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/40#issuecomment-64234473.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:200,deployability,stack,stackoverflow,200,"@lmoneta I see no attachment to the mail, seems like a missing github feature ? Can you send it to me to my professional email address please. Sorry for the inconvenience... EDIT: here you go, http://stackoverflow.com/questions/10963205/how-to-attach-file-to-a-github-issue it seems it needs to be uploaded elsewhere and the link passed in the comment :(. Pastebin maybe ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:263,deployability,integr,integration,263,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:184,energy efficiency,current,current,184,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:236,energy efficiency,current,current,236,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:263,integrability,integr,integration,263,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:263,interoperability,integr,integration,263,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:263,modifiability,integr,integration,263,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:263,reliability,integr,integration,263,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:263,security,integr,integration,263,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:263,testability,integr,integration,263,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:47,usability,support,support,47,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:192,usability,statu,status,192,"Hi, I've added the README.md file for libcmaes support in root/math/cmaes as requested. Though I'm not certain this is the correct place for the readme. Please let me know what is the current status on this PR. I am able to rebase with current head as needed for integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:29,deployability,version,version,29,"There's a new libcmaes 0.9.4 version that has been successfully tested against this PR to Root. Most importantly, it implements a workaround for a bug in clang, thus allowing libcmaes to be successfully built with clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:29,integrability,version,version,29,"There's a new libcmaes 0.9.4 version that has been successfully tested against this PR to Root. Most importantly, it implements a workaround for a bug in clang, thus allowing libcmaes to be successfully built with clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:29,modifiability,version,version,29,"There's a new libcmaes 0.9.4 version that has been successfully tested against this PR to Root. Most importantly, it implements a workaround for a bug in clang, thus allowing libcmaes to be successfully built with clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:64,safety,test,tested,64,"There's a new libcmaes 0.9.4 version that has been successfully tested against this PR to Root. Most importantly, it implements a workaround for a bug in clang, thus allowing libcmaes to be successfully built with clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:64,testability,test,tested,64,"There's a new libcmaes 0.9.4 version that has been successfully tested against this PR to Root. Most importantly, it implements a workaround for a bug in clang, thus allowing libcmaes to be successfully built with clang.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:22,deployability,updat,updated,22,"FYI, this PR has been updated to match ROOT's current master branch in case you are still interested in merging the new capabilities. Also, a new version of the libcmaes is coming up with fixes and improvements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:146,deployability,version,version,146,"FYI, this PR has been updated to match ROOT's current master branch in case you are still interested in merging the new capabilities. Also, a new version of the libcmaes is coming up with fixes and improvements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:46,energy efficiency,current,current,46,"FYI, this PR has been updated to match ROOT's current master branch in case you are still interested in merging the new capabilities. Also, a new version of the libcmaes is coming up with fixes and improvements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:146,integrability,version,version,146,"FYI, this PR has been updated to match ROOT's current master branch in case you are still interested in merging the new capabilities. Also, a new version of the libcmaes is coming up with fixes and improvements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:146,modifiability,version,version,146,"FYI, this PR has been updated to match ROOT's current master branch in case you are still interested in merging the new capabilities. Also, a new version of the libcmaes is coming up with fixes and improvements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:22,safety,updat,updated,22,"FYI, this PR has been updated to match ROOT's current master branch in case you are still interested in merging the new capabilities. Also, a new version of the libcmaes is coming up with fixes and improvements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:22,security,updat,updated,22,"FYI, this PR has been updated to match ROOT's current master branch in case you are still interested in merging the new capabilities. Also, a new version of the libcmaes is coming up with fixes and improvements.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:17,deployability,updat,updated,17,This PR has been updated for the last release of libcmaes (v0.9.5) and rebased to the tip of the ROOT master branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:38,deployability,releas,release,38,This PR has been updated for the last release of libcmaes (v0.9.5) and rebased to the tip of the ROOT master branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:17,safety,updat,updated,17,This PR has been updated for the last release of libcmaes (v0.9.5) and rebased to the tip of the ROOT master branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:17,security,updat,updated,17,This PR has been updated for the last release of libcmaes (v0.9.5) and rebased to the tip of the ROOT master branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:86,usability,tip,tip,86,This PR has been updated for the last release of libcmaes (v0.9.5) and rebased to the tip of the ROOT master branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:47,deployability,build,build,47,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:53,deployability,infrastructur,infrastructure,53,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:98,deployability,integr,integration,98,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:98,integrability,integr,integration,98,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:98,interoperability,integr,integration,98,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:98,modifiability,integr,integration,98,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:98,reliability,integr,integration,98,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:98,security,integr,integration,98,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:98,testability,integr,integration,98,"@beniz, could you rebase again. We have better build infrastructure now and we could speed up the integration process.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:44,performance,time,time,44,"@vgvassilev Hi, I will but it may take some time since this PR is two years old. I may require your help if I hit merging difficulties. cc @nikohansen @kegl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:100,usability,help,help,100,"@vgvassilev Hi, I will but it may take some time since this PR is two years old. I may require your help if I hit merging difficulties. cc @nikohansen @kegl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:49,integrability,sub,sub,49,Sure! I'd really like to split this PR in atomic sub PRs. This would make me and the other reviewers much more comfortable.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:91,safety,review,reviewers,91,Sure! I'd really like to split this PR in atomic sub PRs. This would make me and the other reviewers much more comfortable.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:91,testability,review,reviewers,91,Sure! I'd really like to split this PR in atomic sub PRs. This would make me and the other reviewers much more comfortable.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:30,deployability,build,building,30,"The PR basically includes:. - building changes for including CMA-ES. - the CMA-ES optimizer via libcmaes. - test samples. Not sure how to split it. I'll provide a rebase, and you guys may be able to move forward from there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:82,energy efficiency,optim,optimizer,82,"The PR basically includes:. - building changes for including CMA-ES. - the CMA-ES optimizer via libcmaes. - test samples. Not sure how to split it. I'll provide a rebase, and you guys may be able to move forward from there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:82,performance,optimiz,optimizer,82,"The PR basically includes:. - building changes for including CMA-ES. - the CMA-ES optimizer via libcmaes. - test samples. Not sure how to split it. I'll provide a rebase, and you guys may be able to move forward from there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:108,safety,test,test,108,"The PR basically includes:. - building changes for including CMA-ES. - the CMA-ES optimizer via libcmaes. - test samples. Not sure how to split it. I'll provide a rebase, and you guys may be able to move forward from there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:108,testability,test,test,108,"The PR basically includes:. - building changes for including CMA-ES. - the CMA-ES optimizer via libcmaes. - test samples. Not sure how to split it. I'll provide a rebase, and you guys may be able to move forward from there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:369,deployability,build,build,369,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:205,integrability,configur,configure,205,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:425,interoperability,platform,platforms,425,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:205,modifiability,configur,configure,205,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:262,modifiability,pac,packages,262,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:400,safety,test,test,400,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:205,security,configur,configure,205,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:400,testability,test,test,400,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:193,usability,support,support,193,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:246,usability,support,support,246,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:310,usability,support,support,310,"I don't think this PR should be split. It is fine as now. It needs some cleanup, there are some changes as in TPluginManger.cxx, TF1.cxx etc.. that are not needed. . The only think is that the support for configure/make can be dropped (we do not support for new packages added in ROOT) and just keep the CMake support. . If you give me again the instructions on how to build the cma-es library I can test this PR. . On which platforms can the CMA-ES library be built ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:137,energy efficiency,current,current,137,"@lmoneta @vgvassilev Hi, I am closing this PR and I will provide another fresh one instead with all relevant commits added to the tip of current master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:130,usability,tip,tip,130,"@lmoneta @vgvassilev Hi, I am closing this PR and I will provide another fresh one instead with all relevant commits added to the tip of current master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:70,deployability,updat,updates,70,"Great! I am very interested in do a review of this code after the new updates if @lmoneta @vgvassilev are agreed, CMA-ES appear to be a great minimizer. Best,. Omar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:36,safety,review,review,36,"Great! I am very interested in do a review of this code after the new updates if @lmoneta @vgvassilev are agreed, CMA-ES appear to be a great minimizer. Best,. Omar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:70,safety,updat,updates,70,"Great! I am very interested in do a review of this code after the new updates if @lmoneta @vgvassilev are agreed, CMA-ES appear to be a great minimizer. Best,. Omar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:70,security,updat,updates,70,"Great! I am very interested in do a review of this code after the new updates if @lmoneta @vgvassilev are agreed, CMA-ES appear to be a great minimizer. Best,. Omar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:36,testability,review,review,36,"Great! I am very interested in do a review of this code after the new updates if @lmoneta @vgvassilev are agreed, CMA-ES appear to be a great minimizer. Best,. Omar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:142,usability,minim,minimizer,142,"Great! I am very interested in do a review of this code after the new updates if @lmoneta @vgvassilev are agreed, CMA-ES appear to be a great minimizer. Best,. Omar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/40:70,usability,help,help,70,@lmoneta @vgvassilev @omazapa Please see PR #507 as a follow up. Your help is needed on some minor issues.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/40
https://github.com/root-project/root/pull/51:29,deployability,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/51
https://github.com/root-project/root/pull/51:29,safety,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/51
https://github.com/root-project/root/pull/51:29,security,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/51
https://github.com/root-project/root/pull/53:39,safety,test,test,39,"@ashlaban, could we rebase this PR and test it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/53
https://github.com/root-project/root/pull/53:39,testability,test,test,39,"@ashlaban, could we rebase this PR and test it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/53
https://github.com/root-project/root/pull/53:39,deployability,stack,stack,39,"Not urgent, but we should clean up the stack of PRs.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/53
https://github.com/root-project/root/pull/53:98,deployability,contain,contains,98,This PR is not valid anymore. . There is now a new library since more than one year TMVAGui which contains the original code which was represented as macro in ROOT 5. . If you see any issues in using the TMVA GUI in ROOT 6 please let us know. Best Regards. Lorenzo,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/53
https://github.com/root-project/root/pull/53:15,safety,valid,valid,15,This PR is not valid anymore. . There is now a new library since more than one year TMVAGui which contains the original code which was represented as macro in ROOT 5. . If you see any issues in using the TMVA GUI in ROOT 6 please let us know. Best Regards. Lorenzo,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/53
https://github.com/root-project/root/pull/55:29,deployability,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/55
https://github.com/root-project/root/pull/55:29,safety,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/55
https://github.com/root-project/root/pull/55:29,security,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/55
https://github.com/root-project/root/pull/56:29,deployability,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/56
https://github.com/root-project/root/pull/56:29,safety,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/56
https://github.com/root-project/root/pull/56:29,security,patch,patches,29,merged in trunk and v6-02-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/56
https://github.com/root-project/root/pull/57:30,deployability,patch,patches,30,"Tweaked and added to v5-34-00-patches, v6-02-00-patches and trunk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/57:48,deployability,patch,patches,48,"Tweaked and added to v5-34-00-patches, v6-02-00-patches and trunk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/57:30,safety,patch,patches,30,"Tweaked and added to v5-34-00-patches, v6-02-00-patches and trunk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/57:48,safety,patch,patches,48,"Tweaked and added to v5-34-00-patches, v6-02-00-patches and trunk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/57:30,security,patch,patches,30,"Tweaked and added to v5-34-00-patches, v6-02-00-patches and trunk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/57:48,security,patch,patches,48,"Tweaked and added to v5-34-00-patches, v6-02-00-patches and trunk.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/57
https://github.com/root-project/root/pull/58:21,deployability,patch,patches,21,Uploaded to v6-02-00-patches and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/58
https://github.com/root-project/root/pull/58:21,safety,patch,patches,21,Uploaded to v6-02-00-patches and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/58
https://github.com/root-project/root/pull/58:21,security,patch,patches,21,Uploaded to v6-02-00-patches and master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/58
https://github.com/root-project/root/pull/59:33,energy efficiency,measur,measurements,33,Note: I plan on doing additional measurements with a CMSSW-produced file. Doing the PR now so @pcanal can start to provide advice / feedback.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:8,testability,plan,plan,8,Note: I plan on doing additional measurements with a CMSSW-produced file. Doing the PR now so @pcanal can start to provide advice / feedback.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/59:132,usability,feedback,feedback,132,Note: I plan on doing additional measurements with a CMSSW-produced file. Doing the PR now so @pcanal can start to provide advice / feedback.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/59
https://github.com/root-project/root/pull/60:0,deployability,Integr,Integrated,0,Integrated. Thanks Michael!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/60
https://github.com/root-project/root/pull/60:0,integrability,Integr,Integrated,0,Integrated. Thanks Michael!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/60
https://github.com/root-project/root/pull/60:0,interoperability,Integr,Integrated,0,Integrated. Thanks Michael!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/60
https://github.com/root-project/root/pull/60:0,modifiability,Integr,Integrated,0,Integrated. Thanks Michael!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/60
https://github.com/root-project/root/pull/60:0,reliability,Integr,Integrated,0,Integrated. Thanks Michael!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/60
https://github.com/root-project/root/pull/60:0,security,Integr,Integrated,0,Integrated. Thanks Michael!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/60
https://github.com/root-project/root/pull/60:0,testability,Integr,Integrated,0,Integrated. Thanks Michael!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/60
https://github.com/root-project/root/pull/61:79,availability,Error,Error,79,"When trying to run the test I get. Processing create_makeproject_examples.C... Error in TStreamerInfo::Build: The class ""SillyStlEvent"" is interpreted and for its the data member ""foo"", we do not have a dictionary for the collection ""bitset<16>"", we will not be able to read or write this data member. (int) 0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:103,deployability,Build,Build,103,"When trying to run the test I get. Processing create_makeproject_examples.C... Error in TStreamerInfo::Build: The class ""SillyStlEvent"" is interpreted and for its the data member ""foo"", we do not have a dictionary for the collection ""bitset<16>"", we will not be able to read or write this data member. (int) 0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:79,performance,Error,Error,79,"When trying to run the test I get. Processing create_makeproject_examples.C... Error in TStreamerInfo::Build: The class ""SillyStlEvent"" is interpreted and for its the data member ""foo"", we do not have a dictionary for the collection ""bitset<16>"", we will not be able to read or write this data member. (int) 0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:23,safety,test,test,23,"When trying to run the test I get. Processing create_makeproject_examples.C... Error in TStreamerInfo::Build: The class ""SillyStlEvent"" is interpreted and for its the data member ""foo"", we do not have a dictionary for the collection ""bitset<16>"", we will not be able to read or write this data member. (int) 0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:79,safety,Error,Error,79,"When trying to run the test I get. Processing create_makeproject_examples.C... Error in TStreamerInfo::Build: The class ""SillyStlEvent"" is interpreted and for its the data member ""foo"", we do not have a dictionary for the collection ""bitset<16>"", we will not be able to read or write this data member. (int) 0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:23,testability,test,test,23,"When trying to run the test I get. Processing create_makeproject_examples.C... Error in TStreamerInfo::Build: The class ""SillyStlEvent"" is interpreted and for its the data member ""foo"", we do not have a dictionary for the collection ""bitset<16>"", we will not be able to read or write this data member. (int) 0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:79,usability,Error,Error,79,"When trying to run the test I get. Processing create_makeproject_examples.C... Error in TStreamerInfo::Build: The class ""SillyStlEvent"" is interpreted and for its the data member ""foo"", we do not have a dictionary for the collection ""bitset<16>"", we will not be able to read or write this data member. (int) 0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:35,safety,test,test,35,"Brian, could you rebase/retry this test?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:35,testability,test,test,35,"Brian, could you rebase/retry this test?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:60,deployability,patch,patched,60,"@pcanal - @zzxuanyuan ran the posted roottest branch with a patched version of ROOT that includes this PR. I think we can close this out, no?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:68,deployability,version,version,68,"@pcanal - @zzxuanyuan ran the posted roottest branch with a patched version of ROOT that includes this PR. I think we can close this out, no?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:68,integrability,version,version,68,"@pcanal - @zzxuanyuan ran the posted roottest branch with a patched version of ROOT that includes this PR. I think we can close this out, no?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:68,modifiability,version,version,68,"@pcanal - @zzxuanyuan ran the posted roottest branch with a patched version of ROOT that includes this PR. I think we can close this out, no?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:60,safety,patch,patched,60,"@pcanal - @zzxuanyuan ran the posted roottest branch with a patched version of ROOT that includes this PR. I think we can close this out, no?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:60,security,patch,patched,60,"@pcanal - @zzxuanyuan ran the posted roottest branch with a patched version of ROOT that includes this PR. I think we can close this out, no?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:122,usability,close,close,122,"@pcanal - @zzxuanyuan ran the posted roottest branch with a patched version of ROOT that includes this PR. I think we can close this out, no?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:40,deployability,patch,patched,40,"> ran the posted roottest branch with a patched version of ROOT that includes this PR. > Indeed, it works and had been uploaded a while [Sorry for the confusion ; attempting to rebase should have point this out :) ].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:48,deployability,version,version,48,"> ran the posted roottest branch with a patched version of ROOT that includes this PR. > Indeed, it works and had been uploaded a while [Sorry for the confusion ; attempting to rebase should have point this out :) ].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:48,integrability,version,version,48,"> ran the posted roottest branch with a patched version of ROOT that includes this PR. > Indeed, it works and had been uploaded a while [Sorry for the confusion ; attempting to rebase should have point this out :) ].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:48,modifiability,version,version,48,"> ran the posted roottest branch with a patched version of ROOT that includes this PR. > Indeed, it works and had been uploaded a while [Sorry for the confusion ; attempting to rebase should have point this out :) ].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:40,safety,patch,patched,40,"> ran the posted roottest branch with a patched version of ROOT that includes this PR. > Indeed, it works and had been uploaded a while [Sorry for the confusion ; attempting to rebase should have point this out :) ].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/61:40,security,patch,patched,40,"> ran the posted roottest branch with a patched version of ROOT that includes this PR. > Indeed, it works and had been uploaded a while [Sorry for the confusion ; attempting to rebase should have point this out :) ].",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/61
https://github.com/root-project/root/pull/63:193,integrability,sub,submitting,193,"Hi,. Thanks for the proposal but these modifications would break compatibility with VAF users. Please get in contact with Dario Berzano about this class and agree with him on any change before submitting a new request. Cheers, GG.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:65,interoperability,compatib,compatibility,65,"Hi,. Thanks for the proposal but these modifications would break compatibility with VAF users. Please get in contact with Dario Berzano about this class and agree with him on any change before submitting a new request. Cheers, GG.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:39,security,modif,modifications,39,"Hi,. Thanks for the proposal but these modifications would break compatibility with VAF users. Please get in contact with Dario Berzano about this class and agree with him on any change before submitting a new request. Cheers, GG.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:88,usability,user,users,88,"Hi,. Thanks for the proposal but these modifications would break compatibility with VAF users. Please get in contact with Dario Berzano about this class and agree with him on any change before submitting a new request. Cheers, GG.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:407,deployability,manag,manager,407,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:499,deployability,patch,patches,499,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:407,energy efficiency,manag,manager,407,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:121,integrability,Filter,Filter,121,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:339,integrability,interfac,interface,339,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:77,interoperability,compatib,compatibility,77,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:339,interoperability,interfac,interface,339,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:526,interoperability,specif,specific,526,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:339,modifiability,interfac,interface,339,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:162,safety,avoid,avoid,162,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:407,safety,manag,manager,407,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:499,safety,patch,patches,499,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:499,security,patch,patches,499,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:105,usability,user,users,105,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:612,usability,tool,tools,612,"Hello @aphecetche,. replacing an existing keyword with another one may break compatibility with existing users. Even if `Filter` sounds more appropriate, I would avoid doing that. Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. _""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work._. To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:29,deployability,depend,dependent,29,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:185,deployability,stage,staged,185,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:202,deployability,deploy,deployed,202,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:230,deployability,version,version,230,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:368,deployability,version,version,368,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1253,deployability,stage,stage-and-filter,1253,"I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1371,deployability,version,version,1371," for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT alrea",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1784,deployability,manag,manager,1784,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2412,deployability,manag,manager,2412,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2508,deployability,patch,patches,2508,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:72,energy efficiency,current,currently,72,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1784,energy efficiency,manag,manager,1784,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2412,energy efficiency,manag,manager,2412,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:29,integrability,depend,dependent,29,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:131,integrability,filter,filtering,131,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:230,integrability,version,version,230,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:368,integrability,version,version,368,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:582,integrability,filter,filtering,582,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:785,integrability,Filter,Filter,785,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1263,integrability,filter,filter,1263,"appy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1311,integrability,filter,filter,1311,"rd for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1318,integrability,filter,filtername,1318,"e user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1371,integrability,version,version,1371," for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT alrea",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1592,integrability,filter,filter,1592,"to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and tha",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2116,integrability,Filter,Filter,2116,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2344,integrability,interfac,interface,2344,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2073,interoperability,compatib,compatibility,2073,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2344,interoperability,interfac,interface,2344,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2535,interoperability,specif,specific,2535,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:29,modifiability,depend,dependent,29,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:230,modifiability,version,version,230,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:368,modifiability,version,version,368,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1371,modifiability,version,version,1371," for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT alrea",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2344,modifiability,interfac,interface,2344,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:144,performance,perform,performed,144,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:166,performance,time,time,166,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:455,performance,cach,cache,455,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:29,safety,depend,dependent,29,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1784,safety,manag,manager,1784,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2156,safety,avoid,avoid,2156,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2412,safety,manag,manager,2412,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2508,safety,patch,patches,2508,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2508,security,patch,patches,2508,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:29,testability,depend,dependent,29,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:144,usability,perform,performed,144,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:325,usability,user,user,325,"Hi,. OK. Yes, this is highly dependent on AliRoot/AliPhysics. . What is currently in production in the SAF is a procedure to get a filtering be performed at the same time data is being staged (*). I’ve deployed on SAF my own root version with those changes and I’m happy with the way it work, but it’s really awkward for the user because they cannot use the same root version for the staging and for their analysis (and they must play with datasetmanager cache of the queries to get the right files…). That’s why I’d want to have it « officially » in Root. To way to trigger such a filtering is to add bit and pieces to the file names generated by the TDataSetManager, e.g. :. const char\* query = ""Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Filter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aph",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1818,usability,user,users,1818,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2101,usability,user,users,2101,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2621,usability,tool,tools,2621,"lter=ESDMUON;Aliphysics=vAN-20150213"";. gProof->ShowDataSet(query);. will generate filenames as : . alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. On the workers the staging script is deciphering the filename in order to call. $ALICE_PHYSICS/aaf-stage-and-filter --from source_url --to destination_url --filter filtername . where :. ALICE_PHYSICS points to (cvmfs version of) vAN-20150213, . source_url is alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root alien:///alice/data/2011/LHC11h/000169838/ESDs/pass2_muon/11000169838080.42/AliESDs.root. filter name is ESDMUON . Hope this clarifies the intent (more bla at http://aphecetche.github.io/aafu/doc/#Datafiltering http://aphecetche.github.io/aafu/doc/#Datafiltering). . If the dataset manager can be easily provided to users without having it in Root, I’m all for it. . Regards,. > Le 5 mai 2015 à 18:40, Dario Berzano notifications@github.com a écrit :. > . > Hello @aphecetche https://github.com/aphecetche,. > . > replacing an existing keyword with another one may break compatibility with existing users. Even if Filter sounds more appropriate, I would avoid doing that. > . > Pushing the concepts of AliRoot and AliPhysics into ROOT is wrong. This is ALICE stuff and should not get ""too much"" into ROOT's code. > . > ""too much"" = the AliEn interface was inside ROOT already (wrongly, IMHO), and this dataset manager has been added to ROOT solely because it requires AliEn only to work. > . > To me those patches reflect your quite specific use case. What is it you'd like to achieve, and that cannot be done with the tools you have? > . > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99135034.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:257,availability,down,download,257,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:561,availability,cluster,cluster,561,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1630,availability,down,download,1630,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:165,deployability,contain,contains,165,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:214,deployability,stage,stager,214,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:456,deployability,Stage,Stage,456,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:561,deployability,cluster,cluster,561,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1231,deployability,patch,patch,1231,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1494,deployability,patch,patches,1494,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1698,deployability,patch,patch,1698,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1832,deployability,manag,manager,1832,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2022,deployability,manag,management,2022,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1832,energy efficiency,manag,manager,1832,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2022,energy efficiency,manag,management,2022,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:375,integrability,filter,filtering,375,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1543,integrability,filter,filtered,1543,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1657,integrability,configur,configured,1657,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1644,interoperability,specif,specifically,1644,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1689,interoperability,specif,specific,1689,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1657,modifiability,configur,configured,1657,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:627,performance,time,time,627,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1811,performance,time,time,1811,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:608,safety,reme,remember,608,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1231,safety,patch,patch,1231,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1494,safety,patch,patches,1494,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1698,safety,patch,patch,1698,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1832,safety,manag,manager,1832,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2022,safety,manag,management,2022,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1231,security,patch,patch,1231,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1494,security,patch,patches,1494,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1657,security,configur,configured,1657,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1698,security,patch,patch,1698,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:18,usability,User,User,18,"Ok, so to sum up. User requests the following file:. ```. alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. ```. This is not an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1204,usability,custom,custom,1204,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1298,usability,document,documentation,1298,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1324,usability,user,user,1324,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1979,usability,interact,interacting,1979,"ot an actual file: it contains a special string that tells the dataset stager (`afdsmgrd`: or more precisely, the download script it invokes for each file) to:. - Take the source file `alien://path/AliESDs.root` from AliEn. - Apply filtering of type `ESDMUON`. - Use AliPhysics `vAN-20150213` for that purpose. - Stage a file called `root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root` on your local cluster. (Please correct me if I am wrong.). I remember that some time ago we have agreed on having 34bb2e2b5f addressing the problem: `Query=<string>` was used to append an arbitrary `?<string>` to the generated filename. For instance:. ```. Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. ```. would generate filenames in the form:. ```. proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. ```. **Question:** did this approach work for you (again, see this: 34bb2e2b5f)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). As an alternative, you can provide them with a macro that generates the `Query=` part for you, if it is less awkward for them. Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about _managing lists of files_. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). Cheers. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:340,availability,down,download,340,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:640,availability,cluster,cluster,640,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3081,availability,down,download,3081,"AOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is ther",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3739,availability,down,download,3739," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:250,deployability,contain,contains,250,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:299,deployability,stage,stager,299,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:537,deployability,Stage,Stage,537,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:640,deployability,cluster,cluster,640,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2420,deployability,patch,patch,2420,"testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mecha",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2592,deployability,stage,stage,2592,"SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2945,deployability,patch,patches,2945,"urpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3149,deployability,patch,patch,3149,"stion: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked thi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3283,deployability,manag,manager,3283,"a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3300,deployability,manag,managing,3300," it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3492,deployability,patch,patch,3492," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3870,deployability,manag,management,3870," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4029,deployability,manag,management,4029," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4117,deployability,manag,manager,4117," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3283,energy efficiency,manag,manager,3283,"a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3300,energy efficiency,manag,managing,3300," it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3870,energy efficiency,manag,management,3870," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4029,energy efficiency,manag,management,4029," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4117,energy efficiency,manag,manager,4117," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:460,integrability,filter,filtering,460,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1537,integrability,filter,filtered,1537,"e a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approac",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2124,integrability,filter,filtered,2124," would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd st",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2994,integrability,filter,filtered,2994,":. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3108,integrability,configur,configured,3108,"and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom data",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3648,integrability,filter,filtering,3648," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3095,interoperability,specif,specifically,3095,"GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3140,interoperability,specif,specific,3140," . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3108,modifiability,configur,configured,3108,"and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom data",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:758,performance,time,time,758,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3262,performance,time,time,3262,"e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub htt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2552,reliability,doe,does,2552," that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:739,safety,reme,remember,739,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1423,safety,test,testing,1423,"AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2420,safety,patch,patch,2420,"testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mecha",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2696,safety,reme,remember,2696,"root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2945,safety,patch,patches,2945,"urpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3149,safety,patch,patch,3149,"stion: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked thi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3283,safety,manag,manager,3283,"a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3300,safety,manag,managing,3300," it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3492,safety,patch,patch,3492," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3870,safety,manag,management,3870," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3998,safety,except,except,3998," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4029,safety,manag,management,4029," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4117,safety,manag,manager,4117," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2420,security,patch,patch,2420,"testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mecha",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2945,security,patch,patches,2945,"urpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3108,security,configur,configured,3108,"and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom data",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3149,security,patch,patch,3149,"stion: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked thi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3492,security,patch,patch,3492," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:1423,testability,test,testing,1423,"AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:105,usability,User,User,105,"> Le 6 mai 2015 à 09:54, Dario Berzano notifications@github.com a écrit :. > . > Ok, so to sum up. > . > User requests the following file:. > . > alien://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root. > This is not an actual file: it contains a special string that tells the dataset stager (afdsmgrd: or more precisely, the download script it invokes for each file) to:. > . > Take the source file alien://path/AliESDs.root from AliEn. > Apply filtering of type ESDMUON. > Use AliPhysics vAN-20150213 for that purpose. > Stage a file called root://path/AliESDs.FILTER_ESDMUON_WITH_ALIPHYSICS_vAN-20150213.root on your local cluster. > (Please correct me if I am wrong.). > . > No need for correction, you got it right. > I remember that some time ago we have agreed on having 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1 addressing the problem: Query=<string> was used to append an arbitrary ?<string> to the generated filename. For instance:. > . > Find;FileName=AliESDs.root;BasePath=/alice/data/2011/LHC11h/000169838/ESDs/pass2_muon;Query=ESDMUON_vAN-20150213. > would generate filenames in the form:. > . > proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root proto://path/root_archive.zip?ESDMUON_vAN-20150213#AliESDs.root. I did try and sent you a mail a while back (15/09/2014), which was :. > Hi Dario,. > . > With lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2393,usability,custom,custom,2393," lots of delay I'm finally testing this part and … encountered a problem. (we are migrating SAF1 to SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2487,usability,document,documentation,2487,"o SAF2 this week and there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the pa",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:2513,usability,user,user,2513,"there are a number of filtered datasets that I’d like to be able to put back on SAF2 in a not so distant future… (*)). > . > It seems the Query= is honored only in the case of FileName=root_archive.zip. > . > e.g. the following query returns just like the one without Query=. > . > gProof->ShowDataSet(""Find;BasePath=/alice/data/2011/LHC11h/000170593/ESDs/pass2_muon/AOD119;FileName=AliAOD.Muons.root;Query=toto »). > . > Is that on purpose ? . > . > Thanks,. > . > (*) for instance :. > . > Find;BasePath=/alice/data/2013/LHC13c/000195644/ESDs/pass2/AOD139;FileName=AliAOD.root is 418 GB on Grid, and ~10 GB filtered on SAF1…. > . > Question: did this approach work for you (again, see this: 34bb2e2 https://github.com/root-mirror/root/commit/34bb2e2b5f21a2917f0821946a90a5d9b51e3fa1)? If it did not, why? If it is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a corr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3428,usability,interact,interacting,3428," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:3538,usability,user,user,3538," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4010,usability,user,users,4010," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:4102,usability,custom,custom,4102," is just a matter of typing less awkward strings for an extremely custom use case, then your patch cannot be accepted and I suggest replacing it with some good documentation for the end user :-). So no, the approach as it is does not work for us as :. a) we rarely stage full archives (that’s for sure). b) out of my head right now I cannot find back why but I kind of remember the proto://xxx?filter_aliversion#…. syntax did cause an issue somewhere. > As an alternative, you can provide them with a macro that generates the Query= part for you, if it is less awkward for them. > . > Ah, I also see that between your patches there is an option to ""stat"" the file if filtered. I can see the point there: stating a file which is not there would trigger a download on a specifically configured xrootd storage. This specific patch cannot be accepted by any means as it goes against a concept we have been trying to establish since a long time: ROOT's dataset manager is about managing lists of files. Staging files is a job that must be done elsewhere, for instance by a storage system or by a mechanism interacting with it. > . > Well, the intent of this part of the patch was to get a correct feed back (for the user) about the actual size of the file (as the size in the collection is the alien catalog size, i.e. before filtering). What you say here is that I cannot do that with a stat as this would trigger a download (in case the file is not there), do I get it correctly ? Any idea on how to achieve what I want ? > Thing is, we let data management in ROOT out of the door for a reason, and we don't want it to come in again through the window :-). > . > Well, yes, except that users do need data management at some point…. One other way maybe : is there a way to get a custom dataset manager (I feel I already asked this question at some point…) ? > Cheers. > . > d. > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/63#issuecomment-99362824.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:237,deployability,patch,patch,237,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:515,deployability,patch,patch,515,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:571,deployability,manag,manager,571,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:571,energy efficiency,manag,manager,571,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:328,modifiability,Concern,Concerning,328,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:237,safety,patch,patch,237,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:515,safety,patch,patch,515,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:571,safety,manag,manager,571,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:237,security,patch,patch,237,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:515,security,patch,patch,515,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:328,testability,Concern,Concerning,328,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:229,usability,minim,minimal,229,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/63:556,usability,custom,custom,556,"Ok right so we have a bug here :-). Can you please open a ticket (on the ALICE JIRA, not the ROOT one) and assign it to me, just saying that the query string is not honored in case you don't use the archive? If you can provide a minimal patch fixing it that'd be great :-). (Emails get lost, as you have seen: tickets do not!). Concerning the stat, it seems that I have got the `stat` part wrong: this part actually makes sense. Can you also open a separate ticket (also on ALICE JIRA) on that? No need to send any patch as you have already done it :-). A custom dataset manager is possible only tampering with ROOT code (I guess it's a ""no"" in your case). Cheers,. d.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/63
https://github.com/root-project/root/pull/64:27,interoperability,specif,specifically,27,"Thanks! Given that this is specifically macosx64 _with GCC_ - could you select on that, and not penalize the main MacOS X compiler?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:103,interoperability,specif,specifically,103,"Any clues on what variable to use. On 06/08/2015 12:54 PM, karies wrote:. > Thanks! Given that this is specifically macosx64 /with GCC/ - could . > you select on that, and not penalize the main MacOS X compiler? > . > —. > Reply to this email directly or view it on GitHub . > https://github.com/root-mirror/root/pull/64#issuecomment-110091485.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:18,modifiability,variab,variable,18,"Any clues on what variable to use. On 06/08/2015 12:54 PM, karies wrote:. > Thanks! Given that this is specifically macosx64 /with GCC/ - could . > you select on that, and not penalize the main MacOS X compiler? > . > —. > Reply to this email directly or view it on GitHub . > https://github.com/root-mirror/root/pull/64#issuecomment-110091485.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:30,modifiability,variab,variable,30,"Is that set as an environment variable? Would this work. ```. if [ $(ARCH) = ""macosx64"" && $(GCC_MAJOR) ]; then \. LLVM_CFLAGS=""-m64 -fno-omit-frame-pointer""; \. fi; \. ```. On 06/08/2015 12:59 PM, karies wrote:. > You could check for |GCC_MAJOR| which is not set for clang (where . > |CLANG_MAJOR| is set instead). > . > —. > Reply to this email directly or view it on GitHub . > https://github.com/root-mirror/root/pull/64#issuecomment-110092634.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:9,deployability,patch,patches,9,v6-02-00-patches and v6-04-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:30,deployability,patch,patches,30,v6-02-00-patches and v6-04-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:9,safety,patch,patches,9,v6-02-00-patches and v6-04-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:30,safety,patch,patches,30,v6-02-00-patches and v6-04-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:9,security,patch,patches,9,v6-02-00-patches and v6-04-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:30,security,patch,patches,30,v6-02-00-patches and v6-04-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:7,reliability,doe,doesn,7,But it doesn't set the flag.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/64:66,reliability,doe,does,66,@karies it is still not setting the flag. I will resubmit when it does.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/64
https://github.com/root-project/root/pull/65:57,reliability,Doe,Does,57,"I have pushed something similar, fixing the AND of test. Does that work for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/65:51,safety,test,test,51,"I have pushed something similar, fixing the AND of test. Does that work for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/65:51,testability,test,test,51,"I have pushed something similar, fixing the AND of test. Does that work for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/65
https://github.com/root-project/root/pull/66:31,deployability,patch,patches,31,@karies please add to v6.02.00-patches and v6.04.00-patches beanches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:52,deployability,patch,patches,52,@karies please add to v6.02.00-patches and v6.04.00-patches beanches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:31,safety,patch,patches,31,@karies please add to v6.02.00-patches and v6.04.00-patches beanches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:52,safety,patch,patches,52,@karies please add to v6.02.00-patches and v6.04.00-patches beanches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:31,security,patch,patches,31,@karies please add to v6.02.00-patches and v6.04.00-patches beanches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:52,security,patch,patches,52,@karies please add to v6.02.00-patches and v6.04.00-patches beanches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:34,usability,confirm,confirm,34,Thanks for spotting that! Can you confirm that the master works for you? Then I'll merge into v6-02 and v6-04.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:13,deployability,version,version,13,Yes the head version on master works as expected.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:13,integrability,version,version,13,Yes the head version on master works as expected.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/66:13,modifiability,version,version,13,Yes the head version on master works as expected.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/66
https://github.com/root-project/root/pull/67:22,performance,performance issu,performance issue,22,unfortunately this is performance issue .. as this way of handling the problem basically serialize all destruction of object derived from TObject ... :( ... i.e. one need a performance read-write lock for a proper fix.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:173,performance,perform,performance,173,unfortunately this is performance issue .. as this way of handling the problem basically serialize all destruction of object derived from TObject ... :( ... i.e. one need a performance read-write lock for a proper fix.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:196,performance,lock,lock,196,unfortunately this is performance issue .. as this way of handling the problem basically serialize all destruction of object derived from TObject ... :( ... i.e. one need a performance read-write lock for a proper fix.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:196,security,lock,lock,196,unfortunately this is performance issue .. as this way of handling the problem basically serialize all destruction of object derived from TObject ... :( ... i.e. one need a performance read-write lock for a proper fix.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:22,usability,perform,performance,22,unfortunately this is performance issue .. as this way of handling the problem basically serialize all destruction of object derived from TObject ... :( ... i.e. one need a performance read-write lock for a proper fix.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:173,usability,perform,performance,173,unfortunately this is performance issue .. as this way of handling the problem basically serialize all destruction of object derived from TObject ... :( ... i.e. one need a performance read-write lock for a proper fix.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:44,deployability,contain,container,44,CMS is seeing a crash originating from this container. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:110,deployability,patch,patch,110,"I am not surprised, this is a know problem. If the performance is acceptable for the CMS case, please use the patch. For the general case, we need more work on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:51,performance,perform,performance,51,"I am not surprised, this is a know problem. If the performance is acceptable for the CMS case, please use the patch. For the general case, we need more work on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:110,safety,patch,patch,110,"I am not surprised, this is a know problem. If the performance is acceptable for the CMS case, please use the patch. For the general case, we need more work on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:110,security,patch,patch,110,"I am not surprised, this is a know problem. If the performance is acceptable for the CMS case, please use the patch. For the general case, we need more work on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:51,usability,perform,performance,51,"I am not surprised, this is a know problem. If the performance is acceptable for the CMS case, please use the patch. For the general case, we need more work on it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:89,performance,lock,lock,89,How many TObjects get marked at 'kMustCleanup'? It is only under that condition that the lock will be taken in the destructor.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:89,security,lock,lock,89,How many TObjects get marked at 'kMustCleanup'? It is only under that condition that the lock will be taken in the destructor.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:0,availability,ping,ping,0,ping^1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:5,deployability,patch,patch,5,This patch will be superseded by work subsequent to #596,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:38,integrability,sub,subsequent,38,This patch will be superseded by work subsequent to #596,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:5,safety,patch,patch,5,This patch will be superseded by work subsequent to #596,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:5,security,patch,patch,5,This patch will be superseded by work subsequent to #596,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:8,reliability,doe,does,8,@pcanal does it incl. https://github.com/cms-sw/root/commit/308dabacf4b595918ee0b125298406fe4db5578a ? This is a part we still apply at CMS.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:10,deployability,patch,patch,10,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:24,integrability,event,eventually,24,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:88,performance,lock,lock,88,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:141,performance,lock,lock,141,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:10,safety,patch,patch,10,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:10,security,patch,patch,10,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:88,security,lock,lock,88,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:141,security,lock,lock,141,"Yes, this patch *will* (eventually) also be unnecessary (i.e. replaced by taking a read lock at this point that might be turned into a write lock as needed).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:13,usability,close,close,13,"Ok, shall we close it then?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:100,security,sign,signal,100,I will close this on another related PR when a proper replacement is uploaded. This will serve as a signal to the author to replace their temporary work-around.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:114,security,auth,author,114,I will close this on another related PR when a proper replacement is uploaded. This will serve as a signal to the author to replace their temporary work-around.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:7,usability,close,close,7,I will close this on another related PR when a proper replacement is uploaded. This will serve as a signal to the author to replace their temporary work-around.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:27,usability,close,close,27,"Hi @pcanal, perhaps we can close this one already since it is superseded by the RWlock PRs you have been working on?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:75,deployability,updat,updating,75,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:135,deployability,updat,update,135,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:95,performance,lock,lock,95,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:37,safety,safe,safe,37,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:75,safety,updat,updating,75,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:135,safety,updat,update,135,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:75,security,updat,updating,75,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:95,security,lock,lock,95,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:135,security,updat,update,135,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/67:121,usability,behavi,behavior,121,This is superseed by adding a thread-safe mode to some ROOT collection and updating the global lock to have a Read-Write behavior (and update RecursiveRemove and friends accordingly).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/67
https://github.com/root-project/root/pull/68:50,deployability,patch,patch,50,"Merged into master, v6-02, v6-04. Thanks for your patch!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/68
https://github.com/root-project/root/pull/68:50,safety,patch,patch,50,"Merged into master, v6-02, v6-04. Thanks for your patch!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/68
https://github.com/root-project/root/pull/68:50,security,patch,patch,50,"Merged into master, v6-02, v6-04. Thanks for your patch!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/68
https://github.com/root-project/root/pull/70:16,safety,test,testing,16,@pcanal - we're testing this in CMS. Will let you know if it went well.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/70
https://github.com/root-project/root/pull/70:16,testability,test,testing,16,@pcanal - we're testing this in CMS. Will let you know if it went well.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/70
https://github.com/root-project/root/pull/71:34,deployability,build,build,34,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:40,deployability,patch,patched,40,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:81,deployability,manag,manage,81,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:81,energy efficiency,manag,manage,81,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:40,safety,patch,patched,40,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:81,safety,manag,manage,81,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:40,security,patch,patched,40,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:139,usability,prefer,prefer,139,"Thanks. master only it's fine, we build patched v5.34 in any case and the way we manage externals makes it easy to do so. ;-). BTW, do you prefer Github or JIRA for fixes / cleanups?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:49,deployability,patch,patches,49,"Hi Giulio,. Thanks! We keep bug reports in Jira; patches over Github are indeed easier (we. can review them). Cheers, Axel .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:49,safety,patch,patches,49,"Hi Giulio,. Thanks! We keep bug reports in Jira; patches over Github are indeed easier (we. can review them). Cheers, Axel .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:96,safety,review,review,96,"Hi Giulio,. Thanks! We keep bug reports in Jira; patches over Github are indeed easier (we. can review them). Cheers, Axel .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:49,security,patch,patches,49,"Hi Giulio,. Thanks! We keep bug reports in Jira; patches over Github are indeed easier (we. can review them). Cheers, Axel .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/71:96,testability,review,review,96,"Hi Giulio,. Thanks! We keep bug reports in Jira; patches over Github are indeed easier (we. can review them). Cheers, Axel .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/71
https://github.com/root-project/root/pull/72:45,interoperability,specif,specific,45,"Thanks! I will apply it. And it is obviously specific to ix86, since x86_64 is not yet supported on Windows.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:87,usability,support,supported,87,"Thanks! I will apply it. And it is obviously specific to ix86, since x86_64 is not yet supported on Windows.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:47,deployability,patch,patches,47,Thanks! Now applied in git master and v5-34-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:47,safety,patch,patches,47,Thanks! Now applied in git master and v5-34-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:47,security,patch,patches,47,Thanks! Now applied in git master and v5-34-00-patches.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:150,deployability,modul,module,150,"@bellenot, I'd also like to understand why this command is here as i've got one other PR, #73 that may be related, regarding where to put this python module .pyd.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:150,modifiability,modul,module,150,"@bellenot, I'd also like to understand why this command is here as i've got one other PR, #73 that may be related, regarding where to put this python module .pyd.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:150,safety,modul,module,150,"@bellenot, I'd also like to understand why this command is here as i've got one other PR, #73 that may be related, regarding where to put this python module .pyd.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:28,testability,understand,understand,28,"@bellenot, I'd also like to understand why this command is here as i've got one other PR, #73 that may be related, regarding where to put this python module .pyd.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:48,usability,command,command,48,"@bellenot, I'd also like to understand why this command is here as i've got one other PR, #73 that may be related, regarding where to put this python module .pyd.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:29,interoperability,standard,standard,29,"@bellenot but there's also a standard site dir, something like `<python_prefix>\Lib\site-packages`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:89,modifiability,pac,packages,89,"@bellenot but there's also a standard site dir, something like `<python_prefix>\Lib\site-packages`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:102,testability,understand,understand,102,"i was wondering why this command was here instead of just setting the .pyd suffix, but I still do not understand bc9ce4e : was it to add `-export:initlibPyROOT` ? what's the use of ROOTULIBS ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:25,usability,command,command,25,"i was wondering why this command was here instead of just setting the .pyd suffix, but I still do not understand bc9ce4e : was it to add `-export:initlibPyROOT` ? what's the use of ROOTULIBS ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:98,deployability,patch,patches,98,"@xantares In fact it is needed on Windows to force import of some symbols. It is used in v5-34-00-patches, but forgotten in master (since master doesn't build yet on Windows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:153,deployability,build,build,153,"@xantares In fact it is needed on Windows to force import of some symbols. It is used in v5-34-00-patches, but forgotten in master (since master doesn't build yet on Windows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:145,reliability,doe,doesn,145,"@xantares In fact it is needed on Windows to force import of some symbols. It is used in v5-34-00-patches, but forgotten in master (since master doesn't build yet on Windows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:98,safety,patch,patches,98,"@xantares In fact it is needed on Windows to force import of some symbols. It is used in v5-34-00-patches, but forgotten in master (since master doesn't build yet on Windows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:98,security,patch,patches,98,"@xantares In fact it is needed on Windows to force import of some symbols. It is used in v5-34-00-patches, but forgotten in master (since master doesn't build yet on Windows).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:19,testability,hard-wir,hard-wired,19,and what about the hard-wired link command ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:35,usability,command,command,35,and what about the hard-wired link command ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:36,deployability,instal,install,36,"yeah, i wasn't sure if changing the install destination of the PyROOT target would affect this .pyd too, because you relink it to libPyROOT.pyd somehow and reinstall it to CMAKE_INSTALL_BINDIR, and it seemed like overly-complicated to just set the .pyd suffix.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:220,safety,compl,complicated,220,"yeah, i wasn't sure if changing the install destination of the PyROOT target would affect this .pyd too, because you relink it to libPyROOT.pyd somehow and reinstall it to CMAKE_INSTALL_BINDIR, and it seemed like overly-complicated to just set the .pyd suffix.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/72:220,security,compl,complicated,220,"yeah, i wasn't sure if changing the install destination of the PyROOT target would affect this .pyd too, because you relink it to libPyROOT.pyd somehow and reinstall it to CMAKE_INSTALL_BINDIR, and it seemed like overly-complicated to just set the .pyd suffix.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/72
https://github.com/root-project/root/pull/73:40,safety,review,review,40,"hi @karies, @peremato, someone up for a review ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:40,testability,review,review,40,"hi @karies, @peremato, someone up for a review ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:627,deployability,instal,install,627,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:642,deployability,modul,module,642,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:135,integrability,contract,contract,135,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:607,integrability,Sub,Subject,607,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:135,interoperability,contract,contract,135,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:166,modifiability,maintain,maintain,166,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:642,modifiability,modul,module,642,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:166,safety,maintain,maintain,166,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:642,safety,modul,module,642,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:128,security,sign,sign,128,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:32,usability,document,documented,32,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:182,usability,help,help,182,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:196,usability,user,users,196,"Hi,. yes, my objections are all documented in that jira report. I strongly. vote 'no'. If anyone wants to go ahead anyway, then sign a contract in. blood that you'll maintain it and help confused users from here on out. Best regards,. Wim. On Thursday 2015-09-03 05:08, Axel Naumann wrote:. > Date: Thu, 03 Sep 2015 05:08:04 -0700. > From: Axel Naumann notifications@github.com. > Reply-To: root-mirror/root. > <reply+00613b66d70f8ce7beaed1a94ac44c0adf0329085ffc340492cf0000000111fffa2. > 492a169ce05d53aeb@reply.github.com>. > To: root-mirror/root root@noreply.github.com. > Cc: wlav WLavrijsen@lbl.gov. > Subject: Re: [root] install python module to site-dir (ROOT-3316) (#73). > . > @wlav should have a look as seemed to have good reasons against such a change on https://sft.its.cern.ch/jira/browse/ROOT-3316. > . > ---. > . > Reply to this email directly or view it on GitHub:. > https://github.com/root-mirror/root/pull/73#issuecomment-137418303. ## . WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:186,availability,robust,robust,186,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:332,deployability,updat,updated,332,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:422,deployability,manag,manager,422,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:422,energy efficiency,manag,manager,422,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:270,modifiability,pac,package,270,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:414,modifiability,pac,package,414,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:186,reliability,robust,robust,186,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:356,reliability,doe,doesn,356,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:186,safety,robust,robust,186,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:307,safety,risk,risks,307,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:332,safety,updat,updated,332,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:422,safety,manag,manager,422,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:307,security,risk,risks,307,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:332,security,updat,updated,332,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:397,usability,user,users,397,"hello @wlav,. I was confused to have to set PYTHONPATH in the first place, like Andy was :). Forgive me but your objections do not seem rock-solid:. - '""distutils.sysconfig"" is far from robust as claimed' : afaik it works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. - ""package as a whole gets split, which risks that one part gets updated whereas another doesn't"": how would that be possible for users ? a decent package manager should handle that well. regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:149,availability,robust,robust,149,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1567,availability,error,error,1567,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1717,availability,down,downsides,1717,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:412,deployability,updat,updated,412,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:508,deployability,manag,manager,508,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:551,deployability,manag,manager,551,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:563,deployability,instal,install,563,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:697,deployability,build,building,697,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:747,deployability,manag,managers,747,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:824,deployability,instal,installations,824,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:863,deployability,build,building,863,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:886,deployability,version,versions,886,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:924,deployability,upgrad,upgrades,924,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1015,deployability,instal,installation,1015,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1266,deployability,instal,install,1266,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1313,deployability,build,builders,1313,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1397,deployability,instal,installing,1397,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:508,energy efficiency,manag,manager,508,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:551,energy efficiency,manag,manager,551,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:747,energy efficiency,manag,managers,747,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:886,integrability,version,versions,886,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1573,integrability,messag,messages,1573,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1782,integrability,contract,contract,1782,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:270,interoperability,platform,platforms,270,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1573,interoperability,messag,messages,1573,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1782,interoperability,contract,contract,1782,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:350,modifiability,pac,package,350,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:500,modifiability,pac,package,500,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:543,modifiability,pac,package,543,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:739,modifiability,pac,package,739,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:849,modifiability,pac,packagers,849,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:886,modifiability,version,versions,886,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:924,modifiability,upgrad,upgrades,924,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:953,modifiability,pac,packages,953,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1530,performance,time,time,1530,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1567,performance,error,error,1567,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:149,reliability,robust,robust,149,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:439,reliability,doe,doesn,439,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:149,safety,robust,robust,149,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:387,safety,risk,risks,387,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:412,safety,updat,updated,412,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:508,safety,manag,manager,508,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:551,safety,manag,manager,551,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:747,safety,manag,managers,747,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1567,safety,error,error,1567,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:387,security,risk,risks,387,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:412,security,updat,updated,412,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1652,security,access,access,1652,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1766,security,sign,sign,1766,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:623,testability,simpl,simply,623,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:968,testability,simpl,simply,968,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:480,usability,user,users,480,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:623,usability,simpl,simply,623,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:691,usability,user,users,691,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:780,usability,user,users,780,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:968,usability,simpl,simply,968,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:977,usability,user,user,977,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1029,usability,User,Users,1029,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1567,usability,error,error,1567,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1617,usability,user,user,1617,"Hi,. On Thursday 2015-09-03 10:56, xantares wrote:. > Forgive me but your objections do not seem rock-solid:. > - '""distutils.sysconfig"" is far from robust as claimed' : afaik it. > works very well from 2.6-2.7, 3.1,3.2, 3.3 to 3.4. sure, on Linux. Did you try all main platforms? (And do add at least p2.5,. as that for sure is still in use.). > - ""package as a whole gets split, which risks that one part gets updated. > whereas another doesn't"": how would that be possible for users ? a. > decent package manager should handle that well. A package manager can install wherever it wants and can make its own. adjustment (simply copy over the two files, or put symlinks); this will. affect users building from source. I don't worry about package managers,. only about the latter users. As to 'how': the common case mixing. installations (e.g. from packagers and building from source), versions. (different pythons), system upgrades (that wipe out site-packages), or. simply a user doing 'rm -rf' for only half the installation. Users are. very, very inventive in creating trouble. :P None of that if all of ROOT. is kept in a single directory. So the only upside there seems to be is removing of this teeny-weeny. inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh,. which sets up PYTHONPATH; and B) installing in /usr/local is not. recommended to begin with, b/c of the same problem with remnants. Debugging a setup problem is very time consuming and frustrating: the. error messages are spurious and only occur on the user's machine to which. I have no access. In sum, I see no upside to speak of, but do see enormous downsides. And. if you really believe otherwise: sign that blood contract. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:682,availability,down,downsides,682,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:129,deployability,instal,install,129,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:176,deployability,build,builders,176,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:259,deployability,instal,installing,259,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:383,deployability,instal,installing,383,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:429,deployability,instal,install,429,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:446,deployability,modul,module,446,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:497,deployability,instal,install,497,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:552,deployability,manag,management,552,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:616,deployability,instal,install,616,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:552,energy efficiency,manag,management,552,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:446,modifiability,modul,module,446,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:544,modifiability,pac,package,544,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:585,modifiability,pac,packaging,585,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:372,safety,valid,valid,372,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:446,safety,modul,module,446,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:552,safety,manag,management,552,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:576,testability,simpl,simplify,576,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:723,testability,simpl,simpler,723,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:397,usability,user,user,397,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:460,usability,user,user,460,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:481,usability,user,users,481,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:576,usability,simpl,simplify,576,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:723,usability,simpl,simpler,723,"@wlav . ""So the only upside there seems to be is removing of this teeny-weeny inconvenience of having to setup PYTHONPATH if you install in /usr/local. But A) most from-source builders don't do that, they use bin/thisroot.sh, which sets up PYTHONPATH; and B) installing in /usr/local is not recommended to begin with, b/c of the same problem with remnants."". A) it's also valid when installing as user to ~/.local (like when you install a python module with --user). B) of course, users shouldn't install anything to /usr[/local] without using package management, but it will simplify packaging too by not having to install an ugly script somewhere that sets PYTHONPATH. As for the downsides, I think this solution is just simpler (not mentioning cleaner), maybe this will get you less bug reports.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:545,availability,down,downsides,545,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:75,deployability,instal,install,75,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:133,deployability,manag,management,133,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:212,deployability,instal,install,212,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:411,deployability,manag,manager,411,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:704,deployability,build,build,704,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:723,deployability,roll,roll,723,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:867,deployability,instal,installation,867,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:899,deployability,instal,installations,899,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:133,energy efficiency,manag,management,133,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:411,energy efficiency,manag,manager,411,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:125,modifiability,pac,package,125,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:181,modifiability,pac,packaging,181,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:403,modifiability,pac,package,403,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:461,modifiability,pac,package,461,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:971,modifiability,pac,packages,971,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:990,modifiability,pac,packagers,990,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:15,performance,time,time,15,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:1379,performance,time,time,1379,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:133,safety,manag,management,133,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:411,safety,manag,manager,411,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:948,security,access,access,948,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:172,testability,simpl,simplify,172,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:387,testability,simpl,simpler,387,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:586,testability,simpl,simpler,586,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:59,usability,user,users,59,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:172,usability,simpl,simplify,172,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:387,usability,simpl,simpler,387,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:586,usability,simpl,simpler,586,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:814,usability,workflow,workflow,814,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/73:927,usability,user,users,927,"Hi,. very last time and then I give up ... > B) of course, users shouldn't install anything to /usr[/local] without. > using package management. But they do. > but it will simplify packaging too by not having to install an ugly. > script somewhere that sets PYTHONPATH. Ugly scripts that are seldom seen. I care more about humans than computers. Additionally, the removal scripts can be simpler, as the package manager. knows where it put what, rather than the package stuffing portions in. different places, so I'd say its a wash. > As for the downsides, I think this solution is just simpler (not. > mentioning cleaner), maybe this will get you less bug reports. Straight of the bat, the whole nightly build system would roll over and. all developers that use cmake (not me, luckily) would have to change their. workflow. Why? B/c most of these setups are 1 python installation and. multiple ROOT installations, or different users for both so no access. rights to site packages. Add that packagers for LCG experiments now need. to know that ROOT puts stuff in $ROOTSYS and in $PYTHONHOME and fix what. they pick up from where. For that matter, I think there will be far more. 'ugly scripts' being created here to work around the mess this would add,. that I dare claim that even that argument of yours holds no water. Like I said, this is my last word on it. It's not worth my time if you. refuse to look beyond that one use case. Best regards,. ## Wim. WLavrijsen@lbl.gov -- +1 (510) 486 6411 -- www.lavrijsen.net.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/73
https://github.com/root-project/root/pull/74:111,deployability,patch,patch,111,"Hi Omar,. we have changed the documentation syntax to doxygen; you have reverted some of these changes in your patch. Could you fix that, please? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:111,safety,patch,patch,111,"Hi Omar,. we have changed the documentation syntax to doxygen; you have reverted some of these changes in your patch. Could you fix that, please? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:111,security,patch,patch,111,"Hi Omar,. we have changed the documentation syntax to doxygen; you have reverted some of these changes in your patch. Could you fix that, please? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:30,usability,document,documentation,30,"Hi Omar,. we have changed the documentation syntax to doxygen; you have reverted some of these changes in your patch. Could you fix that, please? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:158,deployability,integr,integrate,158,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:158,integrability,integr,integrate,158,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:158,interoperability,integr,integrate,158,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:158,modifiability,integr,integrate,158,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:158,reliability,integr,integrate,158,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:158,security,integr,integrate,158,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:158,testability,integr,integrate,158,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:38,usability,document,documentation,38,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:134,usability,user,users,134,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:140,usability,guid,guide,140,"Hi Axel,. The fixes are ready and the documentation in doxygen is ready . http://files.oproject.org/root/rootdoc/html/group___r.html. users guide in markdown integrate to doxygen . http://files.oproject.org/root/rootdoc/html/md__home_omazapa_root_bindings_r_doc_users-guide__r_o_o_t_r__users__guide.html. Best regards.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:33,deployability,updat,updated,33,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:234,interoperability,bind,bindings,234,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:234,modifiability,bind,bindings,234,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:33,safety,updat,updated,33,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:47,safety,test,tested,47,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:99,safety,review,review,99,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:33,security,updat,updated,33,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:47,testability,test,tested,47,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:99,testability,review,review,99,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:198,usability,user,users,198,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:204,usability,guid,guide,204,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:249,usability,user,users-guide,249,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:313,usability,user,users,313,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:319,usability,guid,guides,319,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:338,usability,document,documentation,338,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:352,usability,user,users-guide,352,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:380,usability,user,users,380,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/74:386,usability,guid,guide,386,"Hi Axel and Lorenzo,. I have all updated, well tested and ready for merge. If you want to do other review and you have corrections please let me know. On the other hand I have a question:. I have a users guide in markdown in $ROOTSYS/bindings/r/doc/users-guide and I can see that in the last commits you have the users guides in $ROOTSYS/documentation/users-guide. must I move my users guide there? Best Regards! .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/74
https://github.com/root-project/root/pull/81:55,interoperability,format,format,55,"@zzxuanyuan - can you post the above info in a tabular format? Also, can you repeat the tests using the file @pcanal posted in the other ticket? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:88,safety,test,tests,88,"@zzxuanyuan - can you post the above info in a tabular format? Also, can you repeat the tests using the file @pcanal posted in the other ticket? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:88,testability,test,tests,88,"@zzxuanyuan - can you post the above info in a tabular format? Also, can you repeat the tests using the file @pcanal posted in the other ticket? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:118,modifiability,deco,decompression,118,"@pcanal - I think this is ready to go in. Talking with Zhe, I think the reason the CMS file shows smaller increase in decompression speed is mostly due to the more complex objects in CMS's files (which causes deserialization to be the bottleneck, not decompression).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:251,modifiability,deco,decompression,251,"@pcanal - I think this is ready to go in. Talking with Zhe, I think the reason the CMS file shows smaller increase in decompression speed is mostly due to the more complex objects in CMS's files (which causes deserialization to be the bottleneck, not decompression).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:235,performance,bottleneck,bottleneck,235,"@pcanal - I think this is ready to go in. Talking with Zhe, I think the reason the CMS file shows smaller increase in decompression speed is mostly due to the more complex objects in CMS's files (which causes deserialization to be the bottleneck, not decompression).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:164,safety,compl,complex,164,"@pcanal - I think this is ready to go in. Talking with Zhe, I think the reason the CMS file shows smaller increase in decompression speed is mostly due to the more complex objects in CMS's files (which causes deserialization to be the bottleneck, not decompression).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:164,security,compl,complex,164,"@pcanal - I think this is ready to go in. Talking with Zhe, I think the reason the CMS file shows smaller increase in decompression speed is mostly due to the more complex objects in CMS's files (which causes deserialization to be the bottleneck, not decompression).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:41,usability,confirm,confirm,41,Could we do a quick set of igprof run to confirm this hypothesis?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:73,testability,context,context,73,"@pcanal - I haven't shown Zhe igprof yet. I normally use it from the CMS context (with the CMS ROOT, CMS compilers, etc). Is there a good documentation page for using it with ROOT directly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:138,usability,document,documentation,138,"@pcanal - I haven't shown Zhe igprof yet. I normally use it from the CMS context (with the CMS ROOT, CMS compilers, etc). Is there a good documentation page for using it with ROOT directly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:64,safety,reme,remember,64,There should be no difference with the CMS case ... The only to remember is to run it on the executable spelled root.exe (rather than the executable spelled 'root').,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:48,energy efficiency,cloud,cloud,48,"![screen shot 2015-09-13 at 6 24 30 am](https://cloud.githubusercontent.com/assets/5465535/9836448/4774c3b4-59e0-11e5-8b1c-3bd4f9cdcd5d.png). I have been profiling the decompression executable with zlib, lzma, lz4. I attached the result here. lz4 uses the least time to decompress the basket (16.3%). @pcanal @bbockelm .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:154,energy efficiency,profil,profiling,154,"![screen shot 2015-09-13 at 6 24 30 am](https://cloud.githubusercontent.com/assets/5465535/9836448/4774c3b4-59e0-11e5-8b1c-3bd4f9cdcd5d.png). I have been profiling the decompression executable with zlib, lzma, lz4. I attached the result here. lz4 uses the least time to decompress the basket (16.3%). @pcanal @bbockelm .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:168,modifiability,deco,decompression,168,"![screen shot 2015-09-13 at 6 24 30 am](https://cloud.githubusercontent.com/assets/5465535/9836448/4774c3b4-59e0-11e5-8b1c-3bd4f9cdcd5d.png). I have been profiling the decompression executable with zlib, lzma, lz4. I attached the result here. lz4 uses the least time to decompress the basket (16.3%). @pcanal @bbockelm .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:270,modifiability,deco,decompress,270,"![screen shot 2015-09-13 at 6 24 30 am](https://cloud.githubusercontent.com/assets/5465535/9836448/4774c3b4-59e0-11e5-8b1c-3bd4f9cdcd5d.png). I have been profiling the decompression executable with zlib, lzma, lz4. I attached the result here. lz4 uses the least time to decompress the basket (16.3%). @pcanal @bbockelm .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:154,performance,profil,profiling,154,"![screen shot 2015-09-13 at 6 24 30 am](https://cloud.githubusercontent.com/assets/5465535/9836448/4774c3b4-59e0-11e5-8b1c-3bd4f9cdcd5d.png). I have been profiling the decompression executable with zlib, lzma, lz4. I attached the result here. lz4 uses the least time to decompress the basket (16.3%). @pcanal @bbockelm .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:262,performance,time,time,262,"![screen shot 2015-09-13 at 6 24 30 am](https://cloud.githubusercontent.com/assets/5465535/9836448/4774c3b4-59e0-11e5-8b1c-3bd4f9cdcd5d.png). I have been profiling the decompression executable with zlib, lzma, lz4. I attached the result here. lz4 uses the least time to decompress the basket (16.3%). @pcanal @bbockelm .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:224,performance,time,time-only,224,"So the igprof report says that lz4 on the cms file is 20% faster than zlib. It is odd that it is not reflected in the data as it is supposed to be using "" TTreePerfStats information, which gives us access to the compression-time-only rates."" ... what am I missing? (i.e. do we have a bug in TTreePerfStas or is the number above not the (de)compression-time-only? Also LZ4HC and zlib-1 are expected to have similar file size. So we could also add zlib-1 to the table? Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:352,performance,time,time-only,352,"So the igprof report says that lz4 on the cms file is 20% faster than zlib. It is odd that it is not reflected in the data as it is supposed to be using "" TTreePerfStats information, which gives us access to the compression-time-only rates."" ... what am I missing? (i.e. do we have a bug in TTreePerfStas or is the number above not the (de)compression-time-only? Also LZ4HC and zlib-1 are expected to have similar file size. So we could also add zlib-1 to the table? Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:198,security,access,access,198,"So the igprof report says that lz4 on the cms file is 20% faster than zlib. It is odd that it is not reflected in the data as it is supposed to be using "" TTreePerfStats information, which gives us access to the compression-time-only rates."" ... what am I missing? (i.e. do we have a bug in TTreePerfStas or is the number above not the (de)compression-time-only? Also LZ4HC and zlib-1 are expected to have similar file size. So we could also add zlib-1 to the table? Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:275,energy efficiency,measur,measure,275,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:184,modifiability,deco,decompression,184,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:287,performance,perform,performance,287,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:18,safety,test,testing,18,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:18,testability,test,testing,18,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:202,testability,simpl,simply,202,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:202,usability,simpl,simply,202,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:287,usability,perform,performance,287,"@pcanal I wrote a testing program on my own. For compression, it basically reads the root file given in your ticket and compress all the trees in it and write out to another file. For decompression, it simply iterates all entries in the compressed file. I used TStopWatch to measure the performance. I did not use TTreePerfStats in my program. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:71,usability,tool,tool,71,> I did not use TTreePerfStats in my program. . > Why not? (It was the tool used by Brian originally and would have give more accurate information by focusing on 'just' the zipping/unzipping).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:35,performance,perform,performance,35,I will rerun the tests and see how performance looks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:17,safety,test,tests,17,I will rerun the tests and see how performance looks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:17,testability,test,tests,17,I will rerun the tests and see how performance looks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:35,usability,perform,performance,35,I will rerun the tests and see how performance looks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:332,energy efficiency,cpu,cpu,332,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:154,integrability,Event,Events,154,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:291,modifiability,deco,decompression,291,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:318,modifiability,deco,decompression,318,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:134,performance,time,time,134,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:310,performance,time,time,310,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:332,performance,cpu,cpu,332,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:336,performance,time,time,336,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:662,performance,time,time,662,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:708,testability,understand,understand,708,"I have some trouble to use TTreePerfStats to accumulate perf stats of all the trees in CMS file. The following is the depression-only-time from the tree ""Events"" (it is constitude 1.8 GB out of 1.9 GB in CMS). I also attached zlib-1 (I assume it stands for zlib with level 1). | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. @pcanal regarding to your previous comment. Is there a way to compare (de)compression time only from igprof result? I did not quite understand why lz4 is 20% faster than zlib?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:43,energy efficiency,measur,measure,43,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:322,integrability,Event,Events,322,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:521,integrability,Event,Events,521,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:63,performance,time,time,63,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:486,performance,iop,ioperf,486,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:631,performance,iop,ioperf,631,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:732,performance,iop,ioperf,732,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:656,usability,Close,Close,656,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:673,usability,Close,Close,673,"@pcanal @bbockelm I am still struggling to measure compression time. I can't find a good way to copy the tree before I attach it into TTreePerfStats. I paste a piece of code extracted from my code. . ``` c++. TFile* rfile = TFile::Open(""CMS_7250E9A5-682D-DF11-8701-002618943934.root"");. TTree* rtree = (TTree*)rfile->Get(""Events"");. Long64_t nentries = rtree->GetEntries();. TFile* wfile = TFile::Open(""copytree.root"",""RECREATE"");. TTree* wtree = rtree->CloneTree(0); . TTreePerfStats* ioperf = new TTreePerfStats(""Stats Events"", wtree);. for(Long64_t i; i<nentries; ++i){. rtree->GetEntry(i);. wtree->Fill();. }. wtree->Write();. ioperf->Print();. wfile->Close();. rfile->Close();. ```. But I can't get any useful information from ioperf.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:270,availability,state,states,270,"@pcanal - Zhe is going to post the output of ioperf->Print() soon so we can help figure out what's going wrong. I'm not entirely sure the tree is being cloned properly; can you look at the code he posted? However, looking at your prior comment, I'm not sure that igprof states there's a 20% improvement going from zlib to lz4 -- it looks more modest than that to me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:270,integrability,state,states,270,"@pcanal - Zhe is going to post the output of ioperf->Print() soon so we can help figure out what's going wrong. I'm not entirely sure the tree is being cloned properly; can you look at the code he posted? However, looking at your prior comment, I'm not sure that igprof states there's a 20% improvement going from zlib to lz4 -- it looks more modest than that to me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:45,performance,iop,ioperf,45,"@pcanal - Zhe is going to post the output of ioperf->Print() soon so we can help figure out what's going wrong. I'm not entirely sure the tree is being cloned properly; can you look at the code he posted? However, looking at your prior comment, I'm not sure that igprof states there's a 20% improvement going from zlib to lz4 -- it looks more modest than that to me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:76,usability,help,help,76,"@pcanal - Zhe is going to post the output of ioperf->Print() soon so we can help figure out what's going wrong. I'm not entirely sure the tree is being cloned properly; can you look at the code he posted? However, looking at your prior comment, I'm not sure that igprof states there's a 20% improvement going from zlib to lz4 -- it looks more modest than that to me.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:445,energy efficiency,CPU,CPU,445,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:56,integrability,Event,Events,56,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:227,integrability,Event,Events,227,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:421,performance,Time,Time,421,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:445,performance,CPU,CPU,445,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:449,performance,Time,Time,449,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:473,performance,Disk,Disk,473,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:478,performance,Time,Time,478,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:500,performance,Disk,Disk,500,"Here is the output of the program. I only list tree of ""Events"" here. @bbockelm I was wrong. The program did generate the correct root output file. I guess the following is the result it is supposed to be? ``` text. Stats Tree Events. TreeCache = 30 MBytes. N leaves = 285. ReadTotal = 0 MBytes. ReadUnZip = -nan MBytes. ReadCalls = 0. ReadSize = -nan KBytes/read. Readahead = 256 KBytes. Readextra = -nan per cent. Real Time = 848.538 seconds. CPU Time = 815.200 seconds. Disk Time = 0.000 seconds. Disk IO = -nan MBytes/s. ReadUZRT = -nan MBytes/s. ReadUZCP = -nan MBytes/s. ReadRT = 0.000 MBytes/s. ReadCP = 0.000 MBytes/s. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:104,deployability,updat,updating,104,"Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:104,safety,updat,updating,104,"Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:104,security,updat,updating,104,"Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:299,deployability,updat,updating,299,"Yeah, I'd be happy to start tackling that - but I'd much prefer to wrap this PR up first. Brian. Sent from my iPhone. > On Sep 28, 2015, at 5:25 PM, pcanal notifications@github.com wrote:. > . > Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? > . > Thanks. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:67,integrability,wrap,wrap,67,"Yeah, I'd be happy to start tackling that - but I'd much prefer to wrap this PR up first. Brian. Sent from my iPhone. > On Sep 28, 2015, at 5:25 PM, pcanal notifications@github.com wrote:. > . > Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? > . > Thanks. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:299,safety,updat,updating,299,"Yeah, I'd be happy to start tackling that - but I'd much prefer to wrap this PR up first. Brian. Sent from my iPhone. > On Sep 28, 2015, at 5:25 PM, pcanal notifications@github.com wrote:. > . > Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? > . > Thanks. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:299,security,updat,updating,299,"Yeah, I'd be happy to start tackling that - but I'd much prefer to wrap this PR up first. Brian. Sent from my iPhone. > On Sep 28, 2015, at 5:25 PM, pcanal notifications@github.com wrote:. > . > Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? > . > Thanks. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:57,usability,prefer,prefer,57,"Yeah, I'd be happy to start tackling that - but I'd much prefer to wrap this PR up first. Brian. Sent from my iPhone. > On Sep 28, 2015, at 5:25 PM, pcanal notifications@github.com wrote:. > . > Yes, I had forgotten that TTreePerfStats was not wired for writing ... only reading. Would you consider updating TTreePerfStats and TBasket to also track writing? > . > Thanks. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:81,performance,perform,performance,81,"Brian,. So the number seems to say that lz4 and zlib-1 are equivalent in term of performance and compression. What use case do you see where lz4 really wins (I.e. where CMS would really benefit from switching)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:81,usability,perform,performance,81,"Brian,. So the number seems to say that lz4 and zlib-1 are equivalent in term of performance and compression. What use case do you see where lz4 really wins (I.e. where CMS would really benefit from switching)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:124,modifiability,deco,decompression,124,"@zzxuanyuan - for non-CMS files, can you also post the results for zlib-1? @pcanal - even for CMS files, LZ4 beat ZLIB-1 at decompression speed, right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:100,energy efficiency,cpu,cpu,100,"Here is the results from ""event"" executable. | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 122.62 MB/s | 136.61 MB/s | 181 MB |. | lz4 | 127.57 MB/s | 146.42 MB/s | 221 MB |. | zlib-1 | 105.57 MB/s | 118.10 MB/s | 197 MB |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:26,integrability,event,event,26,"Here is the results from ""event"" executable. | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 122.62 MB/s | 136.61 MB/s | 181 MB |. | lz4 | 127.57 MB/s | 146.42 MB/s | 221 MB |. | zlib-1 | 105.57 MB/s | 118.10 MB/s | 197 MB |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:59,modifiability,deco,decompression,59,"Here is the results from ""event"" executable. | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 122.62 MB/s | 136.61 MB/s | 181 MB |. | lz4 | 127.57 MB/s | 146.42 MB/s | 221 MB |. | zlib-1 | 105.57 MB/s | 118.10 MB/s | 197 MB |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:86,modifiability,deco,decompression,86,"Here is the results from ""event"" executable. | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 122.62 MB/s | 136.61 MB/s | 181 MB |. | lz4 | 127.57 MB/s | 146.42 MB/s | 221 MB |. | zlib-1 | 105.57 MB/s | 118.10 MB/s | 197 MB |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:78,performance,time,time,78,"Here is the results from ""event"" executable. | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 122.62 MB/s | 136.61 MB/s | 181 MB |. | lz4 | 127.57 MB/s | 146.42 MB/s | 221 MB |. | zlib-1 | 105.57 MB/s | 118.10 MB/s | 197 MB |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:100,performance,cpu,cpu,100,"Here is the results from ""event"" executable. | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 122.62 MB/s | 136.61 MB/s | 181 MB |. | lz4 | 127.57 MB/s | 146.42 MB/s | 221 MB |. | zlib-1 | 105.57 MB/s | 118.10 MB/s | 197 MB |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:104,performance,time,time,104,"Here is the results from ""event"" executable. | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 122.62 MB/s | 136.61 MB/s | 181 MB |. | lz4 | 127.57 MB/s | 146.42 MB/s | 221 MB |. | zlib-1 | 105.57 MB/s | 118.10 MB/s | 197 MB |.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:99,energy efficiency,cpu,cpu,99,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:58,modifiability,deco,decompression,58,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:85,modifiability,deco,decompression,85,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:480,modifiability,deco,decompressing,480,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:557,modifiability,deco,decompressed,557,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:77,performance,time,time,77,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:99,performance,cpu,cpu,99,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:103,performance,time,time,103,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:383,performance,time,time,383,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:522,performance,time,times,522,@bbockelm The CMS if I am not mistaken is . | Algorithm | decompression(real time) | decompression(cpu time) | Compressed File Size |. | --- | --- | --- | --- |. | zlib | 54.13 MB/s | 63.28 MB/s | 1.6 GB |. | lzma | 22.47 MB/s | 23.41 MB/s | 1.2 GB |. | lz4 | 56.36 MB/s | 66.06 MB/s | 1.8 GB |. | zlib-1 | 54.58 MB/s | 62.78 MB/s | 1.8 GB |. Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:140,availability,down,down,140,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:2,energy efficiency,measur,measured,2,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:415,energy efficiency,cpu,cpu,415,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:174,modifiability,deco,decompression,174,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:376,modifiability,deco,decompression,376,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:401,modifiability,deco,decompression,401,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:737,modifiability,deco,decompressing,737,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:814,modifiability,deco,decompressed,814,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:17,performance,time,times,17,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:91,performance,perform,performance,91,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:395,performance,time,time,395,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:415,performance,cpu,cpu,415,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:419,performance,time,time,419,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:638,performance,time,time,638,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:779,performance,time,times,779,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:91,usability,perform,performance,91,"I measured three times on each algorithms and wrote the averages in the table. I think the performance between zlib-6 and zlib-1 are up and down but quite similar in term of decompression. I could double check it later. . Sent from my iPhone. > On Oct 1, 2015, at 11:17, pcanal notifications@github.com wrote:. > . > @bbockelm The CMS if I am not mistaken is. > . > Algorithm decompression(real time) decompression(cpu time) Compressed File Size. > zlib 54.13 MB/s 63.28 MB/s 1.6 GB. > lzma 22.47 MB/s 23.41 MB/s 1.2 GB. > lz4 56.36 MB/s 66.06 MB/s 1.8 GB. > zlib-1 54.58 MB/s 62.78 MB/s 1.8 GB. > Where at same compression level the run-time gain is 5% (and even less compared to zlib-6) .... > hummm the numbers are odd .... zlib-6 is decompressing faster than zlib-1? Are the times divided by the compressed or decompressed size? > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:83,modifiability,deco,decompressed,83,One important question is to verify if the times divided by the compressed size or decompressed size.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:43,performance,time,times,43,One important question is to verify if the times divided by the compressed size or decompressed size.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:29,testability,verif,verify,29,One important question is to verify if the times divided by the compressed size or decompressed size.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:63,energy efficiency,CPU,CPU,63,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:143,energy efficiency,CPU,CPU,143,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:37,performance,Time,Time,37,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:63,performance,CPU,CPU,63,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:67,performance,Time,Time,67,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:121,performance,Time,Time,121,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:143,performance,CPU,CPU,143,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:147,performance,Time,Time,147,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:540,performance,time,times,540,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:991,performance,time,times,991,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1119,performance,cach,cache,1119,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:514,safety,test,tested,514,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:881,safety,test,test,881,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:951,safety,test,test,951,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:980,safety,test,test,980,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:514,testability,test,tested,514,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:881,testability,test,test,881,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:951,testability,test,test,951,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:980,testability,test,test,980,| Algorithm | ReadUZRT(Unzipped Real Time) | ReadUZCT(Unzipped CPU Time) | ReadUnzip(Unzipped Size) | ReadRT(Zipped Real Time) | ReadCT(Zipped CPU Time) | ReadTotal(Zipped Size) |. | --- | --- | --- | --- | --- | --- | --- |. | zlib | 55.22 MB/s | 60.46 MB/s | 6803.79 MB | 13.34 MB/s | 14.60 MB/s | 1643.17 MB |. | lz4 | 54.67 MB/s | 60.77 MB/s | 6803.26 MB | 15.01 MB/s | 16.68 MB/s | 1867.59 MB |. | zlib-1 | 52.64 MB/s | 58.43 MB/s | 6802.96 MB | 14.74 MB/s | 16.37 MB/s | 1905.55 MB |. Here are the results I tested. Again I run three times for each of the algorithms and interleave three algorithms in round-robin fashion.( zlib lz4 zlib-1 zlib lz4 zlib-1 zlib lz4 zlib-1). ReadUZ\* represents the speed of dividing uncompressed size and Read\* represents the speed of dividing compressed size. There is no obvious gap between lz4 and zlib. I tried to reproduce the previous test results. I guess the reason might be due to the sequence of each test? (previously I run each test three times and then switch to the next algorithm like zlib zlib zlib zlib-1 zlib-1 zlib-1 lz4 lz4 lz4). However I did clean the page cache before each run. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:209,energy efficiency,Measur,Measurements,209,"i see we have some overlap, i also worked a bit on compression algorithms for root [pseyfert/root-compression](https://github.com/pseyfert/root-compression). results come from an LHCb analyst-level root file. Measurements for a central production file are less advance: [plot](http://virgilio.mib.infn.it/~seyfert/productionfile.pdf).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:739,energy efficiency,profil,profiling,739,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:150,integrability,event,events,150,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:479,integrability,event,events,479,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:136,performance,time,time,136,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:578,performance,time,time,578,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:739,performance,profil,profiling,739,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:810,performance,overhead,overhead,810,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:840,performance,memor,memory,840,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:31,safety,test,test,31,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:587,safety,test,tests,587,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:639,safety,test,test,639,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1222,safety,test,test,1222,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:31,testability,test,test,31,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:587,testability,test,tests,587,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:639,testability,test,test,639,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1222,testability,test,test,1222,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:840,usability,memor,memory,840,"@zzxuanyuan I ran a production test job for 18 different compression settings - zlib from level 1 to 9 and lzma from level 1 to 9, each time the same events. Size is the size of the output file in Byte. I ran through valgrind/callgrind and the cycles are the number of cycles spent in the R__zipMultipleAlgorithm function (and functions called from there). The spike in the lzma curve is something i haven't understood yet I want to crosscheck it running over a different set of events (possibly more, though then it gets annoying in space requirements of the output and in the time the tests take). Not included in the numbers in neither test/summary.txt nor the plot is the RAM usage of a production job (just running tcmalloc with heap profiling and reporting the peak usage. this comes probably with large overhead because i report the memory usage of the full process, not only the compression). (was a different job than the one from which the filesize and cycle counts come). zlib:x 237 MB. lzma:1 239 MB. lzma:2 241 MB. lzma:3 262 MB. lzma:4 276 MB. lzma:5 322 MB. lzma:6 322 MB. lzma:7 411 MB. lzma:8 600 MB. lzma:9 904 MB. please also look at [this file](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt) for the analyst root file where i not only report numbers for writing, but also for reading (though it seems the last column seems buggy).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:18,usability,clear,clear,18,"@pseyfert - to be clear though, you're talking about a different algorithm, right? (LZMA versus LZ4).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:132,energy efficiency,measur,measure,132,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:164,energy efficiency,cpu,cpu,164,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:184,energy efficiency,clock,clock,184,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:229,energy efficiency,cpu,cpu,229,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:249,energy efficiency,clock,clock,249,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:350,energy efficiency,measur,measuring,350,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:384,energy efficiency,cpu,cpu,384,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:209,modifiability,deco,decompression,209,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:257,modifiability,deco,decompression,257,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:158,performance,time,time,158,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:164,performance,cpu,cpu,164,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:223,performance,time,time,223,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:229,performance,cpu,cpu,229,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:378,performance,time,time,378,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:384,performance,cpu,cpu,384,"well, in the linked file (refering to analysis ntuples) i have zlib, lzma, lzo, lz4, zopfli, brotli, for compression levels 1-9 and measure size, compression time (cpu cycles and wall clock), compression RAM, decompression time (cpu cycles and wall clock), decompression RAM. for production jobs i only have zlib and lzma for compression levels 1-9, measuring size, compression time (cpu cycles) and compression RAM.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:584,deployability,patch,patches,584,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:659,deployability,version,version,659,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:723,energy efficiency,cpu,cpu,723,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:447,integrability,interfac,interfaces,447,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:489,integrability,interfac,interfaces,489,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:659,integrability,version,version,659,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:447,interoperability,interfac,interfaces,447,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:489,interoperability,interfac,interfaces,489,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:447,modifiability,interfac,interfaces,447,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:489,modifiability,interfac,interfaces,489,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:659,modifiability,version,version,659,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:723,performance,cpu,cpu,723,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:744,performance,disk,disk,744,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:360,safety,test,test,360,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:584,safety,patch,patches,584,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:584,security,patch,patches,584,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:360,testability,test,test,360,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:614,usability,effectiv,effectively,614,"i don't have readable plots ready at the moment (with all the numbers i brute forced 2d plots for all combinations of benchmarks, and plotted in them 6 lines - one for each algorithm) the plots are then always dominated by the worst algorithm in each category. But you can read the numbers from. [here](https://github.com/pseyfert/root-compression/blob/master/test/summary.txt). row 2 (zlib-1) and rows 29-37 (lz4). NB: only the zopfli and brotli interfaces are from 2015, the lzo and lz4 interfaces are from 2011 and the lz4 backend is stuck in 2012. i've seen lz4 received upstream patches which i should merge, effectively the compression level in the old version is meaningless. we didn't follow up on lz4 back then as cpu seemed cheap and disk was rare, so we switched to lzma.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:147,deployability,version,version,147,"@pseyfert - would it be possible to share the file you used for this? Particularly, I'd be curious to see how the compression ratio looks with the version of LZ4 @zzxuanyuan is using. I note the entire process read time (which LZ4 is supposed to optimize) is 6% faster with LZ4. Is there any way to fix the last column?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:246,energy efficiency,optim,optimize,246,"@pseyfert - would it be possible to share the file you used for this? Particularly, I'd be curious to see how the compression ratio looks with the version of LZ4 @zzxuanyuan is using. I note the entire process read time (which LZ4 is supposed to optimize) is 6% faster with LZ4. Is there any way to fix the last column?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:147,integrability,version,version,147,"@pseyfert - would it be possible to share the file you used for this? Particularly, I'd be curious to see how the compression ratio looks with the version of LZ4 @zzxuanyuan is using. I note the entire process read time (which LZ4 is supposed to optimize) is 6% faster with LZ4. Is there any way to fix the last column?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:36,interoperability,share,share,36,"@pseyfert - would it be possible to share the file you used for this? Particularly, I'd be curious to see how the compression ratio looks with the version of LZ4 @zzxuanyuan is using. I note the entire process read time (which LZ4 is supposed to optimize) is 6% faster with LZ4. Is there any way to fix the last column?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:147,modifiability,version,version,147,"@pseyfert - would it be possible to share the file you used for this? Particularly, I'd be curious to see how the compression ratio looks with the version of LZ4 @zzxuanyuan is using. I note the entire process read time (which LZ4 is supposed to optimize) is 6% faster with LZ4. Is there any way to fix the last column?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:215,performance,time,time,215,"@pseyfert - would it be possible to share the file you used for this? Particularly, I'd be curious to see how the compression ratio looks with the version of LZ4 @zzxuanyuan is using. I note the entire process read time (which LZ4 is supposed to optimize) is 6% faster with LZ4. Is there any way to fix the last column?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:246,performance,optimiz,optimize,246,"@pseyfert - would it be possible to share the file you used for this? Particularly, I'd be curious to see how the compression ratio looks with the version of LZ4 @zzxuanyuan is using. I note the entire process read time (which LZ4 is supposed to optimize) is 6% faster with LZ4. Is there any way to fix the last column?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:84,energy efficiency,profil,profile,84,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:150,energy efficiency,profil,profile,150,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:235,energy efficiency,profil,profiles,235,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:369,integrability,pub,published,369,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:307,interoperability,share,share,307,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:589,interoperability,share,shared,589,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:84,performance,profil,profile,84,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:150,performance,profil,profile,150,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:235,performance,profil,profiles,235,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:624,performance,overhead,overhead,624,"Hi, okay I now understood what's wrong in the last column, my handwritten callgrind profile reader cannot handle when a function appears twice in the profile (of which I don't know right now what that means). Which means I'll read the profiles with kcachegrind and type the numbers by hand. I'm hesitant to share since it's real data on analysis level which is not yet published. I think it's less controversial if i take one of the ntuples which were used to generate the date for the kaggle challenge. since that data is already out in the wild. (will query my convenors for what can be shared without too much ""political overhead"").",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:254,availability,cluster,cluster,254,"last column is fixed now. as additional explanation:. i have two ntuples, one small one from the first round of benchmarks, and one larger one, where the benchmarks take much longer (also the small one fits my notebook, the large one is processed on the cluster). for zlib-1 and lz4 I report the callgrind reading cycles from both files, for all other settings I only report the values from the larger file. I don't think that matters much for the interpretation, you just cannot say ""decompression is x times faster than compression"". but you can say ""(de)compression with zlib is x times slower than (de)compression with lz4"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:590,availability,slo,slower,590,"last column is fixed now. as additional explanation:. i have two ntuples, one small one from the first round of benchmarks, and one larger one, where the benchmarks take much longer (also the small one fits my notebook, the large one is processed on the cluster). for zlib-1 and lz4 I report the callgrind reading cycles from both files, for all other settings I only report the values from the larger file. I don't think that matters much for the interpretation, you just cannot say ""decompression is x times faster than compression"". but you can say ""(de)compression with zlib is x times slower than (de)compression with lz4"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:254,deployability,cluster,cluster,254,"last column is fixed now. as additional explanation:. i have two ntuples, one small one from the first round of benchmarks, and one larger one, where the benchmarks take much longer (also the small one fits my notebook, the large one is processed on the cluster). for zlib-1 and lz4 I report the callgrind reading cycles from both files, for all other settings I only report the values from the larger file. I don't think that matters much for the interpretation, you just cannot say ""decompression is x times faster than compression"". but you can say ""(de)compression with zlib is x times slower than (de)compression with lz4"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:485,modifiability,deco,decompression,485,"last column is fixed now. as additional explanation:. i have two ntuples, one small one from the first round of benchmarks, and one larger one, where the benchmarks take much longer (also the small one fits my notebook, the large one is processed on the cluster). for zlib-1 and lz4 I report the callgrind reading cycles from both files, for all other settings I only report the values from the larger file. I don't think that matters much for the interpretation, you just cannot say ""decompression is x times faster than compression"". but you can say ""(de)compression with zlib is x times slower than (de)compression with lz4"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:504,performance,time,times,504,"last column is fixed now. as additional explanation:. i have two ntuples, one small one from the first round of benchmarks, and one larger one, where the benchmarks take much longer (also the small one fits my notebook, the large one is processed on the cluster). for zlib-1 and lz4 I report the callgrind reading cycles from both files, for all other settings I only report the values from the larger file. I don't think that matters much for the interpretation, you just cannot say ""decompression is x times faster than compression"". but you can say ""(de)compression with zlib is x times slower than (de)compression with lz4"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:584,performance,time,times,584,"last column is fixed now. as additional explanation:. i have two ntuples, one small one from the first round of benchmarks, and one larger one, where the benchmarks take much longer (also the small one fits my notebook, the large one is processed on the cluster). for zlib-1 and lz4 I report the callgrind reading cycles from both files, for all other settings I only report the values from the larger file. I don't think that matters much for the interpretation, you just cannot say ""decompression is x times faster than compression"". but you can say ""(de)compression with zlib is x times slower than (de)compression with lz4"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:590,reliability,slo,slower,590,"last column is fixed now. as additional explanation:. i have two ntuples, one small one from the first round of benchmarks, and one larger one, where the benchmarks take much longer (also the small one fits my notebook, the large one is processed on the cluster). for zlib-1 and lz4 I report the callgrind reading cycles from both files, for all other settings I only report the values from the larger file. I don't think that matters much for the interpretation, you just cannot say ""decompression is x times faster than compression"". but you can say ""(de)compression with zlib is x times slower than (de)compression with lz4"".",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:24,deployability,updat,update,24,"@pcanal - From the last update of @pseyfert (see https://github.com/pseyfert/root-compression/blob/master/test/summary.txt), the LZ4 read speed was 7.2X faster versus zlib-1. As I suspected, we're hitting the fact that decompression speed is not a huge part of the overall read workflow. Hence, I think the impact here is going to be more noticeable as we increase deserialization speed. @pseyfert - if it's not possible to post the file, could you rebuild your ROOT with the `LZ4-HC` algorithm that @zzxuanyuan used in this PR and then check the filesize? I want to see how `LZ4-HC`'s compression ratio compares with ZLIB-1 for this case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:219,modifiability,deco,decompression,219,"@pcanal - From the last update of @pseyfert (see https://github.com/pseyfert/root-compression/blob/master/test/summary.txt), the LZ4 read speed was 7.2X faster versus zlib-1. As I suspected, we're hitting the fact that decompression speed is not a huge part of the overall read workflow. Hence, I think the impact here is going to be more noticeable as we increase deserialization speed. @pseyfert - if it's not possible to post the file, could you rebuild your ROOT with the `LZ4-HC` algorithm that @zzxuanyuan used in this PR and then check the filesize? I want to see how `LZ4-HC`'s compression ratio compares with ZLIB-1 for this case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:24,safety,updat,update,24,"@pcanal - From the last update of @pseyfert (see https://github.com/pseyfert/root-compression/blob/master/test/summary.txt), the LZ4 read speed was 7.2X faster versus zlib-1. As I suspected, we're hitting the fact that decompression speed is not a huge part of the overall read workflow. Hence, I think the impact here is going to be more noticeable as we increase deserialization speed. @pseyfert - if it's not possible to post the file, could you rebuild your ROOT with the `LZ4-HC` algorithm that @zzxuanyuan used in this PR and then check the filesize? I want to see how `LZ4-HC`'s compression ratio compares with ZLIB-1 for this case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:106,safety,test,test,106,"@pcanal - From the last update of @pseyfert (see https://github.com/pseyfert/root-compression/blob/master/test/summary.txt), the LZ4 read speed was 7.2X faster versus zlib-1. As I suspected, we're hitting the fact that decompression speed is not a huge part of the overall read workflow. Hence, I think the impact here is going to be more noticeable as we increase deserialization speed. @pseyfert - if it's not possible to post the file, could you rebuild your ROOT with the `LZ4-HC` algorithm that @zzxuanyuan used in this PR and then check the filesize? I want to see how `LZ4-HC`'s compression ratio compares with ZLIB-1 for this case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:24,security,updat,update,24,"@pcanal - From the last update of @pseyfert (see https://github.com/pseyfert/root-compression/blob/master/test/summary.txt), the LZ4 read speed was 7.2X faster versus zlib-1. As I suspected, we're hitting the fact that decompression speed is not a huge part of the overall read workflow. Hence, I think the impact here is going to be more noticeable as we increase deserialization speed. @pseyfert - if it's not possible to post the file, could you rebuild your ROOT with the `LZ4-HC` algorithm that @zzxuanyuan used in this PR and then check the filesize? I want to see how `LZ4-HC`'s compression ratio compares with ZLIB-1 for this case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:106,testability,test,test,106,"@pcanal - From the last update of @pseyfert (see https://github.com/pseyfert/root-compression/blob/master/test/summary.txt), the LZ4 read speed was 7.2X faster versus zlib-1. As I suspected, we're hitting the fact that decompression speed is not a huge part of the overall read workflow. Hence, I think the impact here is going to be more noticeable as we increase deserialization speed. @pseyfert - if it's not possible to post the file, could you rebuild your ROOT with the `LZ4-HC` algorithm that @zzxuanyuan used in this PR and then check the filesize? I want to see how `LZ4-HC`'s compression ratio compares with ZLIB-1 for this case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:278,usability,workflow,workflow,278,"@pcanal - From the last update of @pseyfert (see https://github.com/pseyfert/root-compression/blob/master/test/summary.txt), the LZ4 read speed was 7.2X faster versus zlib-1. As I suspected, we're hitting the fact that decompression speed is not a huge part of the overall read workflow. Hence, I think the impact here is going to be more noticeable as we increase deserialization speed. @pseyfert - if it's not possible to post the file, could you rebuild your ROOT with the `LZ4-HC` algorithm that @zzxuanyuan used in this PR and then check the filesize? I want to see how `LZ4-HC`'s compression ratio compares with ZLIB-1 for this case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:68,deployability,updat,update,68,@zzxuanyuan - I noticed that merge conflicts have snuck in. Can you update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:35,interoperability,conflict,conflicts,35,@zzxuanyuan - I noticed that merge conflicts have snuck in. Can you update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:68,safety,updat,update,68,@zzxuanyuan - I noticed that merge conflicts have snuck in. Can you update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:68,security,updat,update,68,@zzxuanyuan - I noticed that merge conflicts have snuck in. Can you update the branch?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:33,deployability,version,version,33,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:290,deployability,build,build,290,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:581,energy efficiency,measur,measure,581,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1380,energy efficiency,cpu,cpu,1380,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:33,integrability,version,version,33,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:33,modifiability,version,version,33,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:717,performance,memor,memory,717,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:762,performance,memor,memory,762,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:798,performance,memor,memory,798,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1380,performance,cpu,cpu,1380,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1581,performance,time,time,1581,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1586,safety,test,tests,1586,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1586,testability,test,tests,1586,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:717,usability,memor,memory,717,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:762,usability,memor,memory,762,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:798,usability,memor,memory,798,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:1609,usability,prefer,prefer,1609,"I successfully ran @zzxuanyuan's version but got benchmarks far from mine, so I got suspicious if I'm seing effects of something else that changed in ROOT (or possibly me having changed the compile options with which I compile ROOT). So I also reran my implementation in @zzxuanyuan's ROOT build (since I use LD_PRELOAD I can override @zzxuanyuan's compression while keeping the entire rest of ROOT). If you compare these new numbers with the previous ones I posted, the RAM consumption went up in general, but it's the same for my implementation and @zzxuanyuan's. I anyhow don't measure the RAM consumption for individual functions and at some point concluded that this is dominated by holding the root file in the memory. | alg -level | compressed size (B) | memory reading (peak, process, B) | memory writing (peak, process, B) | cycles writing (function) | cycles reading (function) |. | --- | --: | --: | --: | --: | --: |. | ZLIB yours | 50704058.000000 | 330447558.000000 | 374567259.000000 | 255700352.000000 | 2443672496 |. | LZ4 yours | 69861890.000000 | 357286997.000000 | 374567259.000000 | 188653871.000000 | 1006741856 |. | ZLIB mine | 50704058.000000 | 327875161.000000 | 371586581.000000 | 255702351.000000 | 2443713877 |. | LZ4 mine | 69874907.000000 | 354320671.000000 | 371586581.000000 | 28579724.000000 | 275698694 |. Seems my implementation takes much less cpu cycles. Since there's not much code in the actual R__zip method, my guess is that this comes from the fact that I use `LZ4_compress` while you use `LZ4_compress_limitedOutput`? I left out the real time tests as for these i'd prefer the computer ""undisturbed"" which it isn't at the moment.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:518,availability,state,state,518,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:0,deployability,updat,update,0,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:19,deployability,build,building,19,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:267,deployability,fail,fails,267,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:420,deployability,updat,update,420,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:476,deployability,updat,updated,476,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:578,deployability,updat,update,578,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:454,integrability,configur,configure,454,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:518,integrability,state,state,518,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:454,modifiability,configur,configure,454,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:267,reliability,fail,fails,267,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:0,safety,updat,update,0,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:285,safety,test,tests,285,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:420,safety,updat,update,420,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:476,safety,updat,updated,476,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:578,safety,updat,update,578,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:0,security,updat,update,0,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:276,security,checksum,checksum,276,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:420,security,updat,update,420,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:454,security,configur,configure,454,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:476,security,updat,updated,476,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:578,security,updat,update,578,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:285,testability,test,tests,285,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:344,usability,document,documentation,344,update: instead of building a preload library I now ported [my changes](https://github.com/pseyfert/root-compression) into root itself [here](https://github.com/pseyfert/root/tree/master_compressions). There are still items on the todo list:. - using an external LZ4 fails. - checksum tests are skipped. - compiler warnings should get fixed. - documentation and attribution (I looked at your PR as an instruction how to update the CMakeLists files). - ./configure scripts not updated. - license issue (at the moment i state in the description that the changes require GPLv3). - update/run benchmarks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/81:22,usability,close,close,22,@zzxuanyuan - can you close this PR as the functionality got merged elsewhere?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/81
https://github.com/root-project/root/pull/82:48,interoperability,platform,platform-agnostic,48,"Not for now, code changes were only made in the platform-agnostic part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/82
https://github.com/root-project/root/pull/84:41,safety,input,inputStream,41,"@pcanal In the function ""GetNewlineValue(inputStream)"", it is trying to call tellg() and seekg() functions to read the first line of the .csv file and make sure the stream goes back to the beginning position at the end of ""GetNewlineValue(inputStream)"". For stringstream and fstream, I can see the position of stream ""inPos"" increments as the characters read in. But cin always sets ""inPos"" as -1.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:239,safety,input,inputStream,239,"@pcanal In the function ""GetNewlineValue(inputStream)"", it is trying to call tellg() and seekg() functions to read the first line of the .csv file and make sure the stream goes back to the beginning position at the end of ""GetNewlineValue(inputStream)"". For stringstream and fstream, I can see the position of stream ""inPos"" increments as the characters read in. But cin always sets ""inPos"" as -1.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:41,usability,input,inputStream,41,"@pcanal In the function ""GetNewlineValue(inputStream)"", it is trying to call tellg() and seekg() functions to read the first line of the .csv file and make sure the stream goes back to the beginning position at the end of ""GetNewlineValue(inputStream)"". For stringstream and fstream, I can see the position of stream ""inPos"" increments as the characters read in. But cin always sets ""inPos"" as -1.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:239,usability,input,inputStream,239,"@pcanal In the function ""GetNewlineValue(inputStream)"", it is trying to call tellg() and seekg() functions to read the first line of the .csv file and make sure the stream goes back to the beginning position at the end of ""GetNewlineValue(inputStream)"". For stringstream and fstream, I can see the position of stream ""inPos"" increments as the characters read in. But cin always sets ""inPos"" as -1.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:74,availability,error,error,74,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:184,availability,error,error,184,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:147,deployability,Fail,FailBit,147,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:74,performance,error,error,74,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:184,performance,error,error,184,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:147,reliability,Fail,FailBit,147,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:6,safety,input,inputStream,6,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:74,safety,error,error,74,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:158,safety,input,inputStream,158,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:184,safety,error,error,184,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:6,usability,input,inputStream,6,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:74,usability,error,error,74,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:158,usability,input,inputStream,158,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:184,usability,error,error,184,"Edit: inputStream.seekg(inPos) in GetNewlineValue() function the location error happened. Since cin always set inPos as -1, this function will set FailBit in inputStream and cause the error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:35,safety,detect,detection,35,The question I have is whether the detection of the case where we need to use the fallback solution can be improve (comparing to std::cin address might not be sufficient (and might sometimes but a false positive).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:35,security,detect,detection,35,The question I have is whether the detection of the case where we need to use the fallback solution can be improve (comparing to std::cin address might not be sufficient (and might sometimes but a false positive).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:50,safety,detect,detecting,50,"Did you get a change to analyze my question about detecting the case where we need to use a fallback? Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:50,security,detect,detecting,50,"Did you get a change to analyze my question about detecting the case where we need to use a fallback? Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:458,availability,failur,failure,458,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:458,deployability,fail,failure,458,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:787,integrability,buffer,buffer,787,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:885,integrability,buffer,buffer,885,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:1004,integrability,buffer,buffer,1004,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:458,performance,failur,failure,458,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:730,performance,memor,memory,730,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:780,performance,memor,memory,780,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:997,performance,memor,memory,997,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:458,reliability,fail,failure,458,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:1027,reliability,Doe,Does,1027,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:238,safety,input,input,238,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:283,safety,input,input,283,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:30,testability,understand,understand,30,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:238,usability,input,input,238,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:283,usability,input,input,283,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:730,usability,memor,memory,730,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:780,usability,memor,memory,780,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:997,usability,memor,memory,997,"Philippe,. I am not sure if I understand ""fallback"" correctly. But I tried two different experiments and get more solid analysis:. 1. I run ""TString::ReadFile(std::istream& strm)"" function in Stringio.cxx and parse a file (ifstream) as a input, it works fine. If I parse std::cin as input, it has the same problem as ROOT-7588 described. The reason is because in the function it uses ""strm.tellg()"" to manipulate the std::cin, which always return -1 and set failure flag. 2. I run ""TString::ReadLine(std::istream& strm, Bool_t skipWhite)"" and ""TString::ReadString(std::istream& strm)"" in Stringio.cxx. I re-run the same kind of experiments as ROOT-7588. It works fine. These functions internally call ReadToDelim() which reserves memory for TString and read std::cin into TString memory buffer. I think this implementation is a smoother way rather than creating a temporary sstream to buffer std::cin. Anyway, I think we can either create a sstream to hold std::cin or find a new way to reserve a memory buffer for std::cin. . Does this answer the question of fallback you mentioned? Regards,. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:9,deployability,patch,patch,9,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:15,deployability,contain,contains,15,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:9,safety,patch,patch,9,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:39,safety,input,inputStream,39,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:91,safety,test,test,91,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:147,safety,test,test,147,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:187,safety,input,inputStream,187,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:9,security,patch,patch,9,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:91,testability,test,test,91,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:147,testability,test,test,147,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:39,usability,input,inputStream,39,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:187,usability,input,inputStream,187,"Hi,. The patch contains. ``` c++. if (&inputStream == &std::cin) {. ```. where rather than test on the address of std::cin, I wonder if there is a test we can make on the seek ability of inputStream. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:35,safety,test,test,35,That looks right to me. Is there a test written for this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:35,testability,test,test,35,That looks right to me. Is there a test written for this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:39,deployability,patch,patch,39,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:436,deployability,DEPEND,DEPENDS,436,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:232,energy efficiency,Core,Core,232,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:436,integrability,DEPEND,DEPENDS,436,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:436,modifiability,DEPEND,DEPENDS,436,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:39,safety,patch,patch,39,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:154,safety,test,test,154,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:409,safety,test,test,409,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:426,safety,test,test,426,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:436,safety,DEPEND,DEPENDS,436,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:558,safety,test,test,558,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:652,safety,test,test,652,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:698,safety,test,test,698,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:755,safety,test,test,755,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:39,security,patch,patch,39,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:154,testability,test,test,154,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:409,testability,test,test,409,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:426,testability,test,test,426,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:436,testability,DEPEND,DEPENDS,436,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:558,testability,test,test,558,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:652,testability,test,test,652,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:698,testability,test,test,698,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:755,testability,test,test,755,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:389,usability,COMMAND,COMMAND,389,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:529,usability,COMMAND,COMMAND,529,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:719,usability,command,command,719,"@pcanal I am writing roottest for this patch. . ```. SET(THESCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/parseCin.sh). SET(THEINPUTFILE ${CMAKE_CURRENT_SOURCE_DIR}/test.csv). ROOTTEST_GENERATE_EXECUTABLE(readFromCin readFromCin.cxx LIBRARIES Core Hist RIO Net Graf Graf3d Gpad Tree Rint Postscript Matrix Physics MathCore Thread MultiProc). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-readFromCin. COMMAND readFromCin test.csv. OUTREF test.ref. DEPENDS ${GENERATE_EXECUTABLE_TEST}). ROOTTEST_ADD_TEST(roottest-root-tree-readcin-parseCin. COMMAND ${THESCRIPT}. OUTREF test.ref ). ROOTTEST_ADD_TESTDIRS(). ```. where parseCin.sh is one line bash script. ```. cat test.csv | ./readFromCin. ```. When I run the test case, these two command always generate empty file. test.csv never been parsed in as an argument. How should I parse a argument? I tried MACRO_ARGS but that did not work. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:85,safety,review,review,85,"Hi Zhe,. Were you able to post the roottest branch to your github account so I could review your issue? Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:85,testability,review,review,85,"Hi Zhe,. Were you able to post the roottest branch to your github account so I could review your issue? Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:325,safety,review,review,325,"Sure. I was compiling the roottest directly within root. I will try to reproduce my issue with standalone roottest and upload repo to my github. Zhe. > On Jan 24, 2016, at 20:08, Brian Bockelman notifications@github.com wrote:. > . > Hi Zhe,. > . > Were you able to post the roottest branch to your github account so I could review your issue? > . > Brian. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:325,testability,review,review,325,"Sure. I was compiling the roottest directly within root. I will try to reproduce my issue with standalone roottest and upload repo to my github. Zhe. > On Jan 24, 2016, at 20:08, Brian Bockelman notifications@github.com wrote:. > . > Hi Zhe,. > . > Were you able to post the roottest branch to your github account so I could review your issue? > . > Brian. > . > —. > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:121,availability,down,downloading,121,To do that - simply checkout roottest into the `root` source directory. The build directory will utilize that instead of downloading its own copy.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:76,deployability,build,build,76,To do that - simply checkout roottest into the `root` source directory. The build directory will utilize that instead of downloading its own copy.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:13,testability,simpl,simply,13,To do that - simply checkout roottest into the `root` source directory. The build directory will utilize that instead of downloading its own copy.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:13,usability,simpl,simply,13,To do that - simply checkout roottest into the `root` source directory. The build directory will utilize that instead of downloading its own copy.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:84,safety,review,review,84,@pcanal - any chance to get an official mirror of roottest? It's somewhat a PITA to review contributions otherwise...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:84,testability,review,review,84,@pcanal - any chance to get an official mirror of roottest? It's somewhat a PITA to review contributions otherwise...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:264,energy efficiency,current,current,264,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:12,safety,accid,accidentally,12,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:243,safety,test,test,243,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:272,safety,test,test,272,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:238,testability,unit,unit,238,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:243,testability,test,test,243,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:272,testability,test,test,272,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:277,testability,simpl,simply,277,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:277,usability,simpl,simply,277,@bbockelm I accidentally deleted my previous work last night. But good news is I figured out the issue I was facing when I try to reproduce my work today. Now everything is working. I uploaded roottest repo in my github and generated the unit test as a commit. My current test simply follows the sample code in https://sft.its.cern.ch/jira/browse/ROOT-7588. Let me know if something is not correct.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:75,safety,test,test,75,Sounds good! If we're happy with the approach now and have a corresponding test ... are we ready to get this merged? @pcanal - any unaddressed issues in the ticket history?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/84:75,testability,test,test,75,Sounds good! If we're happy with the approach now and have a corresponding test ... are we ready to get this merged? @pcanal - any unaddressed issues in the ticket history?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/84
https://github.com/root-project/root/pull/85:65,safety,test,test,65,Not sure about the rationale here but could you rebase and add a test case for this functionality?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/85:65,testability,test,test,65,Not sure about the rationale here but could you rebase and add a test case for this functionality?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/85:24,usability,close,close,24,"@Axel-Naumann, shall we close this due to inactivity?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/85:24,usability,close,close,24,@Axel-Naumann should we close this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/85:7,safety,risk,risk,7,At the risk of being repetitive :grin: @Axel-Naumann can we close this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/85:7,security,risk,risk,7,At the risk of being repetitive :grin: @Axel-Naumann can we close this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/85:60,usability,close,close,60,At the risk of being repetitive :grin: @Axel-Naumann can we close this one?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/85:6,usability,close,close,6,"Let's close - we keep the code in this PR, but for now there has not been a lot of demand for the feature :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/85
https://github.com/root-project/root/pull/87:180,availability,restor,restore,180,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/87:213,deployability,build,build,213,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/87:240,deployability,patch,patches,240,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/87:196,interoperability,compatib,compatibility,196,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/87:219,performance,time,time,219,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/87:180,reliability,restor,restore,180,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/87:240,safety,patch,patches,240,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/87:240,security,patch,patches,240,"Hi Daniela,. thanks for the pr. I backported the two scripts coming from the master. https://root.cern.ch/gitweb?p=root.git;a=commit;h=140192cbaa5ebadf0c172fe6cf362955ddb00ee1. to restore Python3 compatibility at build time for the 6-04-00-patches branch. Cheers,. Danilo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/87
https://github.com/root-project/root/pull/88:20,deployability,patch,patch,20,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:56,integrability,repositor,repository,56,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:124,integrability,coupl,couple,124,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:56,interoperability,repositor,repository,56,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:134,interoperability,conflict,conflicts,134,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:124,modifiability,coupl,couple,124,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:20,safety,patch,patch,20,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:20,security,patch,patch,20,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:83,security,modif,modifications,83,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/88:124,testability,coupl,couple,124,"Hi,. Thanks for the patch. I have merged it in the main repository with some small modifications,. essentially to resolve a couple of conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/88
https://github.com/root-project/root/pull/90:41,deployability,version,version,41,"Hello,. I have tried to take your latest version of fontembedps.cxx, but for me it does not compile. Can you send me a diff against the ROOT master ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:41,integrability,version,version,41,"Hello,. I have tried to take your latest version of fontembedps.cxx, but for me it does not compile. Can you send me a diff against the ROOT master ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:41,modifiability,version,version,41,"Hello,. I have tried to take your latest version of fontembedps.cxx, but for me it does not compile. Can you send me a diff against the ROOT master ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:83,reliability,doe,does,83,"Hello,. I have tried to take your latest version of fontembedps.cxx, but for me it does not compile. Can you send me a diff against the ROOT master ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:198,availability,error,errors,198,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:121,deployability,patch,patches,121,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:83,integrability,configur,configure,83,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:83,modifiability,configur,configure,83,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:198,performance,error,errors,198,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:121,safety,patch,patches,121,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:198,safety,error,errors,198,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:83,security,configur,configure,83,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:121,security,patch,patches,121,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:198,usability,error,errors,198,"If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). What errors do you get?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:30,availability,error,errors,30,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:493,availability,error,errors,493,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:414,deployability,patch,patches,414,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:376,integrability,configur,configure,376,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:376,modifiability,configur,configure,376,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:30,performance,error,errors,30,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:493,performance,error,errors,493,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:30,safety,error,errors,30,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:414,safety,patch,patches,414,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:493,safety,error,errors,493,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:165,security,modif,modified,165,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:376,security,configur,configure,376,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:414,security,patch,patches,414,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:30,usability,error,errors,30,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:493,usability,error,errors,493,"I am using cmake and get some errors (I cannot retry now because I am busy with something else). May be I did some mistake applying the changes. Can you send me the modified file ? it is quite small …. Thanks. Olivier. > On 21 Sep 2015, at 17:05, ellert notifications@github.com wrote:. > . > If I check out the master and apply the changes from this pull request, then doing configure and make (without any other patches applied) works for me (Fedora 22, gcc-c++-5.1.1-4.fc22.x86_64). > What errors do you get? > . > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/90#issuecomment-142009345.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:39,interoperability,conflict,conflicts,39,"This branch should still merge without conflicts, so I don't know what went wrong. Anyway - here is the complete file. (I had to add .txt to the filename since attachments with .cxx extensions were not allowed.). [fontembedps.cxx.txt](https://github.com/root-mirror/root/files/83592/fontembedps.cxx.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:182,modifiability,extens,extensions,182,"This branch should still merge without conflicts, so I don't know what went wrong. Anyway - here is the complete file. (I had to add .txt to the filename since attachments with .cxx extensions were not allowed.). [fontembedps.cxx.txt](https://github.com/root-mirror/root/files/83592/fontembedps.cxx.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:104,safety,compl,complete,104,"This branch should still merge without conflicts, so I don't know what went wrong. Anyway - here is the complete file. (I had to add .txt to the filename since attachments with .cxx extensions were not allowed.). [fontembedps.cxx.txt](https://github.com/root-mirror/root/files/83592/fontembedps.cxx.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:104,security,compl,complete,104,"This branch should still merge without conflicts, so I don't know what went wrong. Anyway - here is the complete file. (I had to add .txt to the filename since attachments with .cxx extensions were not allowed.). [fontembedps.cxx.txt](https://github.com/root-mirror/root/files/83592/fontembedps.cxx.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:5,deployability,version,version,5,This version of fontembedps.cxx is now in the master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:5,integrability,version,version,5,This version of fontembedps.cxx is now in the master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/90:5,modifiability,version,version,5,This version of fontembedps.cxx is now in the master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/90
https://github.com/root-project/root/pull/93:48,deployability,Patch,Patch,48,Oups. You are correct. Sorry for the confusion. Patch pushed to the repository.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/93
https://github.com/root-project/root/pull/93:68,integrability,repositor,repository,68,Oups. You are correct. Sorry for the confusion. Patch pushed to the repository.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/93
https://github.com/root-project/root/pull/93:68,interoperability,repositor,repository,68,Oups. You are correct. Sorry for the confusion. Patch pushed to the repository.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/93
https://github.com/root-project/root/pull/93:48,safety,Patch,Patch,48,Oups. You are correct. Sorry for the confusion. Patch pushed to the repository.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/93
https://github.com/root-project/root/pull/93:48,security,Patch,Patch,48,Oups. You are correct. Sorry for the confusion. Patch pushed to the repository.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/93
https://github.com/root-project/root/pull/94:337,deployability,API,API,337,"> Kind of major change: HDFS URLs are now absolute. Is this change necessary? Main reasons to ask are. a) it is somewhat backward incompatible (however I have no idea how many user might be relying on this). b) without it, the user can still decide to use absolute path to have the ""could be used interchangeably between ROOT and Hadoop API "" part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:337,integrability,API,API,337,"> Kind of major change: HDFS URLs are now absolute. Is this change necessary? Main reasons to ask are. a) it is somewhat backward incompatible (however I have no idea how many user might be relying on this). b) without it, the user can still decide to use absolute path to have the ""could be used interchangeably between ROOT and Hadoop API "" part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:130,interoperability,incompatib,incompatible,130,"> Kind of major change: HDFS URLs are now absolute. Is this change necessary? Main reasons to ask are. a) it is somewhat backward incompatible (however I have no idea how many user might be relying on this). b) without it, the user can still decide to use absolute path to have the ""could be used interchangeably between ROOT and Hadoop API "" part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:337,interoperability,API,API,337,"> Kind of major change: HDFS URLs are now absolute. Is this change necessary? Main reasons to ask are. a) it is somewhat backward incompatible (however I have no idea how many user might be relying on this). b) without it, the user can still decide to use absolute path to have the ""could be used interchangeably between ROOT and Hadoop API "" part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:176,usability,user,user,176,"> Kind of major change: HDFS URLs are now absolute. Is this change necessary? Main reasons to ask are. a) it is somewhat backward incompatible (however I have no idea how many user might be relying on this). b) without it, the user can still decide to use absolute path to have the ""could be used interchangeably between ROOT and Hadoop API "" part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:227,usability,user,user,227,"> Kind of major change: HDFS URLs are now absolute. Is this change necessary? Main reasons to ask are. a) it is somewhat backward incompatible (however I have no idea how many user might be relying on this). b) without it, the user can still decide to use absolute path to have the ""could be used interchangeably between ROOT and Hadoop API "" part.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:185,availability,sla,slash,185,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:387,availability,sla,slash,387,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:570,availability,sla,slashes,570,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:458,energy efficiency,current,current,458,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:59,interoperability,specif,specify,59,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:634,interoperability,compatib,compatibility,634,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:656,modifiability,exten,extent,656,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:185,reliability,sla,slash,185,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:387,reliability,sla,slash,387,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:570,reliability,sla,slashes,570,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:46,usability,user,user,46,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:145,usability,user,user,145,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:150,usability,user,username,150,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:206,usability,person,personally,206,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:517,usability,user,user,517,"Well, it isn't necessary. Without this change user have to specify the absolute path by adding one more / in front of it. E.g. hdfs://host:port//user/username/dir/file. (note the extra slash after host). I personally think that's kind of weird. Anyway, the problem is that there is no way (to my knowledge) to point to relative path in Hadoop using hdfs:// prefix. So Hadoop uses single slash to point to absolute url. This URL will be parsed incorrectly by current THDFSFile by assuming that the path is relative to user directory. The absolute URLs with extra leading slashes are, however, correctly parsed by Hadoop. So there is a compatibility to some extent.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:30,safety,review,review,30,@smithdh Would you be able to review (and rebase) this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:30,testability,review,review,30,@smithdh Would you be able to review (and rebase) this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:9,availability,ping,ping,9,@smithdh ping...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:55,modifiability,maintain,maintainers,55,"Hello @evgeny-boger Could you select ""allow edits from maintainers"" for this PR (I think this may not be set at the moment), so that I can rebase? Thank you, David",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:55,safety,maintain,maintainers,55,"Hello @evgeny-boger Could you select ""allow edits from maintainers"" for this PR (I think this may not be set at the moment), so that I can rebase? Thank you, David",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:11,deployability,build,build,11,@phsft-bot build! @smithdh and @evgeny-boger thanks rebasing! Could you fix the clang-format issues?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:86,interoperability,format,format,86,@phsft-bot build! @smithdh and @evgeny-boger thanks rebasing! Could you fix the clang-format issues?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/94:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/94
https://github.com/root-project/root/pull/97:236,deployability,version,version,236,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:318,deployability,version,version,318,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:236,integrability,version,version,236,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:318,integrability,version,version,318,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:103,interoperability,Specif,Specifically,103,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:236,modifiability,version,version,236,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:318,modifiability,version,version,318,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:148,performance,time,timeout,148,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:148,safety,timeout,timeout,148,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:160,safety,Avoid,Avoid,160,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:363,safety,safe,safe,363,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:356,security,sign,signal,356,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:229,usability,custom,custom,229,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:299,usability,document,documentation,299,"Hi Zhe,. You may also want to pull in the work done here:. https://github.com/cms-sw/cmssw/pull/11662. Specifically,. a) Allow the read function to timeout. b) Avoid use of execv on Linux. CERN uses LD_PRELOAD tricks to insert a custom version of this function into the executable. Unlike the POSIX documentation, the version of execv at CERN is not async signal safe. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:56,deployability,patch,patch,56,"Hi Philippe,. @pcanal Could you take a look at this new patch? Is there any test cases I can run with? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:56,safety,patch,patch,56,"Hi Philippe,. @pcanal Could you take a look at this new patch? Is there any test cases I can run with? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:76,safety,test,test,76,"Hi Philippe,. @pcanal Could you take a look at this new patch? Is there any test cases I can run with? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:56,security,patch,patch,56,"Hi Philippe,. @pcanal Could you take a look at this new patch? Is there any test cases I can run with? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:76,testability,test,test,76,"Hi Philippe,. @pcanal Could you take a look at this new patch? Is there any test cases I can run with? Thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:46,interoperability,specif,specifically,46,> Is there any test cases I can run with? Not specifically. Some of the code would be exercised by calling ::Fatal( ... ).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:15,safety,test,test,15,> Is there any test cases I can run with? Not specifically. Some of the code would be exercised by calling ::Fatal( ... ).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:15,testability,test,test,15,> Is there any test cases I can run with? Not specifically. Some of the code would be exercised by calling ::Fatal( ... ).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:104,deployability,updat,update,104,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:168,deployability,version,version,168,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:168,integrability,version,version,168,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:168,modifiability,version,version,168,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:33,safety,test,testing,33,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:59,safety,test,test,59,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:104,safety,updat,update,104,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:104,security,updat,update,104,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:33,testability,test,testing,33,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:59,testability,test,test,59,"Hi,. What was the result of your testing? Did you create a test we can add to roottest? Did you already update to follow the coding conventions? (I do not see an newer version so I commented on what I see). Thanks,. Philippe. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:106,integrability,sub,sub,106,"Since all the signal handling and processing is essentially standalone, could be move it all in a single (sub)class? Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:14,security,sign,signal,14,"Since all the signal handling and processing is essentially standalone, could be move it all in a single (sub)class? Thanks,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:143,modifiability,refact,refactor,143,"Hi Philippe,. Talked with Zhe about this yesterday; now that the end-of-semester rush is over, he's coming back to this item. We're working to refactor this to a new class. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:143,performance,refactor,refactor,143,"Hi Philippe,. Talked with Zhe about this yesterday; now that the end-of-semester rush is over, he's coming back to this item. We're working to refactor this to a new class. Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:49,modifiability,refact,refactoring,49,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:49,performance,refactor,refactoring,49,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:96,security,sign,signal,96,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:175,security,modif,modify,175,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:223,security,Sign,SignalHandling,223,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:346,security,sign,signal,346,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:431,security,Sign,SignalHandling,431,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:490,usability,clear,clear,490,"@pcanal @bbockelm I think there are two possible refactoring approaches. 1. I could extract all signal handling related functions and attributes out from TSystem(.h,.cxx) and modify both TUnixSystem and TWinNT. 2. I create SignalHandling class in another class and add it as an class member in TUnixSystem. In that sense, I need to overwrite all signal handling functions and point them to the corresponding functions in new class SignalHandling. Which one is better? The first one is more clear to me but I am not sure how it will impact the windows machine. Zhe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:116,modifiability,refact,refactoring,116,"I meant a variation of 1, where TSystem calls directly the extracted methods (i.e. essentially this should just be 'refactoring'). Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:116,performance,refactor,refactoring,116,"I meant a variation of 1, where TSystem calls directly the extracted methods (i.e. essentially this should just be 'refactoring'). Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:42,modifiability,concern,concern,42,Sure. It makes more sense to me. The only concern I have is how much side effect it will introduce to windows. I just ignore it from now?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:42,testability,concern,concern,42,Sure. It makes more sense to me. The only concern I have is how much side effect it will introduce to windows. I just ignore it from now?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/97:72,usability,close,close,72,"@zzxuanyuan - since this appears to be replaced by #134, can you please close this request?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/97
https://github.com/root-project/root/pull/98:719,deployability,Patch,Patch,719,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:783,deployability,patch,patch,783,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:833,deployability,patch,patch,833,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:626,energy efficiency,core,core,626,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:294,performance,time,time,294,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:148,safety,compl,complete,148,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:302,safety,avoid,avoiding,302,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:719,safety,Patch,Patch,719,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:783,safety,patch,patch,783,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:833,safety,patch,patch,833,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:148,security,compl,complete,148,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:719,security,Patch,Patch,719,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:783,security,patch,patch,783,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:833,security,patch,patch,833,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:232,usability,document,documentation,232,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/98:587,usability,document,documentation,587,"Done. > On 06 Oct 2015, at 22:56, Dmitri Smirnov notifications@github.com wrote:. > . > It is a minor fix but I though it would be nice to have the complete list since. > I always forget the style names for polymarkers and use this documentation as. > a reference. May also save someone else's time by avoiding a lookup in the. > header file. > . > You can view, comment on, or merge this pull request online at:. > . > https://github.com/root-mirror/root/pull/98 https://github.com/root-mirror/root/pull/98. > Commit Summary. > . > TAttMarker: Added missing marker style names in class documentation. > File Changes. > . > M core/base/src/TAttMarker.cxx https://github.com/root-mirror/root/pull/98/files#diff-0 (6). > Patch Links:. > . > https://github.com/root-mirror/root/pull/98.patch https://github.com/root-mirror/root/pull/98.patch. > https://github.com/root-mirror/root/pull/98.diff https://github.com/root-mirror/root/pull/98.diff. > —. > Reply to this email directly or view it on GitHub https://github.com/root-mirror/root/pull/98.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/98
https://github.com/root-project/root/pull/99:59,integrability,batch,batch,59,"This is for full-framework use-case where we start root in batch mode. When the request to start up TApplication & GUI arrives we have to set up things again. TStryle objects get deleted and even if we recreate them, the colors do not because the init_done is set to true ... so we had this workaround to enforce this reinitialization.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:59,performance,batch,batch,59,"This is for full-framework use-case where we start root in batch mode. When the request to start up TApplication & GUI arrives we have to set up things again. TStryle objects get deleted and even if we recreate them, the colors do not because the init_done is set to true ... so we had this workaround to enforce this reinitialization.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:6,safety,reme,remember,6,"Oh, I remember now ... there is ~TApplication called somewhere from cmssw, let me try to find it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:159,deployability,updat,update,159,"I don't see a commit between 5.34.17 and 5.34.18 that would explain the change of behaviors. But either way, there is indeed a semantic problem and we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:127,interoperability,semant,semantic,127,"I don't see a commit between 5.34.17 and 5.34.18 that would explain the change of behaviors. But either way, there is indeed a semantic problem and we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:159,safety,updat,update,159,"I don't see a commit between 5.34.17 and 5.34.18 that would explain the change of behaviors. But either way, there is indeed a semantic problem and we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:159,security,updat,update,159,"I don't see a commit between 5.34.17 and 5.34.18 that would explain the change of behaviors. But either way, there is indeed a semantic problem and we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:82,usability,behavi,behaviors,82,"I don't see a commit between 5.34.17 and 5.34.18 that would explain the change of behaviors. But either way, there is indeed a semantic problem and we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:26,deployability,version,versions,26,CMS probably skipped some versions before 5.34.18 ... and we only noticed it at 18. I'd guess this is the guy:. https://github.com/root-mirror/root/commit/2bcf0d70a1fa6929ca66764bd421dfd9650e44e6.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:26,integrability,version,versions,26,CMS probably skipped some versions before 5.34.18 ... and we only noticed it at 18. I'd guess this is the guy:. https://github.com/root-mirror/root/commit/2bcf0d70a1fa6929ca66764bd421dfd9650e44e6.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:26,modifiability,version,versions,26,CMS probably skipped some versions before 5.34.18 ... and we only noticed it at 18. I'd guess this is the guy:. https://github.com/root-mirror/root/commit/2bcf0d70a1fa6929ca66764bd421dfd9650e44e6.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:15,deployability,version,versions,15,"> skipped some versions before 5.34.18 . > Fair enough. > I'd guess this is the guy:. > Close enough :). > It is indeed needed .. but we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:145,deployability,updat,update,145,"> skipped some versions before 5.34.18 . > Fair enough. > I'd guess this is the guy:. > Close enough :). > It is indeed needed .. but we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:15,integrability,version,versions,15,"> skipped some versions before 5.34.18 . > Fair enough. > I'd guess this is the guy:. > Close enough :). > It is indeed needed .. but we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:15,modifiability,version,versions,15,"> skipped some versions before 5.34.18 . > Fair enough. > I'd guess this is the guy:. > Close enough :). > It is indeed needed .. but we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:145,safety,updat,update,145,"> skipped some versions before 5.34.18 . > Fair enough. > I'd guess this is the guy:. > Close enough :). > It is indeed needed .. but we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:145,security,updat,update,145,"> skipped some versions before 5.34.18 . > Fair enough. > I'd guess this is the guy:. > Close enough :). > It is indeed needed .. but we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:88,usability,Close,Close,88,"> skipped some versions before 5.34.18 . > Fair enough. > I'd guess this is the guy:. > Close enough :). > It is indeed needed .. but we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ) ....",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:0,availability,ping,ping,0,ping^1.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:115,deployability,updat,update,115,"The changes have been pushed onto the master. We still need to come up with a solution for TColor (I.e. we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:115,safety,updat,update,115,"The changes have been pushed onto the master. We still need to come up with a solution for TColor (I.e. we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:115,security,updat,update,115,"The changes have been pushed onto the master. We still need to come up with a solution for TColor (I.e. we need to update the ""deletes the default TApplication"" to be softer (i.e. not call EndOfProcessCleanups() ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:182,deployability,build,builds,182,"Just for reference, commit: https://root.cern.ch/gitweb?p=root.git;a=commit;h=e1503ba36e99dab94f281f75cc504025689493c5. That's a good progress, we might have GCC 5.2.0 and GCC 6.0.0 builds after all ;). Any ideas on ETA for TColor?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:134,usability,progress,progress,134,"Just for reference, commit: https://root.cern.ch/gitweb?p=root.git;a=commit;h=e1503ba36e99dab94f281f75cc504025689493c5. That's a good progress, we might have GCC 5.2.0 and GCC 6.0.0 builds after all ;). Any ideas on ETA for TColor?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:72,deployability,patch,patches,72,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:93,energy efficiency,schedul,scheduled,93,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:196,integrability,pub,public,196,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:223,interoperability,standard,standard,223,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:93,performance,schedul,scheduled,93,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:72,safety,patch,patches,72,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:72,security,patch,patches,72,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:27,usability,prefer,prefer,27,"We are not that burning, I prefer upstream solution instead out of tree patches. GCC 5.2+ is scheduled for CMSSW_8_0_X. `TColor` is now the last piece keeping us from cleaning up `#define private public` (it breaks GNU C++ standard library headers).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:137,deployability,resourc,resource,137,"@osschar, can you double check that your TColor issue is solved by the commit I just pushed:. - 8dd71a9 - (13 seconds ago) Do not delete resource when replacing default TApplication. — Philippe Canal (HEAD, origin/master, origin/HEAD, master).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:137,energy efficiency,resourc,resource,137,"@osschar, can you double check that your TColor issue is solved by the commit I just pushed:. - 8dd71a9 - (13 seconds ago) Do not delete resource when replacing default TApplication. — Philippe Canal (HEAD, origin/master, origin/HEAD, master).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:137,performance,resourc,resource,137,"@osschar, can you double check that your TColor issue is solved by the commit I just pushed:. - 8dd71a9 - (13 seconds ago) Do not delete resource when replacing default TApplication. — Philippe Canal (HEAD, origin/master, origin/HEAD, master).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:137,safety,resourc,resource,137,"@osschar, can you double check that your TColor issue is solved by the commit I just pushed:. - 8dd71a9 - (13 seconds ago) Do not delete resource when replacing default TApplication. — Philippe Canal (HEAD, origin/master, origin/HEAD, master).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:137,testability,resourc,resource,137,"@osschar, can you double check that your TColor issue is solved by the commit I just pushed:. - 8dd71a9 - (13 seconds ago) Do not delete resource when replacing default TApplication. — Philippe Canal (HEAD, origin/master, origin/HEAD, master).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:63,integrability,event,event,63,"I'm away this week, it's near impossible to run full-framework event display remotely. I'll try this next Monday.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:0,availability,ping,ping,0,"ping, reminder ;).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:102,integrability,pub,public,102,@osschar do we have a verdict? Are we fine between ROOT + CMS Fireworks? No more any `#define private public` or `#define protected public` are needed?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:132,integrability,pub,public,132,@osschar do we have a verdict? Are we fine between ROOT + CMS Fireworks? No more any `#define private public` or `#define protected public` are needed?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:100,reliability,doe,doesn,100,"Yup ... @pcanal's change works. I was able to remove reinitialization of TColor array. Note that it doesn't merge cleanly into 6.02, you also need to take https://github.com/root-mirror/root/commit/8068d47df7203fec1e6ca607cd71d1c2b9bdfe71.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:74,performance,time,time,74,"Actually, yes would be nice to have in 6.02 also, because 6.04 are taking time and not fully working yet for CMSSW.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:88,safety,compl,completed,88,"@osschar: yes, it would nice to have two new PR. I am closing this one has it is per se completed. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:88,security,compl,completed,88,"@osschar: yes, it would nice to have two new PR. I am closing this one has it is per se completed. Thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/99:57,usability,help,help,57,"OK, deal, will try to do it later today. Thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/99
https://github.com/root-project/root/pull/100:50,usability,close,close,50,"Hi, I know it's quite late but would you agree to close this PR given the recent merging which happened in the past week?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/100
https://github.com/root-project/root/pull/100:0,usability,close,closed,0,"closed, sure. Even though I still want to port the threading code. It needs to be rebased / reworked anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/100
https://github.com/root-project/root/pull/101:105,deployability,patch,patch,105,I think THREAD_TLS is not working properly on all platform for global variable. I will provide a similar patch and upload asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/101
https://github.com/root-project/root/pull/101:50,interoperability,platform,platform,50,I think THREAD_TLS is not working properly on all platform for global variable. I will provide a similar patch and upload asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/101
https://github.com/root-project/root/pull/101:70,modifiability,variab,variable,70,I think THREAD_TLS is not working properly on all platform for global variable. I will provide a similar patch and upload asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/101
https://github.com/root-project/root/pull/101:105,safety,patch,patch,105,I think THREAD_TLS is not working properly on all platform for global variable. I will provide a similar patch and upload asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/101
https://github.com/root-project/root/pull/101:105,security,patch,patch,105,I think THREAD_TLS is not working properly on all platform for global variable. I will provide a similar patch and upload asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/101
https://github.com/root-project/root/pull/101:27,availability,sli,slightly,27,merged into the merge in a slightly different form.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/101
https://github.com/root-project/root/pull/101:27,reliability,sli,slightly,27,merged into the merge in a slightly different form.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/101
https://github.com/root-project/root/pull/105:69,deployability,patch,patches,69,Thanks for your input. I am looking at it now. But I do not use your patches because there is much more to do than just these 3 files. In particular in TPrincipal there is two headers to completely reformat.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/105
https://github.com/root-project/root/pull/105:16,safety,input,input,16,Thanks for your input. I am looking at it now. But I do not use your patches because there is much more to do than just these 3 files. In particular in TPrincipal there is two headers to completely reformat.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/105
https://github.com/root-project/root/pull/105:69,safety,patch,patches,69,Thanks for your input. I am looking at it now. But I do not use your patches because there is much more to do than just these 3 files. In particular in TPrincipal there is two headers to completely reformat.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/105
https://github.com/root-project/root/pull/105:187,safety,compl,completely,187,Thanks for your input. I am looking at it now. But I do not use your patches because there is much more to do than just these 3 files. In particular in TPrincipal there is two headers to completely reformat.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/105
https://github.com/root-project/root/pull/105:69,security,patch,patches,69,Thanks for your input. I am looking at it now. But I do not use your patches because there is much more to do than just these 3 files. In particular in TPrincipal there is two headers to completely reformat.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/105
https://github.com/root-project/root/pull/105:187,security,compl,completely,187,Thanks for your input. I am looking at it now. But I do not use your patches because there is much more to do than just these 3 files. In particular in TPrincipal there is two headers to completely reformat.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/105
https://github.com/root-project/root/pull/105:16,usability,input,input,16,Thanks for your input. I am looking at it now. But I do not use your patches because there is much more to do than just these 3 files. In particular in TPrincipal there is two headers to completely reformat.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/105
https://github.com/root-project/root/pull/108:49,deployability,patch,patches,49,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:67,deployability,patch,patches,67,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:85,deployability,patch,patches,85,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:49,safety,patch,patches,49,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:67,safety,patch,patches,67,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:85,safety,patch,patches,85,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:49,security,patch,patches,49,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:67,security,patch,patches,67,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/108:85,security,patch,patches,85,"Hi,. Thanks. I've applied the change to v5-34-00-patches, v6-04-00-patches, v6-06-00-patches and master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/108
https://github.com/root-project/root/pull/109:4,deployability,patch,patch,4,The patch has been merged in the master and v6.04 and v6.06 patch branches. thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/109
https://github.com/root-project/root/pull/109:60,deployability,patch,patch,60,The patch has been merged in the master and v6.04 and v6.06 patch branches. thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/109
https://github.com/root-project/root/pull/109:4,safety,patch,patch,4,The patch has been merged in the master and v6.04 and v6.06 patch branches. thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/109
https://github.com/root-project/root/pull/109:60,safety,patch,patch,60,The patch has been merged in the master and v6.04 and v6.06 patch branches. thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/109
https://github.com/root-project/root/pull/109:4,security,patch,patch,4,The patch has been merged in the master and v6.04 and v6.06 patch branches. thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/109
https://github.com/root-project/root/pull/109:60,security,patch,patch,60,The patch has been merged in the master and v6.04 and v6.06 patch branches. thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/109
https://github.com/root-project/root/pull/110:20,deployability,patch,patch,20,"Hi. I've added your patch to root master, with a little change, e.g. to use a setter rather than setting the token via the public member. Thank you.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/110:123,integrability,pub,public,123,"Hi. I've added your patch to root master, with a little change, e.g. to use a setter rather than setting the token via the public member. Thank you.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/110:20,safety,patch,patch,20,"Hi. I've added your patch to root master, with a little change, e.g. to use a setter rather than setting the token via the public member. Thank you.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/110:20,security,patch,patch,20,"Hi. I've added your patch to root master, with a little change, e.g. to use a setter rather than setting the token via the public member. Thank you.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/110:109,security,token,token,109,"Hi. I've added your patch to root master, with a little change, e.g. to use a setter rather than setting the token via the public member. Thank you.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/110
https://github.com/root-project/root/pull/113:139,deployability,patch,patch,139,"Thank you for your PR! Nice ideas, let's get this in! Please let me know if one of my comments wasn't precise enough or misunderstood your patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:139,safety,patch,patch,139,"Thank you for your PR! Nice ideas, let's get this in! Please let me know if one of my comments wasn't precise enough or misunderstood your patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:139,security,patch,patch,139,"Thank you for your PR! Nice ideas, let's get this in! Please let me know if one of my comments wasn't precise enough or misunderstood your patch.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:83,deployability,integr,integrate,83,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:83,integrability,integr,integrate,83,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:83,interoperability,integr,integrate,83,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:83,modifiability,integr,integrate,83,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:83,reliability,integr,integrate,83,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:22,safety,review,review,22,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:83,security,integr,integrate,83,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:22,testability,review,review,22,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/113:83,testability,integr,integrate,83,"Thanks for your quick review! I'll try to work on your suggestions asap so you can integrate them. Also, do you want me to do the same PR on Cling project?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/113
https://github.com/root-project/root/pull/116:0,availability,ping,ping,0,ping...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:273,deployability,stack,stack,273,"Hi,. I reviewed your suggestions. They are good suggestions, but they are somewhat orthogonal to the fix for the array overflow: Clearly, the current code could use some reworking like getting the types right, but that would require some more work than just the fix of the stack overflow. I could maybe tend to that when I'm back from travelling in May.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:142,energy efficiency,current,current,142,"Hi,. I reviewed your suggestions. They are good suggestions, but they are somewhat orthogonal to the fix for the array overflow: Clearly, the current code could use some reworking like getting the types right, but that would require some more work than just the fix of the stack overflow. I could maybe tend to that when I'm back from travelling in May.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:7,safety,review,reviewed,7,"Hi,. I reviewed your suggestions. They are good suggestions, but they are somewhat orthogonal to the fix for the array overflow: Clearly, the current code could use some reworking like getting the types right, but that would require some more work than just the fix of the stack overflow. I could maybe tend to that when I'm back from travelling in May.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:7,testability,review,reviewed,7,"Hi,. I reviewed your suggestions. They are good suggestions, but they are somewhat orthogonal to the fix for the array overflow: Clearly, the current code could use some reworking like getting the types right, but that would require some more work than just the fix of the stack overflow. I could maybe tend to that when I'm back from travelling in May.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:129,usability,Clear,Clearly,129,"Hi,. I reviewed your suggestions. They are good suggestions, but they are somewhat orthogonal to the fix for the array overflow: Clearly, the current code could use some reworking like getting the types right, but that would require some more work than just the fix of the stack overflow. I could maybe tend to that when I'm back from travelling in May.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:38,availability,failur,failures,38,Clang-format seems unhappy. The other failures are independent on that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:38,deployability,fail,failures,38,Clang-format seems unhappy. The other failures are independent on that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:6,interoperability,format,format,6,Clang-format seems unhappy. The other failures are independent on that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:38,performance,failur,failures,38,Clang-format seems unhappy. The other failures are independent on that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:38,reliability,fail,failures,38,Clang-format seems unhappy. The other failures are independent on that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:373,deployability,observ,observe,373,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:383,integrability,sub,substantial,383,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:118,performance,perform,performance,118,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:164,performance,time,time,164,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:190,performance,cach,cache,190,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:395,performance,perform,performance,395,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:109,safety,test,test,109,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:135,safety,compl,complex,135,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:135,security,compl,complex,135,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:109,testability,test,test,109,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:224,testability,simpl,simple,224,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:279,testability,simpl,simplify,279,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:373,testability,observ,observe,373,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:118,usability,perform,performance,118,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:224,usability,simpl,simple,224,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:279,usability,simpl,simplify,279,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:395,usability,perform,performance,395,"The code looks fine to me. I don't think using vector::reserve is needed in this case. . It would be nice to test the performance in a complex fix which takes some time and uses heavily the cache, The tutorial are maybe too simple and the fitting is too fast. . If you can maybe simplify your workspace and make a standalone running example would be great. . Also, did you observe a substantial performance penalty when creating the std::vector in recalculateCache instead of having as a data member of the class ? . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:169,availability,sli,slight,169,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:176,availability,slo,slowdown,176,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:241,deployability,manag,managing,241,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:315,deployability,stack,stack,315,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:640,deployability,version,version,640,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:241,energy efficiency,manag,managing,241,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:640,integrability,version,version,640,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:640,modifiability,version,version,640,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:228,performance,overhead,overhead,228,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:169,reliability,sli,slight,169,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:176,reliability,slo,slowdown,176,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:241,safety,manag,managing,241,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:350,safety,test,tests,350,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:350,testability,test,tests,350,"Following up on Lorenzo's comment: Can a local vector be used? Short answer: Yes. Long answer:. When I first fixed the bug, I did exactly that. In the tutorials I saw a slight slowdown, probably because of reallocations or some overhead for managing the vector instead of having an array[1000] which appears on the stack instantly. Now, I did timing tests with a heavy workspace, gcc 5.4 -O2. Results are as follows:. There is almost no difference in speed. If differences are more than statistical, the implementation with a (local or instance-persistent) vector is even faster than array[1000]. See attached file. I therefore committed a version with a local vector and vec.reserve(), the most easy, most clean fix. [timingResults.txt](https://github.com/root-project/root/files/971127/timingResults.txt).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:29,interoperability,format,formatting,29,@hageboeck could you fix the formatting issues reported by clang-format (see Details of Travis CI),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:65,interoperability,format,format,65,@hageboeck could you fix the formatting issues reported by clang-format (see Details of Travis CI),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:13,deployability,patch,patched,13,Done. I just patched in the diff from the clang-format.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:48,interoperability,format,format,48,Done. I just patched in the diff from the clang-format.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:13,safety,patch,patched,13,Done. I just patched in the diff from the clang-format.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:13,security,patch,patched,13,Done. I just patched in the diff from the clang-format.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/116:11,deployability,build,build,11,"@phsft-bot build! @hageboeck, thanks!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/116
https://github.com/root-project/root/pull/117:6,deployability,patch,patch,6,which patch branches do you need this fix on?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/117
https://github.com/root-project/root/pull/117:6,safety,patch,patch,6,which patch branches do you need this fix on?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/117
https://github.com/root-project/root/pull/117:6,security,patch,patch,6,which patch branches do you need this fix on?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/117
https://github.com/root-project/root/pull/118:76,availability,Error,Error,76,@pcanal This should fix an exception happening in CMS code. ```. Fatal Root Error: @SUB=TExMap::Add. key 140181673649616 is not unique. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/118
https://github.com/root-project/root/pull/118:84,integrability,SUB,SUB,84,@pcanal This should fix an exception happening in CMS code. ```. Fatal Root Error: @SUB=TExMap::Add. key 140181673649616 is not unique. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/118
https://github.com/root-project/root/pull/118:76,performance,Error,Error,76,@pcanal This should fix an exception happening in CMS code. ```. Fatal Root Error: @SUB=TExMap::Add. key 140181673649616 is not unique. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/118
https://github.com/root-project/root/pull/118:27,safety,except,exception,27,@pcanal This should fix an exception happening in CMS code. ```. Fatal Root Error: @SUB=TExMap::Add. key 140181673649616 is not unique. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/118
https://github.com/root-project/root/pull/118:76,safety,Error,Error,76,@pcanal This should fix an exception happening in CMS code. ```. Fatal Root Error: @SUB=TExMap::Add. key 140181673649616 is not unique. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/118
https://github.com/root-project/root/pull/118:76,usability,Error,Error,76,@pcanal This should fix an exception happening in CMS code. ```. Fatal Root Error: @SUB=TExMap::Add. key 140181673649616 is not unique. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/118
https://github.com/root-project/root/pull/121:15,interoperability,conflict,conflict,15,"looks like the conflict is purely whitespace changes on master, mergeing by hand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:70,interoperability,conflict,conflicts,70,this is *not* superseded by #572 (though merging both might result in conflicts. i can work that out in #121 once #572 is merged).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:69,availability,state,state,69,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:164,availability,state,state,164,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:347,availability,state,state,347,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:69,integrability,state,state,69,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:164,integrability,state,state,164,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:263,integrability,repositor,repository,263,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:347,integrability,state,state,347,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:60,interoperability,conflict,conflict,60,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:155,interoperability,conflict,conflict,155,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:247,interoperability,conflict,conflicts,247,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:263,interoperability,repositor,repository,263,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:338,interoperability,conflict,conflict,338,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:116,safety,review,review,116,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:116,testability,review,review,116,"I think that's what I meant. My idea was:. - *#121 is in no-conflict state*. - wait until #572 is merged (easier to review, more important). - *#121 is in conflict state*. - `git rebase master` on `pseyfert/tmva-mlp-codegen`. - work out the merge conflicts in my repository. - push the fixed `pseyfert/tmva-mlp-codegen`. - *#121 is in no-conflict state*",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,"@phsft-bot build! @pseyfert, I was wondering can we create a gtest testing that part? This is good for test coverage and documentation purposes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:67,safety,test,testing,67,"@phsft-bot build! @pseyfert, I was wondering can we create a gtest testing that part? This is good for test coverage and documentation purposes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:103,safety,test,test,103,"@phsft-bot build! @pseyfert, I was wondering can we create a gtest testing that part? This is good for test coverage and documentation purposes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:67,testability,test,testing,67,"@phsft-bot build! @pseyfert, I was wondering can we create a gtest testing that part? This is good for test coverage and documentation purposes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:103,testability,test,test,103,"@phsft-bot build! @pseyfert, I was wondering can we create a gtest testing that part? This is good for test coverage and documentation purposes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:108,testability,coverag,coverage,108,"@phsft-bot build! @pseyfert, I was wondering can we create a gtest testing that part? This is good for test coverage and documentation purposes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:121,usability,document,documentation,121,"@phsft-bot build! @pseyfert, I was wondering can we create a gtest testing that part? This is good for test coverage and documentation purposes...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:10,availability,ping,ping,10,@pseyfert ping...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:398,availability,failur,failure,398,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:908,availability,consist,consistency,908,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:1091,availability,failur,failure,1091,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:176,deployability,stack,stackoverflow,176,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:398,deployability,fail,failure,398,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:1085,deployability,build,build,1085,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:1091,deployability,fail,failure,1091,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:82,performance,network,network,82,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:398,performance,failur,failure,398,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:490,performance,network,network,490,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:536,performance,time,times,536,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:1091,performance,failur,failure,1091,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:398,reliability,fail,failure,398,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:1091,reliability,fail,failure,1091,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:418,safety,test,tests,418,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:976,safety,test,testing,976,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:1263,safety,test,test,1263,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:82,security,network,network,82,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:490,security,network,network,490,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:418,testability,test,tests,418,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:976,testability,test,testing,976,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:1263,testability,test,test,1263,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:908,usability,consist,consistency,908,"back on this one. it appears my change is not super numerically stable. I ran the network from tutorials/tmva/TMVAClassification and the floating point comparison from https://stackoverflow.com/a/253874 with rapidcheck and this check. ```. if (!( essentiallyEqual(reference , newimplementation , 1000.f*std::numeric_limits<float>::epsilon()) )) {. RC_ASSERT( refval == safval) ;. }. ```. and get a failure every ~ 500 tests (i.e. at that rate the numerical noise i generate by changing the network implementation exceeds more than 1000 times floating point precision (NB: the return value is actually a double …)). but this only if i disable the fast tanh evaluation (enabled by default). If i enable the fast tanh evaluation it appears response values change by more than that. [background: the TMVA::Reader already uses the fast evaluation, the codegen wasn't. so this should actually improve actually the consistency between TMVA::Reader usage and the codegen - i was only testing old codegen vs new codegen]. will discuss at the next tmva meeting, with a bit more insight. for the build failure, sorry that was a pretty stupid merging mistake i should've seen (… if i had compiled it locally before pushing … instead of postponing that to running the numeric test).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:0,availability,ping,ping,0,ping.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:29,safety,test,test,29,found the issue. ran numeric test here https://github.com/pseyfert/tmva-codegen-rapidcheck,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:29,testability,test,test,29,found the issue. ran numeric test here https://github.com/pseyfert/tmva-codegen-rapidcheck,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:297,deployability,automat,automated,297,"As discussed in the meeting of today: This is ready to be merged *but* for a broader testing with rapidcheck as linked by @pseyfert previously. Broader since not only the MLP is affected by the change. I'll take care of that and report back when done. This kind of testing should at some point be automated, but that is a separate task.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:85,safety,test,testing,85,"As discussed in the meeting of today: This is ready to be merged *but* for a broader testing with rapidcheck as linked by @pseyfert previously. Broader since not only the MLP is affected by the change. I'll take care of that and report back when done. This kind of testing should at some point be automated, but that is a separate task.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:265,safety,test,testing,265,"As discussed in the meeting of today: This is ready to be merged *but* for a broader testing with rapidcheck as linked by @pseyfert previously. Broader since not only the MLP is affected by the change. I'll take care of that and report back when done. This kind of testing should at some point be automated, but that is a separate task.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:85,testability,test,testing,85,"As discussed in the meeting of today: This is ready to be merged *but* for a broader testing with rapidcheck as linked by @pseyfert previously. Broader since not only the MLP is affected by the change. I'll take care of that and report back when done. This kind of testing should at some point be automated, but that is a separate task.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:265,testability,test,testing,265,"As discussed in the meeting of today: This is ready to be merged *but* for a broader testing with rapidcheck as linked by @pseyfert previously. Broader since not only the MLP is affected by the change. I'll take care of that and report back when done. This kind of testing should at some point be automated, but that is a separate task.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:297,testability,automat,automated,297,"As discussed in the meeting of today: This is ready to be merged *but* for a broader testing with rapidcheck as linked by @pseyfert previously. Broader since not only the MLP is affected by the change. I'll take care of that and report back when done. This kind of testing should at some point be automated, but that is a separate task.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:32,usability,statu,status,32,"@ashlaban, @lmoneta what is the status of this? Can we go for the merge?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:527,security,auth,auth,527,"Sorry, no. It's on me to look verify a few things and I have been busy . with other things. Cheers,. Kim. etejedor wrote:. >. > @ashlaban <https://github.com/ashlaban>, @lmoneta. > <https://github.com/lmoneta> what is the status of this? Can we go for. > the merge? >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/root-project/root/pull/121#issuecomment-347113984>, or . >. > mute the thread. > <https://github.com/notifications/unsubscribe-auth/ACBi2asFNnjfcki5bZg6gR88WW3-rplhks5s6najgaJpZM4G5ZQG>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:30,testability,verif,verify,30,"Sorry, no. It's on me to look verify a few things and I have been busy . with other things. Cheers,. Kim. etejedor wrote:. >. > @ashlaban <https://github.com/ashlaban>, @lmoneta. > <https://github.com/lmoneta> what is the status of this? Can we go for. > the merge? >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/root-project/root/pull/121#issuecomment-347113984>, or . >. > mute the thread. > <https://github.com/notifications/unsubscribe-auth/ACBi2asFNnjfcki5bZg6gR88WW3-rplhks5s6najgaJpZM4G5ZQG>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:222,usability,statu,status,222,"Sorry, no. It's on me to look verify a few things and I have been busy . with other things. Cheers,. Kim. etejedor wrote:. >. > @ashlaban <https://github.com/ashlaban>, @lmoneta. > <https://github.com/lmoneta> what is the status of this? Can we go for. > the merge? >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/root-project/root/pull/121#issuecomment-347113984>, or . >. > mute the thread. > <https://github.com/notifications/unsubscribe-auth/ACBi2asFNnjfcki5bZg6gR88WW3-rplhks5s6najgaJpZM4G5ZQG>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:27,performance,time,time,27,@ashlaban have you had the time to verify what you needed from this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:35,testability,verif,verify,35,@ashlaban have you had the time to verify what you needed from this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:135,performance,time,time,135,"Thanks for the reminder! > On 20 Feb 2018, at 13:34, Enric Tejedor <notifications@github.com> wrote:. > . > @ashlaban have you had the time to verify what you needed from this PR? > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:143,testability,verif,verify,143,"Thanks for the reminder! > On 20 Feb 2018, at 13:34, Enric Tejedor <notifications@github.com> wrote:. > . > @ashlaban have you had the time to verify what you needed from this PR? > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:116,deployability,updat,update,116,I've now done the verification that I wanted to do. This PR is ok to merge for me! Thanks @pseyfert! Could you also update the PR to fix the merge conflict? I think it's only a whitespace change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:147,interoperability,conflict,conflict,147,I've now done the verification that I wanted to do. This PR is ok to merge for me! Thanks @pseyfert! Could you also update the PR to fix the merge conflict? I think it's only a whitespace change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:116,safety,updat,update,116,I've now done the verification that I wanted to do. This PR is ok to merge for me! Thanks @pseyfert! Could you also update the PR to fix the merge conflict? I think it's only a whitespace change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:116,security,updat,update,116,I've now done the verification that I wanted to do. This PR is ok to merge for me! Thanks @pseyfert! Could you also update the PR to fix the merge conflict? I think it's only a whitespace change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:18,testability,verif,verification,18,I've now done the verification that I wanted to do. This PR is ok to merge for me! Thanks @pseyfert! Could you also update the PR to fix the merge conflict? I think it's only a whitespace change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:85,deployability,updat,updated,85,"Rebase only complained about trailing whitespaces in the generated code for me, just updated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:12,safety,compl,complained,12,"Rebase only complained about trailing whitespaces in the generated code for me, just updated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:85,safety,updat,updated,85,"Rebase only complained about trailing whitespaces in the generated code for me, just updated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:12,security,compl,complained,12,"Rebase only complained about trailing whitespaces in the generated code for me, just updated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:85,security,updat,updated,85,"Rebase only complained about trailing whitespaces in the generated code for me, just updated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:41,safety,review,review,41,"@ashlaban I think we can take away ""need review"" label?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:41,testability,review,review,41,"@ashlaban I think we can take away ""need review"" label?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:54,safety,review,reviewed,54,@lmoneta @ashlaban I understand that this PR has been reviewed and is ready to go? Can you please take care of the merging?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:21,testability,understand,understand,21,@lmoneta @ashlaban I understand that this PR has been reviewed and is ready to go? Can you please take care of the merging?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:54,testability,review,reviewed,54,@lmoneta @ashlaban I understand that this PR has been reviewed and is ready to go? Can you please take care of the merging?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:73,deployability,build,build,73,@ashlaban @lmoneta what is the status of this PR? Should we try again to build and merge?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:31,usability,statu,status,31,@ashlaban @lmoneta what is the status of this PR? Should we try again to build and merge?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:26,availability,ping,ping,26,"Great @ashlaban , can you ping @lmoneta when he is back about this? This is a senior PR, opened in 2015! :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build just on ubuntu16/native,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build just on ubuntu16/native.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build just on ubuntu16/native,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/121:11,deployability,build,build,11,@phsft-bot build just on ubuntu16/native.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/121
https://github.com/root-project/root/pull/123:198,interoperability,platform,platform,198,"This is my first foray into this project, but there are a few instances of commenting out the includes instead of fully removing them. If they can in fact be safely removed regardless of the target platform, then the lines should be removed to avoid cluttering up the code base.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:158,safety,safe,safely,158,"This is my first foray into this project, but there are a few instances of commenting out the includes instead of fully removing them. If they can in fact be safely removed regardless of the target platform, then the lines should be removed to avoid cluttering up the code base.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:244,safety,avoid,avoid,244,"This is my first foray into this project, but there are a few instances of commenting out the includes instead of fully removing them. If they can in fact be safely removed regardless of the target platform, then the lines should be removed to avoid cluttering up the code base.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:54,availability,redund,redundant,54,"@pseyfert, good work! Could you rebase and remove the redundant lines instead of commenting them out?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:54,deployability,redundan,redundant,54,"@pseyfert, good work! Could you rebase and remove the redundant lines instead of commenting them out?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:54,reliability,redundan,redundant,54,"@pseyfert, good work! Could you rebase and remove the redundant lines instead of commenting them out?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:54,safety,redund,redundant,54,"@pseyfert, good work! Could you rebase and remove the redundant lines instead of commenting them out?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:102,deployability,build,build,102,- Rebased and deleted includes instead of commenting out. - I didn't rerun IWYU so I'm curious if the build still succeeds. - Also the rebase failed on math/physics/inc/TVector3.h where I used the master for simplicity.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:142,deployability,fail,failed,142,- Rebased and deleted includes instead of commenting out. - I didn't rerun IWYU so I'm curious if the build still succeeds. - Also the rebase failed on math/physics/inc/TVector3.h where I used the master for simplicity.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:142,reliability,fail,failed,142,- Rebased and deleted includes instead of commenting out. - I didn't rerun IWYU so I'm curious if the build still succeeds. - Also the rebase failed on math/physics/inc/TVector3.h where I used the master for simplicity.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:208,testability,simpl,simplicity,208,- Rebased and deleted includes instead of commenting out. - I didn't rerun IWYU so I'm curious if the build still succeeds. - Also the rebase failed on math/physics/inc/TVector3.h where I used the master for simplicity.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:208,usability,simpl,simplicity,208,- Rebased and deleted includes instead of commenting out. - I didn't rerun IWYU so I'm curious if the build still succeeds. - Also the rebase failed on math/physics/inc/TVector3.h where I used the master for simplicity.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:12,deployability,build,build,12,@phsft-bot: build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:12,deployability,build,build,12,@phsft-bot: build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:12,deployability,build,build,12,@phsft-bot: build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:32,energy efficiency,optim,optimise,32,"@pseyfert, do you think you can optimise the rest of the includes in ROOT in a similar manner in a new PR?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:71,integrability,configur,configure,71,"need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:71,modifiability,configur,configure,71,"need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:280,reliability,doe,doesn,280,"need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:71,security,configur,configure,71,"need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:64,deployability,stack,stackoverflow,64,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:391,integrability,configur,configure,391,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:391,modifiability,configur,configure,391,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:602,reliability,doe,doesn,602,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:165,safety,detect,detect-unused-he,165,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:165,security,detect,detect-unused-he,165,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:391,security,configur,configure,391,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:116,usability,tool,tool-include-what-you-use-together-with-cmake-to-detect-unused-he,116,"It seems that there are two ways to use it within cmake: http://stackoverflow.com/questions/30951492/how-to-use-the-tool-include-what-you-use-together-with-cmake-to-detect-unused-he. Vassil. Msg sent from my phone. Please excuse my brevity. > On Mar 10, 2017, at 17:21, pseyfert <notifications@github.com> wrote:. > . > need to check. i didn't get iwyu running with cmake and haven't used ./configure since quite a while. > i had tried it back then for roofit and realised it caused problems in my own ""third party"" code if a class A has a method to return a pointer to an instance of class B, but A.h doesn't include B.h. > . > —. > You are receiving this because you were assigned. > Reply to this email directly, view it on GitHub, or mute the thread. > .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:32,safety,review,review,32,"Merged, thanks! I'd be happy to review a PR, running IWYU on the rest of the ROOT codebase!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:32,testability,review,review,32,"Merged, thanks! I'd be happy to review a PR, running IWYU on the rest of the ROOT codebase!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:0,energy efficiency,cool,cool,0,"cool, will notify you once i came around running it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:85,deployability,log,log,85,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:123,deployability,build,build,123,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:73,integrability,pub,public,73,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:133,integrability,compon,components,133,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:133,interoperability,compon,components,133,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:133,modifiability,compon,components,133,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:85,safety,log,log,85,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:85,security,log,log,85,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:85,testability,log,log,85,@vgvassilev I put the output of a first run /afs/cern.ch/work/p/pseyfert/public/iwyu.log It's quite big (and i didn't even build all components) and also involves parts I don't dare to touch (llvm). I'll clean up my changes to the cmake files and factorise the suggestions a bit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:105,deployability,build,build,105,"Good progress. I do not understand why it says we should remove the `.o` files. Do you have an in-source build somehow? We should ignore the fixes in llvm at first. Then we should ask the iwyu to order the suggested includes by generality (i.e. stl, libc go last).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:24,testability,understand,understand,24,"Good progress. I do not understand why it says we should remove the `.o` files. Do you have an in-source build somehow? We should ignore the fixes in llvm at first. Then we should ask the iwyu to order the suggested includes by generality (i.e. stl, libc go last).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:5,usability,progress,progress,5,"Good progress. I do not understand why it says we should remove the `.o` files. Do you have an in-source build somehow? We should ignore the fixes in llvm at first. Then we should ask the iwyu to order the suggested includes by generality (i.e. stl, libc go last).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:21,availability,avail,available,21,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:104,deployability,build,build,104,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:155,deployability,build,build,155,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:211,deployability,build,build,211,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:387,deployability,build,build,387,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:132,performance,time,times,132,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:21,reliability,availab,available,21,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:21,safety,avail,available,21,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/123:21,security,availab,available,21,"changes to cmake now available here: https://github.com/pseyfert/root/tree/IWYU . It's not an in-source build, but I iterated a few times with. ```. cd ../build. rm -rf *. cmake ../root -G Ninja ....... cmake --build . ```. and once i saw the first iwyu output (realising i put the parts together correctly), I didn't do an `rm -rf` (don't touch a running system) and ran:. ```. cmake --build . --clean-first -- -v. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/123
https://github.com/root-project/root/pull/124:46,reliability,doe,does,46,"Hi Mattias,. Thanks for collecting those. How does this PR relate to http://reviews.llvm.org/D12834 ? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:76,safety,review,reviews,76,"Hi Mattias,. Thanks for collecting those. How does this PR relate to http://reviews.llvm.org/D12834 ? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:76,testability,review,reviews,76,"Hi Mattias,. Thanks for collecting those. How does this PR relate to http://reviews.llvm.org/D12834 ? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:11,deployability,patch,patch,11,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:71,deployability,patch,patch,71,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:190,deployability,patch,patch,190,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:230,deployability,patch,patch,230,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:409,deployability,patch,patch,409,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:443,deployability,version,version,443,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:423,energy efficiency,adapt,adapted,423,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:423,integrability,adapt,adapted,423,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:443,integrability,version,version,443,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:423,interoperability,adapt,adapted,423,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:423,modifiability,adapt,adapted,423,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:443,modifiability,version,version,443,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:11,safety,patch,patch,11,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:30,safety,review,review,30,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:71,safety,patch,patch,71,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:143,safety,review,reviews,143,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:190,safety,patch,patch,190,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:230,safety,patch,patch,230,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:249,safety,review,review,249,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:409,safety,patch,patch,409,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:11,security,patch,patch,11,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:71,security,patch,patch,71,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:190,security,patch,patch,190,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:230,security,patch,patch,230,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:265,security,sign,significant,265,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:409,security,patch,patch,409,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:30,testability,review,review,30,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:143,testability,review,reviews,143,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:249,testability,review,review,249,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:355,usability,tool,tools,355,The Fedora patch and the llvm review are very much related. The Fedora patch is based on the proposed changes - there is a reference to http://reviews.llvm.org/D12834?id=34645 in the Fedora patch. Making a diff between the Fedora patch and the llvm review shows no significant changes (there are differences because the diffs are generated with different tools). The proposed changes here differs because the patch must be adapted to the llvm version used by root.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:58,deployability,updat,update,58,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:309,reliability,doe,doesn,309,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:58,safety,updat,update,58,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:288,safety,test,tests,288,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:58,security,updat,update,58,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:44,testability,plan,plan,44,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:288,testability,test,tests,288,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:154,usability,support,support,154,"Hi Mattias,. Thanks for your PR! Here's the plan:. I will update llvm and clang still this month. Very likely that'll _not_ be enough to give us GCC5 ABI support. I will then take what's in D12834 and friends (there are a few follow-ups as far as I can see) and apply them for a round of tests. As long as it doesn't break GCC 4.9 we are better off than now. Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:125,deployability,patch,patch,125,"Another bug report related to this issue:. https://sft.its.cern.ch/jira/browse/ROOT-7895. I confirm that after applying this patch (against 44c8e52) everything seems to work well. Debian sid, gcc 5.3.1. Thanks @ellert .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:125,safety,patch,patch,125,"Another bug report related to this issue:. https://sft.its.cern.ch/jira/browse/ROOT-7895. I confirm that after applying this patch (against 44c8e52) everything seems to work well. Debian sid, gcc 5.3.1. Thanks @ellert .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:125,security,patch,patch,125,"Another bug report related to this issue:. https://sft.its.cern.ch/jira/browse/ROOT-7895. I confirm that after applying this patch (against 44c8e52) everything seems to work well. Debian sid, gcc 5.3.1. Thanks @ellert .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:92,usability,confirm,confirm,92,"Another bug report related to this issue:. https://sft.its.cern.ch/jira/browse/ROOT-7895. I confirm that after applying this patch (against 44c8e52) everything seems to work well. Debian sid, gcc 5.3.1. Thanks @ellert .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:31,availability,state,state,31,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:44,deployability,patch,patch,44,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:23,energy efficiency,current,current,23,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:31,integrability,state,state,31,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:44,safety,patch,patch,44,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:56,safety,review,review,56,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:44,security,patch,patch,44,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:141,security,sign,significant,141,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/124:56,testability,review,review,56,"Hi,. I will import the current state of the patch under review with llvm / clang, instead of the original one proposed here. There have been significant changes since. So yes - this will be dealt with (see also the open Jira tickets), but not exactly as proposed here. Thanks anyway for the suggestion! Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/124
https://github.com/root-project/root/pull/126:110,availability,down,downloaded,110,This PR has became invalid since we have removed the sources of Vc from the ROOT sources. A source tarfile is downloaded if the option 'builtin_vc' is set. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/126
https://github.com/root-project/root/pull/130:150,deployability,configurat,configuration,150,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:288,deployability,automat,automatically,288,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:356,deployability,depend,depends,356,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:322,energy efficiency,load,loaded,322,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:150,integrability,configur,configuration,150,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:356,integrability,depend,depends,356,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:564,integrability,rout,routines,564,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:36,modifiability,variab,variable,36,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:150,modifiability,configur,configuration,150,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:356,modifiability,depend,depends,356,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:690,modifiability,variab,variable,690,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:142,performance,perform,perform,142,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:322,performance,load,loaded,322,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:356,safety,depend,depends,356,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:150,security,configur,configuration,150,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:584,security,modif,modified,584,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:288,testability,automat,automatically,288,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:356,testability,depend,depends,356,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:142,usability,perform,perform,142,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:530,usability,behavi,behaviour,530,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:596,usability,command,command,596,"The reason for using an environment variable is the following:. It is a common occurrence in the root code to use initialization classes that perform configuration in its constructor, and then have a static instance of this class declared in a library so that this initialization happens automatically when the library is loaded. This initialization often depends on the various directory paths. Since the initialization of the static instances in the libraries an application links to happens before the main program starts, the behaviour of these initialization routines can not be modified by command line options, since these options are parsed by the main program. With an environment variable this works though.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:142,deployability,patch,patch,142,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:55,interoperability,specif,specific,55,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:107,modifiability,concern,concern,107,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:131,safety,review,review,131,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:142,safety,patch,patch,142,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:142,security,patch,patch,142,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:107,testability,concern,concern,107,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:131,testability,review,review,131,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:81,usability,usab,usability,81,"Excellent reason. It's also likely only needed in very specific situations, i.e. usability is not really a concern here. I'll do a review the patch; looked good on a first quick glimpse!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:19,deployability,patch,patch,19,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:106,deployability,build,build,106,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:91,integrability,configur,configure,91,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:91,modifiability,configur,configure,91,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:19,safety,patch,patch,19,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:64,safety,review,reviewing,64,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:143,safety,review,review,143,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:19,security,patch,patch,19,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:91,security,configur,configure,91,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:64,testability,review,reviewing,64,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:143,testability,review,review,143,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:259,usability,help,help,259,"This is an awesome patch, @ellert - thanks _so_ much! I am done reviewing the code and the configure/make build system; I'll ask Pere for a to review of the CMake part. Ideally I'd like to see the fixes to my comments first. Do you think you would be able to help us with those, too? Cheers, Axel.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:189,deployability,patch,patch,189,"Hi @ellert - where are we with this? All set and waiting for the CMake review? I believe we are still missing the thread safety improvements I mentioned, right? I'd really like to see this patch in ROOT... Do you think you can address the remaining comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:71,safety,review,review,71,"Hi @ellert - where are we with this? All set and waiting for the CMake review? I believe we are still missing the thread safety improvements I mentioned, right? I'd really like to see this patch in ROOT... Do you think you can address the remaining comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:121,safety,safe,safety,121,"Hi @ellert - where are we with this? All set and waiting for the CMake review? I believe we are still missing the thread safety improvements I mentioned, right? I'd really like to see this patch in ROOT... Do you think you can address the remaining comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:189,safety,patch,patch,189,"Hi @ellert - where are we with this? All set and waiting for the CMake review? I believe we are still missing the thread safety improvements I mentioned, right? I'd really like to see this patch in ROOT... Do you think you can address the remaining comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:189,security,patch,patch,189,"Hi @ellert - where are we with this? All set and waiting for the CMake review? I believe we are still missing the thread safety improvements I mentioned, right? I'd really like to see this patch in ROOT... Do you think you can address the remaining comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:71,testability,review,review,71,"Hi @ellert - where are we with this? All set and waiting for the CMake review? I believe we are still missing the thread safety improvements I mentioned, right? I'd really like to see this patch in ROOT... Do you think you can address the remaining comments?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:163,deployability,depend,depends,163,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:238,deployability,depend,depend,238,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:373,energy efficiency,load,loaded,373,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:163,integrability,depend,depends,163,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:238,integrability,depend,depend,238,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:897,integrability,sub,subsequent,897,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:140,modifiability,variab,variable,140,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:163,modifiability,depend,depends,163,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:190,modifiability,variab,variable,190,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:238,modifiability,depend,depend,238,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:275,modifiability,variab,variables,275,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:462,modifiability,variab,variable,462,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:625,modifiability,variab,variable,625,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:803,modifiability,variab,variables,803,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:976,modifiability,variab,variables,976,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:316,performance,time,time,316,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:373,performance,load,loaded,373,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:211,reliability,doe,does,211,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:29,safety,safe,safety,29,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:163,safety,depend,depends,163,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:238,safety,depend,depend,238,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1011,safety,safe,safe,1011,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:163,testability,depend,depends,163,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:238,testability,depend,depend,238,"I see your issue with thread safety. However, your proposed solutions will not work for the following reasons. The assignment of the static variable in GetRootSys depends on the environment variable ROOTSYS (as does the others since they depend on GetRootSys). If the static variables are assigned at initialization time, these assignments will be done when the program is loaded before the program starts. But at this point the value of the ROOTSYS environment variable is not always set to the correct value. If the program is started without ROOTSYS set, TUnixSystem::Init will initialize it. The assignment of the static variable in GetRootSys must therefore be done after this. I have added calls to all the functions in the TROOT constructor, after the call to InitSystem. This way all the static variables get assigned by the TROOT constructor (which I believe is run single threaded). All subsequent calls to the functions will then not change the value of the static variables and are therefore thread safe. Will this work?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:210,deployability,depend,dependency,210,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:501,energy efficiency,power,power,501,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:101,integrability,wrap,wrapped,101,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:210,integrability,depend,dependency,210,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:210,modifiability,depend,dependency,210,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:366,modifiability,variab,variable,366,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:171,performance,time,time,171,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:434,performance,time,time,434,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:210,safety,depend,dependency,210,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:210,testability,depend,dependency,210,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:486,usability,help,help,486,"This sounds good, indeed. Ideally, all these static initializations (including that of gRootsys) are wrapped in functions, such that the statics get initialized the first time they are needed and resolve their dependency themselves, through the call graph. Maybe it's easier to do the gRootsys initialization like that, through a function call the ensures that this variable is set when needed? Up to you - you have spent more recent time with this code than I did :-). Thanks for your help and brain power!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:108,deployability,instal,install-test,108,"A general comment, if possible it would be better if we could avoid the commits ""Merge branch 'master' into install-test"" if possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:62,safety,avoid,avoid,62,"A general comment, if possible it would be better if we could avoid the commits ""Merge branch 'master' into install-test"" if possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:116,safety,test,test,116,"A general comment, if possible it would be better if we could avoid the commits ""Merge branch 'master' into install-test"" if possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:116,testability,test,test,116,"A general comment, if possible it would be better if we could avoid the commits ""Merge branch 'master' into install-test"" if possible.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:180,deployability,automat,automatically,180,"I have tried to keep this PR mergeable, but since it touches quite a lot of files it is not uncommon that changes to master make changes to the same files in a way that can not be automatically resolved. The ""Merge branch 'master' into install-test"" commits are the resolutions of these merge conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:236,deployability,instal,install-test,236,"I have tried to keep this PR mergeable, but since it touches quite a lot of files it is not uncommon that changes to master make changes to the same files in a way that can not be automatically resolved. The ""Merge branch 'master' into install-test"" commits are the resolutions of these merge conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:293,interoperability,conflict,conflicts,293,"I have tried to keep this PR mergeable, but since it touches quite a lot of files it is not uncommon that changes to master make changes to the same files in a way that can not be automatically resolved. The ""Merge branch 'master' into install-test"" commits are the resolutions of these merge conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:244,safety,test,test,244,"I have tried to keep this PR mergeable, but since it touches quite a lot of files it is not uncommon that changes to master make changes to the same files in a way that can not be automatically resolved. The ""Merge branch 'master' into install-test"" commits are the resolutions of these merge conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:180,testability,automat,automatically,180,"I have tried to keep this PR mergeable, but since it touches quite a lot of files it is not uncommon that changes to master make changes to the same files in a way that can not be automatically resolved. The ""Merge branch 'master' into install-test"" commits are the resolutions of these merge conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:244,testability,test,test,244,"I have tried to keep this PR mergeable, but since it touches quite a lot of files it is not uncommon that changes to master make changes to the same files in a way that can not be automatically resolved. The ""Merge branch 'master' into install-test"" commits are the resolutions of these merge conflicts.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:41,interoperability,conflict,conflicts,41,Thanks. I merged master and resolved the conflicts again. This time there were quite a few of them due to the recent changes to the rootcling statge 1 processing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:63,performance,time,time,63,Thanks. I merged master and resolved the conflicts again. This time there were quite a few of them due to the recent changes to the rootcling statge 1 processing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:5,safety,test,testing,5,I am testing it now.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:5,testability,test,testing,5,I am testing it now.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:181,availability,failur,failures,181,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:462,availability,failur,failures,462,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:35,deployability,manag,manage,35,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:143,deployability,fail,failed,143,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:181,deployability,fail,failures,181,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:221,deployability,build,build,221,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:462,deployability,fail,failures,462,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:35,energy efficiency,manag,manage,35,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:181,performance,failur,failures,181,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:462,performance,failur,failures,462,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:143,reliability,fail,failed,143,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:181,reliability,fail,failures,181,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:462,reliability,fail,failures,462,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:35,safety,manag,manage,35,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:53,safety,test,tests,53,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:137,safety,test,tests,137,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:407,safety,compl,complement,407,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:407,security,compl,complement,407,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:53,testability,test,tests,53,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:137,testability,test,tests,137,"Hi Mattias. Running with this PR I manage to run all tests successfully without the option gnuinstall. Running with the option I get 227 tests failed out of 1395. Basically all the failures are related to difficulties to build dictionaries or libraries because the ROOT libraries are expected in different place. . I think I would merge the PR since we will not break existing functionality, but we need to complement with some more changes to fix the remaining failures.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:54,availability,failur,failures,54,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:380,availability,failur,failure,380,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:780,availability,avail,available,780,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:54,deployability,fail,failures,54,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:127,deployability,build,build,127,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:216,deployability,log,logs,216,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:228,deployability,build,build,228,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:234,deployability,log,log,234,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:268,deployability,fail,failed,268,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:380,deployability,fail,failure,380,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:721,deployability,build,build,721,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:737,deployability,version,versions,737,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:758,deployability,depend,dependencies,758,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:946,deployability,build,build,946,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1124,deployability,build,build,1124,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1155,deployability,depend,depend,1155,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:737,integrability,version,versions,737,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:758,integrability,depend,dependencies,758,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1155,integrability,depend,depend,1155,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:797,interoperability,distribut,distribution,797,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:182,modifiability,pac,packages,182,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:737,modifiability,version,versions,737,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:758,modifiability,depend,dependencies,758,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1155,modifiability,depend,depend,1155,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:54,performance,failur,failures,54,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:322,performance,network,network,322,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:380,performance,failur,failure,380,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:54,reliability,fail,failures,54,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:268,reliability,fail,failed,268,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:380,reliability,fail,failure,380,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:780,reliability,availab,available,780,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:89,safety,test,tests,89,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:216,safety,log,logs,216,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:234,safety,log,log,234,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:246,safety,test,tests,246,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:262,safety,test,tests,262,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:306,safety,test,tests,306,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:352,safety,test,test,352,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:392,safety,test,test-stressIOPlugins,392,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:602,safety,test,tests,602,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:699,safety,except,except,699,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:758,safety,depend,dependencies,758,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:780,safety,avail,available,780,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:928,safety,test,test,928,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1155,safety,depend,depend,1155,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:216,security,log,logs,216,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:234,security,log,log,234,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:322,security,network,network,322,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:330,security,access,access,330,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:780,security,availab,available,780,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:89,testability,test,tests,89,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:216,testability,log,logs,216,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:234,testability,log,log,234,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:246,testability,test,tests,246,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:262,testability,test,tests,262,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:306,testability,test,tests,306,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:352,testability,test,test,352,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:392,testability,test,test-stressIOPlugins,392,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:602,testability,test,tests,602,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:758,testability,depend,dependencies,758,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:928,testability,test,test,928,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1155,testability,depend,depend,1155,"I always run with the gnuinstall option, and I see no failures. But I don't have as many tests in total as you. For my 6.08.04 build I have (see: https://kojipkgs.fedoraproject.org//packages/root/6.08.04/1.fc25/data/logs/x86_64/build.log):. 100% tests passed, 0 tests failed out of 602. This is with a few tests requiring network access disabled. make test 'ARGS=-j16 --output-on-failure -E ""test-stressIOPlugins-.*|tutorial-tree-run_h1analysis|tutorial-multicore-imt001_parBranchProcessing|tutorial-multicore-mp103_processSelector|tutorial-multicore-imt101_parTreeProcessing""'. But those few disabled tests do not account for the difference between 602 and 1395. I disable all the builtin options (except for llvm), and build using the versions of external dependencies that are available in the distribution. Can you elaborate on what you mean by ""because the ROOT libraries are expected in different place""? When running the test suite in the build tree, the libraries are expected to be in the same place independently of the gnuinstall option (i.e. in ${CMAKE_BINARY_DIR}/lib). The location of the built targets in the build tree are supposed to not depend on whether the gnuinstall option is on or off.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:189,availability,error,error,189,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:505,availability,Error,Error,505,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:991,availability,Error,Error,991,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1071,availability,Error,Error,1071,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1222,availability,failur,failures,1222,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1705,availability,ERROR,ERROR,1705,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1884,availability,error,error,1884,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:76,deployability,fail,failing,76,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:170,deployability,build,build,170,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:248,deployability,build,build,248,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:320,deployability,build,build,320,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:357,deployability,build,build,357,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1130,deployability,build,build,1130,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1142,deployability,Fail,Failed,1142,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1184,deployability,fail,failed,1184,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1222,deployability,fail,failures,1222,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1287,deployability,resourc,resources,1287,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1365,deployability,build,build,1365,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1438,deployability,build,build,1438,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1475,deployability,build,build,1475,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1751,deployability,resourc,resource,1751,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:817,energy efficiency,load,load,817,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1287,energy efficiency,resourc,resources,1287,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1751,energy efficiency,resourc,resource,1751,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:189,performance,error,error,189,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:298,performance,Content,Contents,298,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:470,performance,time,timeout,470,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:505,performance,Error,Error,505,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:817,performance,load,load,817,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:991,performance,Error,Error,991,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1071,performance,Error,Error,1071,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1222,performance,failur,failures,1222,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1287,performance,resourc,resources,1287,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1416,performance,Content,Contents,1416,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1590,performance,time,timeout,1590,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1705,performance,ERROR,ERROR,1705,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1751,performance,resourc,resource,1751,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1884,performance,error,error,1884,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:76,reliability,fail,failing,76,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:597,reliability,doe,does,597,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1142,reliability,Fail,Failed,1142,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1184,reliability,fail,failed,1184,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1222,reliability,fail,failures,1222,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:32,safety,test,tests,32,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:84,safety,test,tests,84,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:189,safety,error,error,189,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:260,safety,Test,Test,260,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:465,safety,Test,Test,465,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:470,safety,timeout,timeout,470,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:505,safety,Error,Error,505,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:991,safety,Error,Error,991,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1071,safety,Error,Error,1071,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1084,safety,Test,Test,1084,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1162,safety,test,tests,1162,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1178,safety,test,tests,1178,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1287,safety,resourc,resources,1287,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1378,safety,Test,Test,1378,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1585,safety,Test,Test,1585,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1590,safety,timeout,timeout,1590,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1705,safety,ERROR,ERROR,1705,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1751,safety,resourc,resource,1751,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1884,safety,error,error,1884,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:32,testability,test,tests,32,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:84,testability,test,tests,84,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:260,testability,Test,Test,260,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:465,testability,Test,Test,465,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1084,testability,Test,Test,1084,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1162,testability,test,tests,1162,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1178,testability,test,tests,1178,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1287,testability,resourc,resources,1287,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1378,testability,Test,Test,1378,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1585,testability,Test,Test,1585,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1751,testability,resourc,resource,1751,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:189,usability,error,error,189,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:265,usability,command,command,265,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:329,usability,User,Users,329,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:505,usability,Error,Error,505,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:618,usability,User,Users,618,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:991,usability,Error,Error,991,"Are you enabling the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1071,usability,Error,Error,1071,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1383,usability,command,command,1383,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1447,usability,User,Users,1447,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1705,usability,ERROR,ERROR,1705,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1771,usability,User,Users,1771,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:1884,usability,error,error,1884,"g the 'roottest' tests (with -Droottest=ON)? Because all the failing tests are in this category. Lets take for example `roottest-cling-function-refClasses-build`, I get this error:. ```. Start 634: roottest-cling-function-refClasses-build. 634: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-cling-function-refClasses-compile-macro/fast"" ""--"" ""--always-make"". 634: Test timeout computed to be: 1500. 634: Error in <UnknownClass::FindDynamicLibrary>: libCling[.so | .dll | .dylib | .sl | .dl | .a] does not exist in .:/Users/mato/Development/ROOT/root.prefix/lib/root:/usr/local/lib:/usr/X11R6/lib:/usr/lib:/lib:/lib/x86_64-linux-gnu:/usr/local/lib64:/usr/lib64:/lib64:. 634: Fatal in <TROOT::InitInterpreter>: cannot load symbol dlsym(RTLD_DEFAULT, CreateInterpreter): symbol not found. 634: make[1]: *** [roottest/cling/function/CMakeFiles/roottest-cling-function-refClasses-compile-macro] Error 1. 634: make: *** [roottest-cling-function-refClasses-compile-macro/fast] Error 2. 1/1 Test #634: roottest-cling-function-refClasses-build ...***Failed 0.11 sec. 0% tests passed, 1 tests failed out of 1. ```. Another type of failures are the following, which involves the location of Clang resources. ```. Start 1020: roottest-root-meta-expressiveErrorMessages-libgen-build. 1020: Test command: /Applications/CMake.app/Contents/bin/cmake ""--build"" ""/Users/mato/Development/ROOT/build.master"" ""--target"" ""roottest-root-meta-expressiveErrorMessages-libgen/fast"" ""--"" ""--always-make"". 1020: Test timeout computed to be: 1500. 1020: Generating expressiveErrorMessages.cxx, expressiveErrorMessages.rootmap. 1020: ERROR in cling::CIFactory::createCI():. 1020: resource directory /Users/mato/Development/ROOT/root.prefix/etc/root/cling/lib/clang/3.9.0 not found! 1020: input_line_2:1:10: fatal error: 'cling/Interpreter/RuntimeUniverse.h' file not found. 1020: #include ""cling/Interpreter/RuntimeUniverse.h"". 1020: ^. ... ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:4,deployability,fail,failing,4,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:204,deployability,build,build,204,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:232,deployability,instal,installed,232,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:152,integrability,Configur,Configured,152,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:152,modifiability,Configur,Configured,152,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:4,reliability,fail,failing,4,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:12,safety,test,tests,12,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:152,security,Configur,Configured,152,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/130:12,testability,test,tests,12,"The failing tests where from roottest suit. Two fixes:. - Added ENVIRONMENT ROOTIGNOREPREFIX=1 for some additional add_test(...) in roottest sources. - Configured two root-config (one to be used from the build tree, the other to be installed in PREFIX). Merged into master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/130
https://github.com/root-project/root/pull/131:0,deployability,Integr,Integrated,0,Integrated. Thanks Omar for the revision of the text!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/131:0,integrability,Integr,Integrated,0,Integrated. Thanks Omar for the revision of the text!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/131:0,interoperability,Integr,Integrated,0,Integrated. Thanks Omar for the revision of the text!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/131:0,modifiability,Integr,Integrated,0,Integrated. Thanks Omar for the revision of the text!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/131:0,reliability,Integr,Integrated,0,Integrated. Thanks Omar for the revision of the text!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/131:0,security,Integr,Integrated,0,Integrated. Thanks Omar for the revision of the text!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/131:0,testability,Integr,Integrated,0,Integrated. Thanks Omar for the revision of the text!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/131
https://github.com/root-project/root/pull/134:33,safety,test,test,33,"@zzxuanyuan 5. Note that for the test you made for #84, we had to apply a few fixes to the CMakeLists.txt to make it more general.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:33,testability,test,test,33,"@zzxuanyuan 5. Note that for the test you made for #84, we had to apply a few fixes to the CMakeLists.txt to make it more general.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:31,security,Sign,Signal,31,"@zzxuanyuan 2. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary functoin (getenv, etc, to gSystem).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:64,security,sign,signal,64,"@zzxuanyuan 2. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary functoin (getenv, etc, to gSystem).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:50,deployability,Stack,StackTrace,50,@zzxuanyuan Other signals are still using default StackTrace functions. . What made you make this choice? @zzxuanyuan kSigAlarm and kSigChild are ignored for my current implementation. . What made you make this choice? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:161,energy efficiency,current,current,161,@zzxuanyuan Other signals are still using default StackTrace functions. . What made you make this choice? @zzxuanyuan kSigAlarm and kSigChild are ignored for my current implementation. . What made you make this choice? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:18,security,sign,signals,18,@zzxuanyuan Other signals are still using default StackTrace functions. . What made you make this choice? @zzxuanyuan kSigAlarm and kSigChild are ignored for my current implementation. . What made you make this choice? Thanks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:530,availability,fault,fault,530,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:417,deployability,Updat,Update,417,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:530,energy efficiency,fault,fault,530,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:478,integrability,abstract,abstract,478,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:478,modifiability,abstract,abstract,478,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:530,performance,fault,fault,530,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:592,performance,time,timer,592,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:530,reliability,fault,fault,530,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:417,safety,Updat,Update,417,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:530,safety,fault,fault,530,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:417,security,Updat,Update,417,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:554,usability,command,command,554,"@pcanal I ignore kSigAlarm is because it will trigger the function DispatchTimers(). This function is implemented in TUnixSystem but not defined in TSystem. I can't use gSystem to call this function. Same issue for kSigChild, it tries to call CheckChilds(). I could either duplicate these two functions in TSigHandling or add those functions in TSystem. But I don't think it makes sense if we define them in TSystem. Update:. I tried to move DispatchTimers() into TSystem as an abstract function. But it will cause a segmentation fault once I open CINT (command: root -l). It seemed CINT set timer when it is initialized and that cause the problem. Should I duplicate all DispatchTimers() and relative functions into TSigHandling.cxx ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:35,availability,fault,fault,35,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:92,deployability,stack,stack,92,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:35,energy efficiency,fault,fault,35,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:35,performance,fault,fault,35,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:35,reliability,fault,fault,35,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:35,safety,fault,fault,35,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:98,testability,trace,trace,98,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:59,usability,command,command,59,> But it will cause a segmentation fault once I open CINT (command: root -l). . What is the stack trace?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:31,availability,error,error,31,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:249,availability,error,error,249,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1215,availability,operat,operator,1215,"urred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:12,deployability,stack,stack,12,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:604,deployability,Stack,StackTraceTriggerThread,604,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:521,energy efficiency,core,core,521,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:664,energy efficiency,core,core,664,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:844,energy efficiency,core,core,844,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1373,energy efficiency,optim,optimized,1373,"05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1396,energy efficiency,optim,optimized,1396,"ead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x00000000",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1445,energy efficiency,core,core,1445,"\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1538,energy efficiency,optim,optimized,1538,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1587,energy efficiency,core,core,1587,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1716,energy efficiency,alloc,alloc,1716,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1757,energy efficiency,core,core,1757,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1874,energy efficiency,core,core,1874,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2092,energy efficiency,core,core,2092,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2198,energy efficiency,optim,optimized,2198,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2220,energy efficiency,optim,optimized,2220,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2242,energy efficiency,optim,optimized,2242,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2267,energy efficiency,optim,optimized,2267,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2295,energy efficiency,optim,optimized,2295,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2358,energy efficiency,core,core,2358,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:31,performance,error,error,31,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:249,performance,error,error,249,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:454,performance,time,timeout,454,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:462,performance,time,timeout,462,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1373,performance,optimiz,optimized,1373,"05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1396,performance,optimiz,optimized,1396,"ead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x00000000",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:1538,performance,optimiz,optimized,1538,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2198,performance,optimiz,optimized,2198,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2220,performance,optimiz,optimized,2220,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2242,performance,optimiz,optimized,2242,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2267,performance,optimiz,optimized,2267,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:2295,performance,optimiz,optimized,2295,"han0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint"", argc=0x7ffd70968f4c, argv=0x7ffd70969048, numOptions=0) at /home/bockelman/zhan0915/root/core/base/src/TApplication.cxx:144. #14 0x00007f8b05ad1b71 in TRint::TRint (this=0x1582e40, appClassName=<optimized out>, argc=<optimized out>, argv=<optimized out>, options=<optimized out>, numOptions=<optimized out>, noLogo=false) at /home/bockelman/zhan0915/root/core/rint/src/TRint.cxx:144. #15 0x0000000000400fee in main (argc=3, argv=0x7ffd70969048) at /home/bockelman/zhan0915/root/main/src/rmain.cxx:27. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:31,safety,error,error,31,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:249,safety,error,error,249,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:454,safety,timeout,timeout,454,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:462,safety,timeout,timeout,462,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:205,security,sign,signal,205,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:390,security,Sign,SignalSafeRead,390,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:888,security,sign,signal,888,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:18,testability,trace,trace,18,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:49,testability,simpl,simply,49,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:31,usability,error,error,31,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:49,usability,simpl,simply,49,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:249,usability,error,error,249,"Here is the stack trace of the error. Now I just simply use type casting gSystem to TUnixSystem to get rid of defining DispatchTimers() in TSystem. . ```. [zhan0915@hcc-zhan root]$ root -l. A fatal system signal has occurred: segmentation violation error. Thread 1 (Thread 0x7f8b05aa0920 (LWP 10908)):. #0 0x0000003fa220e82d in read () from /lib64/libpthread.so.0. #1 0x00007f8b05fa3c64 in SignalSafeRead (fd=3, inbuf=inbuf. entry=0x7ffd70966680 ""\001"", timeout=timeout. entry=-1, len=1) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:195. #2 0x00007f8b05fa4435 in TUnixSigHandling::StackTraceTriggerThread () at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:816. #3 0x00007f8b05fa450c in TUnixSigHandling::DispatchSignals (this=0x1534f70, sig=kSigSegmentationViolation) at /home/bockelman/zhan0915/root/core/unix/src/TUnixSigHandling.cxx:552. #4 <signal handler called>. #5 0x0000003fa1e811a1 in __strlen_sse2 () from /lib64/libc.so.6. #6 0x00007f8b0255f728 in length (__s=0x0) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/char_traits.h:259. #7 assign (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:1131. #8 operator= (__s=0x0, this=0x7ffd70966c40) at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/basic_string.h:555. #9 TCling::TCling (this=0x1594620, name=<optimized out>, title=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:1068. #10 0x00007f8b025602ae in CreateInterpreter (interpLibHandle=<optimized out>) at /home/bockelman/zhan0915/root/core/meta/src/TCling.cxx:578. #11 0x00007f8b05e2daa8 in TROOT::InitInterpreter (this=0x7f8b062a5520 <ROOT::Internal::GetROOT1()::alloc>) at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:1821. #12 0x00007f8b05e2de26 in ROOT::Internal::GetROOT2 () at /home/bockelman/zhan0915/root/core/base/src/TROOT.cxx:363. #13 0x00007f8b05f03845 in TApplication::TApplication (this=0x1582e40, appClassName=0x401350 ""Rint",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:16,deployability,manag,managed,16,No idea how you managed to get there :-) but that crash should now be protected against in the master by f0e5295. You forgot to set ROOTSYS (and somehow ROOT didn't manage to determine it itself...).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:165,deployability,manag,manage,165,No idea how you managed to get there :-) but that crash should now be protected against in the master by f0e5295. You forgot to set ROOTSYS (and somehow ROOT didn't manage to determine it itself...).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:16,energy efficiency,manag,managed,16,No idea how you managed to get there :-) but that crash should now be protected against in the master by f0e5295. You forgot to set ROOTSYS (and somehow ROOT didn't manage to determine it itself...).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:165,energy efficiency,manag,manage,165,No idea how you managed to get there :-) but that crash should now be protected against in the master by f0e5295. You forgot to set ROOTSYS (and somehow ROOT didn't manage to determine it itself...).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:16,safety,manag,managed,16,No idea how you managed to get there :-) but that crash should now be protected against in the master by f0e5295. You forgot to set ROOTSYS (and somehow ROOT didn't manage to determine it itself...).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:165,safety,manag,manage,165,No idea how you managed to get there :-) but that crash should now be protected against in the master by f0e5295. You forgot to set ROOTSYS (and somehow ROOT didn't manage to determine it itself...).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:300,deployability,continu,continue,300,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:155,performance,time,timeout,155,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:337,performance,parallel,parallel,337,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:127,reliability,doe,does,127,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:115,safety,review,review,115,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:155,safety,timeout,timeout,155,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:329,safety,test,test,329,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:115,testability,review,review,115,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:324,testability,unit,unit,324,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:329,testability,test,test,329,"Hi Zhe,. Just sent a pull request to your branch that merges master into this branch (makes things a bit easier to review) and does a small touchup (add a timeout when waiting for GDB to protect against potential issues). Everything looks good to me - this is probably ready to go forward (do please continue to work on the unit test in parallel). Brian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:69,usability,close,closed,69,@pcanal - I'm starting to poke at this one now. I'd like to get this closed out.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:59,deployability,version,versions,59,"@zzxuanyuan - I only found a small issue, from using newer versions of CMake. Can you cherry-pick this patch:. https://github.com/bbockelm/root/commit/8841ee67324284126de2fbe0f79524fb71a2686d. Merges cleanly back into master; everything seems to work well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:103,deployability,patch,patch,103,"@zzxuanyuan - I only found a small issue, from using newer versions of CMake. Can you cherry-pick this patch:. https://github.com/bbockelm/root/commit/8841ee67324284126de2fbe0f79524fb71a2686d. Merges cleanly back into master; everything seems to work well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:59,integrability,version,versions,59,"@zzxuanyuan - I only found a small issue, from using newer versions of CMake. Can you cherry-pick this patch:. https://github.com/bbockelm/root/commit/8841ee67324284126de2fbe0f79524fb71a2686d. Merges cleanly back into master; everything seems to work well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:59,modifiability,version,versions,59,"@zzxuanyuan - I only found a small issue, from using newer versions of CMake. Can you cherry-pick this patch:. https://github.com/bbockelm/root/commit/8841ee67324284126de2fbe0f79524fb71a2686d. Merges cleanly back into master; everything seems to work well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:103,safety,patch,patch,103,"@zzxuanyuan - I only found a small issue, from using newer versions of CMake. Can you cherry-pick this patch:. https://github.com/bbockelm/root/commit/8841ee67324284126de2fbe0f79524fb71a2686d. Merges cleanly back into master; everything seems to work well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:103,security,patch,patch,103,"@zzxuanyuan - I only found a small issue, from using newer versions of CMake. Can you cherry-pick this patch:. https://github.com/bbockelm/root/commit/8841ee67324284126de2fbe0f79524fb71a2686d. Merges cleanly back into master; everything seems to work well.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:370,availability,failur,failure,370,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:99,deployability,build,build,99,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:370,deployability,fail,failure,370,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:349,modifiability,exten,extent,349,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:370,performance,failur,failure,370,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:370,reliability,fail,failure,370,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:198,security,Sign,Signal,198,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:231,security,sign,signal,231,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:442,usability,close,closer,442,"@bbockelm I had started working on the merge but got distracted. The branch as it was then did not build on MacOS (i have a fix for that). . I am also still uncomfortable with. > 1. I think the new Signal class should focus in the signal handling itself and delegate the auxiliary function (getenv, etc, to gSystem). which zxuanyuan explain to some extent and found odd failure when attempting to improve the situation, so I wanted to take a closer look (too see what the problem was and/or there was a better way).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:44,deployability,updat,updated,44,@pcanal @bbockelm I merged your commits and updated this branch with upstream.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:44,safety,updat,updated,44,@pcanal @bbockelm I merged your commits and updated this branch with upstream.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:44,security,updat,updated,44,@pcanal @bbockelm I merged your commits and updated this branch with upstream.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:30,interoperability,conflict,conflicts,30,@zzxuanyuan - can you resolve conflicts noted above?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:111,availability,state,state,111,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:51,deployability,patch,patch,51,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:103,deployability,upgrad,upgrade,103,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:111,integrability,state,state,111,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:103,modifiability,upgrad,upgrade,103,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:51,safety,patch,patch,51,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:51,security,patch,patch,51,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:137,usability,help,help,137,Don't worry about this .. for better or worse this patch request is on my desk in half merge/half more upgrade state and need a bit more help on my side. I am keeping this pull request open until I am done.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:124,safety,safe,safe,124,TSignalHandler is the name of original implementation in ROOT. TSigHandling is the new implementation which supports thread-safe functions. Zhe,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/134:108,usability,support,supports,108,TSignalHandler is the name of original implementation in ROOT. TSigHandling is the new implementation which supports thread-safe functions. Zhe,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/134
https://github.com/root-project/root/pull/135:26,deployability,patch,patch,26,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:167,deployability,patch,patch,167,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:211,interoperability,plug,plugin,211,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:232,interoperability,plug,plugin,232,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:385,interoperability,mismatch,mismatch,385,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:26,safety,patch,patch,26,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:167,safety,patch,patch,167,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:411,safety,valid,validity,411,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:26,security,patch,patch,26,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:167,security,patch,patch,167,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:292,usability,statu,status,292,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:308,usability,statu,status,308,"Hi Brian,. Thanks for the patch. I think the length returned by Read in ReadBuffer(char *,Int_t) should also be checked too, so I'll also change as well a adding your patch. These changes are in the older xroot plugin. In the newer plugin, TNetXNGFile, the Read() result is checked for a bad status, and the status of the individual chunks from VectorRead() are also checked. A length mismatch is a part of the validity check in the client, so short reads shouldn't be possible there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:19,deployability,patch,patch,19,Hi. I've added the patch. Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:19,safety,patch,patch,19,Hi. I've added the patch. Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/135:19,security,patch,patch,19,Hi. I've added the patch. Thank you.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/135
https://github.com/root-project/root/pull/136:33,deployability,patch,patch,33,"@pcanal @bbockelm . I think this patch is ready. I run through all unit tests. In addition, I switch TBuffer in MainEvent.cxx between little endian and big endian and dump all events in both cases. They look the same. The lines of code in following link is to determine if there is byte count TBuffer I discussed with Brian this morning. I left some comments above it. https://github.com/zzxuanyuan/root/blob/byteswap/io/io/src/TBufferFile.cxx#L3237.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:176,integrability,event,events,176,"@pcanal @bbockelm . I think this patch is ready. I run through all unit tests. In addition, I switch TBuffer in MainEvent.cxx between little endian and big endian and dump all events in both cases. They look the same. The lines of code in following link is to determine if there is byte count TBuffer I discussed with Brian this morning. I left some comments above it. https://github.com/zzxuanyuan/root/blob/byteswap/io/io/src/TBufferFile.cxx#L3237.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:33,safety,patch,patch,33,"@pcanal @bbockelm . I think this patch is ready. I run through all unit tests. In addition, I switch TBuffer in MainEvent.cxx between little endian and big endian and dump all events in both cases. They look the same. The lines of code in following link is to determine if there is byte count TBuffer I discussed with Brian this morning. I left some comments above it. https://github.com/zzxuanyuan/root/blob/byteswap/io/io/src/TBufferFile.cxx#L3237.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:72,safety,test,tests,72,"@pcanal @bbockelm . I think this patch is ready. I run through all unit tests. In addition, I switch TBuffer in MainEvent.cxx between little endian and big endian and dump all events in both cases. They look the same. The lines of code in following link is to determine if there is byte count TBuffer I discussed with Brian this morning. I left some comments above it. https://github.com/zzxuanyuan/root/blob/byteswap/io/io/src/TBufferFile.cxx#L3237.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:33,security,patch,patch,33,"@pcanal @bbockelm . I think this patch is ready. I run through all unit tests. In addition, I switch TBuffer in MainEvent.cxx between little endian and big endian and dump all events in both cases. They look the same. The lines of code in following link is to determine if there is byte count TBuffer I discussed with Brian this morning. I left some comments above it. https://github.com/zzxuanyuan/root/blob/byteswap/io/io/src/TBufferFile.cxx#L3237.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:67,testability,unit,unit,67,"@pcanal @bbockelm . I think this patch is ready. I run through all unit tests. In addition, I switch TBuffer in MainEvent.cxx between little endian and big endian and dump all events in both cases. They look the same. The lines of code in following link is to determine if there is byte count TBuffer I discussed with Brian this morning. I left some comments above it. https://github.com/zzxuanyuan/root/blob/byteswap/io/io/src/TBufferFile.cxx#L3237.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:72,testability,test,tests,72,"@pcanal @bbockelm . I think this patch is ready. I run through all unit tests. In addition, I switch TBuffer in MainEvent.cxx between little endian and big endian and dump all events in both cases. They look the same. The lines of code in following link is to determine if there is byte count TBuffer I discussed with Brian this morning. I left some comments above it. https://github.com/zzxuanyuan/root/blob/byteswap/io/io/src/TBufferFile.cxx#L3237.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:78,integrability,buffer,buffer,78,It is unclear how the code when reading an arbitrary file decides whether the buffer is big endian or little endian. What is the plan there (and/or did I miss some code where it is already implemented)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:129,testability,plan,plan,129,It is unclear how the code when reading an arbitrary file decides whether the buffer is big endian or little endian. What is the plan there (and/or did I miss some code where it is already implemented)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:236,integrability,buffer,buffer,236,"@pcanal I have not implemented it yet. I think I could add one more bit in TFile and indicate the endianness of the file. Does that sound like a plan? Otherwise, I might also evaluate the fBufBigEndian bit in TBuffer and determine each buffer is big endian or little endian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:122,reliability,Doe,Does,122,"@pcanal I have not implemented it yet. I think I could add one more bit in TFile and indicate the endianness of the file. Does that sound like a plan? Otherwise, I might also evaluate the fBufBigEndian bit in TBuffer and determine each buffer is big endian or little endian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:145,testability,plan,plan,145,"@pcanal I have not implemented it yet. I think I could add one more bit in TFile and indicate the endianness of the file. Does that sound like a plan? Otherwise, I might also evaluate the fBufBigEndian bit in TBuffer and determine each buffer is big endian or little endian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:85,usability,indicat,indicate,85,"@pcanal I have not implemented it yet. I think I could add one more bit in TFile and indicate the endianness of the file. Does that sound like a plan? Otherwise, I might also evaluate the fBufBigEndian bit in TBuffer and determine each buffer is big endian or little endian.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:22,testability,understand,understand,22,@zzxuanyuan @pcanal I understand this is still work in progress?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:55,usability,progress,progress,55,@zzxuanyuan @pcanal I understand this is still work in progress?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:61,performance,performance test,performance test,61,@etejedor @pcanal @bbockelm . I think this branch is lack of performance test among different alternatives as discussed in https://sft.its.cern.ch/jira/browse/ROOT-5073. Do we still want to work on that?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:73,safety,test,test,73,@etejedor @pcanal @bbockelm . I think this branch is lack of performance test among different alternatives as discussed in https://sft.its.cern.ch/jira/browse/ROOT-5073. Do we still want to work on that?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:73,testability,test,test,73,@etejedor @pcanal @bbockelm . I think this branch is lack of performance test among different alternatives as discussed in https://sft.its.cern.ch/jira/browse/ROOT-5073. Do we still want to work on that?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:61,usability,perform,performance,61,@etejedor @pcanal @bbockelm . I think this branch is lack of performance test among different alternatives as discussed in https://sft.its.cern.ch/jira/browse/ROOT-5073. Do we still want to work on that?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/136:20,usability,close,close,20,"Hi,. I think we can close for now. Thanks! Brian",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/136
https://github.com/root-project/root/pull/137:488,availability,toler,tolerance,488,"Hi, . I am sorry I cannot include the patch as it is in RooFit because it has the following problems: . - the comments are re-formatted to the old THTML style. They should be mantained to the Doxygen style. Look at the diff to understand it. - The patch is also not correct in case of RooMinuit for the SetEps option. This is due to a naming problem already existing in RooMinimizer. The value you want to change I guess is not the eps (the floating point precision) but the minimization tolerance. The EPS parameter in Minuit controls the precision the function is computed and it should be kept, apart n some exceptional case to the normal double precision value. The parameter you want to change is instead the tolerance for the minimisation, which by default is set to 1 in RooFit. . So I would change the option to SetTolerance or SetTol and implement it correctly in RooMinuit. In RooMinimizer unfortunately the method setting the tolerance is called SetEps. Probably this method should be changed. Please let me know if you can make these changes, . Thank you . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/137
https://github.com/root-project/root/pull/137:714,availability,toler,tolerance,714,"Hi, . I am sorry I cannot include the patch as it is in RooFit because it has the following problems: . - the comments are re-formatted to the old THTML style. They should be mantained to the Doxygen style. Look at the diff to understand it. - The patch is also not correct in case of RooMinuit for the SetEps option. This is due to a naming problem already existing in RooMinimizer. The value you want to change I guess is not the eps (the floating point precision) but the minimization tolerance. The EPS parameter in Minuit controls the precision the function is computed and it should be kept, apart n some exceptional case to the normal double precision value. The parameter you want to change is instead the tolerance for the minimisation, which by default is set to 1 in RooFit. . So I would change the option to SetTolerance or SetTol and implement it correctly in RooMinuit. In RooMinimizer unfortunately the method setting the tolerance is called SetEps. Probably this method should be changed. Please let me know if you can make these changes, . Thank you . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/137
https://github.com/root-project/root/pull/137:937,availability,toler,tolerance,937,"Hi, . I am sorry I cannot include the patch as it is in RooFit because it has the following problems: . - the comments are re-formatted to the old THTML style. They should be mantained to the Doxygen style. Look at the diff to understand it. - The patch is also not correct in case of RooMinuit for the SetEps option. This is due to a naming problem already existing in RooMinimizer. The value you want to change I guess is not the eps (the floating point precision) but the minimization tolerance. The EPS parameter in Minuit controls the precision the function is computed and it should be kept, apart n some exceptional case to the normal double precision value. The parameter you want to change is instead the tolerance for the minimisation, which by default is set to 1 in RooFit. . So I would change the option to SetTolerance or SetTol and implement it correctly in RooMinuit. In RooMinimizer unfortunately the method setting the tolerance is called SetEps. Probably this method should be changed. Please let me know if you can make these changes, . Thank you . Lorenzo.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/137
